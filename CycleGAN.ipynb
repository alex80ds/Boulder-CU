{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cc4772c-acd4-4885-a04f-639fa01ed319",
   "metadata": {},
   "source": [
    "# CycleGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872aa081-473f-4eee-bdbc-cf8d5149fb5d",
   "metadata": {},
   "source": [
    "To build a CycleGAN with PyTorch, you'd typically follow these steps:\n",
    "\n",
    "Define the Dataset and DataLoader: Use torch.utils.data.Dataset to custom load your images, applying necessary transformations like resizing, normalizing, and converting to tensors. DataLoader will handle batching and shuffling of the data for training.\n",
    "Build Generator and Discriminator Models: Define your generator and discriminator classes inheriting from nn.Module, using convolutional layers (nn.Conv2d for discriminators, nn.ConvTranspose2d for generators), batch normalization (nn.BatchNorm2d), and activation functions (nn.ReLU, nn.Tanh).\n",
    "Specify Loss Functions and Optimizers: Commonly, CycleGAN uses adversarial loss (BCE loss) and cycle consistency loss (L1 loss), with optimizers typically being Adam.\n",
    "Training Loop: Implement the training process, alternating between training the discriminator and generator, applying the gradients, and updating the network weights.\n",
    "Visualization and Evaluation: Use matplotlib.pyplot and torchvision.utils for visualizing training progress and results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fabfe5-4c39-4039-a38c-9e27fa799348",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38db4a07-5fa8-4335-b659-8ec4c34bc927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import zipfile\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import itertools\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root_monet, root_photo, transform=None):\n",
    "        self.transform = transform\n",
    "        self.files_monet = [os.path.join(root_monet, file) for file in sorted(os.listdir(root_monet))]\n",
    "        self.files_photo = [os.path.join(root_photo, file) for file in sorted(os.listdir(root_photo))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_monet), len(self.files_photo))\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_monet_path = self.files_monet[index % len(self.files_monet)]\n",
    "        image_photo_path = self.files_photo[index % len(self.files_photo)]\n",
    "\n",
    "        image_monet = Image.open(image_monet_path)\n",
    "        image_photo = Image.open(image_photo_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image_monet = self.transform(image_monet)\n",
    "            image_photo = self.transform(image_photo)\n",
    "\n",
    "        return {'Monet': image_monet, 'Photo': image_photo}\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = ImageDataset(root_monet='monet_jpg', root_photo='photo_jpg', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0679c39-dec5-44ff-b5f4-4e3abf1711fa",
   "metadata": {},
   "source": [
    "# Generator and Discriminator Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de95e983-2e5e-4d8a-aa0d-c5ec5b1da16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f358d4f2-176d-44cf-bc85-2d57212b8878",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 1, kernel_size=4, stride=1, padding=0),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf3a8cb-66a3-479f-a60c-d5b2b165be0d",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4862b10-366f-4b2b-915d-8a4366e0d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf8bda44-a2ad-4da4-8654-f6c51e1e0d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50], Step [0/7038], D Loss: 0.7154467105865479, G Loss: 0.7505959868431091\n",
      "Epoch [0/50], Step [100/7038], D Loss: 0.5808931589126587, G Loss: 0.8234001994132996\n",
      "Epoch [0/50], Step [200/7038], D Loss: 0.6623374223709106, G Loss: 0.8591057062149048\n",
      "Epoch [0/50], Step [300/7038], D Loss: 0.6844042539596558, G Loss: 0.7739900946617126\n",
      "Epoch [0/50], Step [400/7038], D Loss: 0.6526572704315186, G Loss: 0.8366765379905701\n",
      "Epoch [0/50], Step [500/7038], D Loss: 0.5689939260482788, G Loss: 0.9517291188240051\n",
      "Epoch [0/50], Step [600/7038], D Loss: 0.6554127931594849, G Loss: 0.8152122497558594\n",
      "Epoch [0/50], Step [700/7038], D Loss: 0.6952806711196899, G Loss: 0.7639557123184204\n",
      "Epoch [0/50], Step [800/7038], D Loss: 0.6154552698135376, G Loss: 0.8222744464874268\n",
      "Epoch [0/50], Step [900/7038], D Loss: 0.5528801083564758, G Loss: 0.8823978304862976\n",
      "Epoch [0/50], Step [1000/7038], D Loss: 0.5365228652954102, G Loss: 1.0472447872161865\n",
      "Epoch [0/50], Step [1100/7038], D Loss: 0.49429547786712646, G Loss: 1.2555068731307983\n",
      "Epoch [0/50], Step [1200/7038], D Loss: 0.5444107055664062, G Loss: 1.0716030597686768\n",
      "Epoch [0/50], Step [1300/7038], D Loss: 0.4672200679779053, G Loss: 1.068665623664856\n",
      "Epoch [0/50], Step [1400/7038], D Loss: 0.3551255464553833, G Loss: 1.5897634029388428\n",
      "Epoch [0/50], Step [1500/7038], D Loss: 0.4626973271369934, G Loss: 1.411206603050232\n",
      "Epoch [0/50], Step [1600/7038], D Loss: 0.779226541519165, G Loss: 1.2912451028823853\n",
      "Epoch [0/50], Step [1700/7038], D Loss: 0.48381680250167847, G Loss: 1.371251106262207\n",
      "Epoch [0/50], Step [1800/7038], D Loss: 0.41954898834228516, G Loss: 1.280473232269287\n",
      "Epoch [0/50], Step [1900/7038], D Loss: 0.5616124868392944, G Loss: 1.9040334224700928\n",
      "Epoch [0/50], Step [2000/7038], D Loss: 0.39805829524993896, G Loss: 1.3876794576644897\n",
      "Epoch [0/50], Step [2100/7038], D Loss: 0.36316752433776855, G Loss: 1.5133469104766846\n",
      "Epoch [0/50], Step [2200/7038], D Loss: 0.4028187692165375, G Loss: 1.547808289527893\n",
      "Epoch [0/50], Step [2300/7038], D Loss: 0.37836402654647827, G Loss: 1.4933648109436035\n",
      "Epoch [0/50], Step [2400/7038], D Loss: 0.40732070803642273, G Loss: 1.4039770364761353\n",
      "Epoch [0/50], Step [2500/7038], D Loss: 0.36227914690971375, G Loss: 1.5794813632965088\n",
      "Epoch [0/50], Step [2600/7038], D Loss: 0.4144099950790405, G Loss: 1.3695261478424072\n",
      "Epoch [0/50], Step [2700/7038], D Loss: 0.3139485716819763, G Loss: 1.718340277671814\n",
      "Epoch [0/50], Step [2800/7038], D Loss: 0.23615935444831848, G Loss: 1.8891493082046509\n",
      "Epoch [0/50], Step [2900/7038], D Loss: 0.3055572211742401, G Loss: 1.6323254108428955\n",
      "Epoch [0/50], Step [3000/7038], D Loss: 0.352062463760376, G Loss: 2.1720731258392334\n",
      "Epoch [0/50], Step [3100/7038], D Loss: 0.3362475633621216, G Loss: 1.5419018268585205\n",
      "Epoch [0/50], Step [3200/7038], D Loss: 0.3527172803878784, G Loss: 1.649936556816101\n",
      "Epoch [0/50], Step [3300/7038], D Loss: 0.3225036859512329, G Loss: 2.2229509353637695\n",
      "Epoch [0/50], Step [3400/7038], D Loss: 0.2140447497367859, G Loss: 2.3841333389282227\n",
      "Epoch [0/50], Step [3500/7038], D Loss: 0.18183684349060059, G Loss: 2.488103151321411\n",
      "Epoch [0/50], Step [3600/7038], D Loss: 0.3463915288448334, G Loss: 1.820302128791809\n",
      "Epoch [0/50], Step [3700/7038], D Loss: 0.6253038048744202, G Loss: 1.4533214569091797\n",
      "Epoch [0/50], Step [3800/7038], D Loss: 0.34582245349884033, G Loss: 1.6393448114395142\n",
      "Epoch [0/50], Step [3900/7038], D Loss: 0.2435624599456787, G Loss: 2.0275018215179443\n",
      "Epoch [0/50], Step [4000/7038], D Loss: 0.3991127610206604, G Loss: 1.5383939743041992\n",
      "Epoch [0/50], Step [4100/7038], D Loss: 0.4620344042778015, G Loss: 1.2430617809295654\n",
      "Epoch [0/50], Step [4200/7038], D Loss: 0.2556552290916443, G Loss: 2.4375083446502686\n",
      "Epoch [0/50], Step [4300/7038], D Loss: 0.3474314212799072, G Loss: 1.8053598403930664\n",
      "Epoch [0/50], Step [4400/7038], D Loss: 0.3538011908531189, G Loss: 1.7449206113815308\n",
      "Epoch [0/50], Step [4500/7038], D Loss: 0.38114166259765625, G Loss: 2.0854196548461914\n",
      "Epoch [0/50], Step [4600/7038], D Loss: 0.43653005361557007, G Loss: 1.7239371538162231\n",
      "Epoch [0/50], Step [4700/7038], D Loss: 0.3416588306427002, G Loss: 1.9029382467269897\n",
      "Epoch [0/50], Step [4800/7038], D Loss: 0.4094676375389099, G Loss: 1.6200883388519287\n",
      "Epoch [0/50], Step [4900/7038], D Loss: 0.37136152386665344, G Loss: 1.436933159828186\n",
      "Epoch [0/50], Step [5000/7038], D Loss: 0.4878905415534973, G Loss: 1.3816136121749878\n",
      "Epoch [0/50], Step [5100/7038], D Loss: 0.2870686650276184, G Loss: 2.1222503185272217\n",
      "Epoch [0/50], Step [5200/7038], D Loss: 0.38143986463546753, G Loss: 1.9225705862045288\n",
      "Epoch [0/50], Step [5300/7038], D Loss: 0.6851756572723389, G Loss: 2.8938446044921875\n",
      "Epoch [0/50], Step [5400/7038], D Loss: 0.3969687223434448, G Loss: 1.3600364923477173\n",
      "Epoch [0/50], Step [5500/7038], D Loss: 0.396921843290329, G Loss: 1.5701676607131958\n",
      "Epoch [0/50], Step [5600/7038], D Loss: 0.5556326508522034, G Loss: 1.8495895862579346\n",
      "Epoch [0/50], Step [5700/7038], D Loss: 0.47520631551742554, G Loss: 1.6554293632507324\n",
      "Epoch [0/50], Step [5800/7038], D Loss: 0.37113070487976074, G Loss: 1.6230164766311646\n",
      "Epoch [0/50], Step [5900/7038], D Loss: 0.4314921498298645, G Loss: 1.8327382802963257\n",
      "Epoch [0/50], Step [6000/7038], D Loss: 0.46129414439201355, G Loss: 1.504075288772583\n",
      "Epoch [0/50], Step [6100/7038], D Loss: 0.47721561789512634, G Loss: 1.6716824769973755\n",
      "Epoch [0/50], Step [6200/7038], D Loss: 0.262746661901474, G Loss: 2.2561933994293213\n",
      "Epoch [0/50], Step [6300/7038], D Loss: 0.5653191208839417, G Loss: 1.2651578187942505\n",
      "Epoch [0/50], Step [6400/7038], D Loss: 0.3752782940864563, G Loss: 1.5985714197158813\n",
      "Epoch [0/50], Step [6500/7038], D Loss: 0.5291778445243835, G Loss: 1.0095971822738647\n",
      "Epoch [0/50], Step [6600/7038], D Loss: 0.3869434893131256, G Loss: 1.6948953866958618\n",
      "Epoch [0/50], Step [6700/7038], D Loss: 0.41489261388778687, G Loss: 1.4887540340423584\n",
      "Epoch [0/50], Step [6800/7038], D Loss: 0.35174989700317383, G Loss: 2.3817265033721924\n",
      "Epoch [0/50], Step [6900/7038], D Loss: 0.39759087562561035, G Loss: 1.4312444925308228\n",
      "Epoch [0/50], Step [7000/7038], D Loss: 1.0666022300720215, G Loss: 1.8970577716827393\n",
      "Epoch [1/50], Step [0/7038], D Loss: 0.39869067072868347, G Loss: 1.640676498413086\n",
      "Epoch [1/50], Step [100/7038], D Loss: 0.2815816402435303, G Loss: 1.699690341949463\n",
      "Epoch [1/50], Step [200/7038], D Loss: 0.42913317680358887, G Loss: 1.3411219120025635\n",
      "Epoch [1/50], Step [300/7038], D Loss: 0.29740872979164124, G Loss: 1.7384926080703735\n",
      "Epoch [1/50], Step [400/7038], D Loss: 0.3953070044517517, G Loss: 1.4788424968719482\n",
      "Epoch [1/50], Step [500/7038], D Loss: 0.9141430854797363, G Loss: 1.6563290357589722\n",
      "Epoch [1/50], Step [600/7038], D Loss: 0.35583895444869995, G Loss: 1.4152122735977173\n",
      "Epoch [1/50], Step [700/7038], D Loss: 0.25846797227859497, G Loss: 1.931972622871399\n",
      "Epoch [1/50], Step [800/7038], D Loss: 0.48207908868789673, G Loss: 1.441634178161621\n",
      "Epoch [1/50], Step [900/7038], D Loss: 0.36084312200546265, G Loss: 1.8155295848846436\n",
      "Epoch [1/50], Step [1000/7038], D Loss: 0.36701393127441406, G Loss: 1.5088255405426025\n",
      "Epoch [1/50], Step [1100/7038], D Loss: 0.4839380979537964, G Loss: 2.207578659057617\n",
      "Epoch [1/50], Step [1200/7038], D Loss: 0.4399178922176361, G Loss: 1.7519733905792236\n",
      "Epoch [1/50], Step [1300/7038], D Loss: 0.30649787187576294, G Loss: 1.6984678506851196\n",
      "Epoch [1/50], Step [1400/7038], D Loss: 0.31861191987991333, G Loss: 1.876028060913086\n",
      "Epoch [1/50], Step [1500/7038], D Loss: 0.4801790118217468, G Loss: 1.1279010772705078\n",
      "Epoch [1/50], Step [1600/7038], D Loss: 0.2980400025844574, G Loss: 1.4836242198944092\n",
      "Epoch [1/50], Step [1700/7038], D Loss: 0.3928483724594116, G Loss: 1.2856380939483643\n",
      "Epoch [1/50], Step [1800/7038], D Loss: 0.4494161605834961, G Loss: 1.3654030561447144\n",
      "Epoch [1/50], Step [1900/7038], D Loss: 0.34404268860816956, G Loss: 1.4816316366195679\n",
      "Epoch [1/50], Step [2000/7038], D Loss: 0.33898666501045227, G Loss: 1.6342053413391113\n",
      "Epoch [1/50], Step [2100/7038], D Loss: 0.3456834554672241, G Loss: 1.4895204305648804\n",
      "Epoch [1/50], Step [2200/7038], D Loss: 0.4296708106994629, G Loss: 1.679016351699829\n",
      "Epoch [1/50], Step [2300/7038], D Loss: 0.4317023754119873, G Loss: 1.1997042894363403\n",
      "Epoch [1/50], Step [2400/7038], D Loss: 0.4012187123298645, G Loss: 1.2766220569610596\n",
      "Epoch [1/50], Step [2500/7038], D Loss: 0.5372829437255859, G Loss: 1.527560830116272\n",
      "Epoch [1/50], Step [2600/7038], D Loss: 0.4718111753463745, G Loss: 1.7650649547576904\n",
      "Epoch [1/50], Step [2700/7038], D Loss: 0.3374764323234558, G Loss: 1.3732633590698242\n",
      "Epoch [1/50], Step [2800/7038], D Loss: 0.4816627502441406, G Loss: 1.5638453960418701\n",
      "Epoch [1/50], Step [2900/7038], D Loss: 0.47374022006988525, G Loss: 1.4998602867126465\n",
      "Epoch [1/50], Step [3000/7038], D Loss: 0.3909493386745453, G Loss: 1.849778413772583\n",
      "Epoch [1/50], Step [3100/7038], D Loss: 0.4488376975059509, G Loss: 1.5468826293945312\n",
      "Epoch [1/50], Step [3200/7038], D Loss: 0.3867826759815216, G Loss: 1.4866127967834473\n",
      "Epoch [1/50], Step [3300/7038], D Loss: 0.5145050883293152, G Loss: 1.2411128282546997\n",
      "Epoch [1/50], Step [3400/7038], D Loss: 0.4720515310764313, G Loss: 1.9002046585083008\n",
      "Epoch [1/50], Step [3500/7038], D Loss: 0.6526764631271362, G Loss: 1.375864863395691\n",
      "Epoch [1/50], Step [3600/7038], D Loss: 0.4864795207977295, G Loss: 1.2138890027999878\n",
      "Epoch [1/50], Step [3700/7038], D Loss: 0.3843955993652344, G Loss: 1.6747548580169678\n",
      "Epoch [1/50], Step [3800/7038], D Loss: 0.6262533664703369, G Loss: 2.09580659866333\n",
      "Epoch [1/50], Step [3900/7038], D Loss: 0.4127611517906189, G Loss: 1.9851757287979126\n",
      "Epoch [1/50], Step [4000/7038], D Loss: 0.3691592514514923, G Loss: 1.4790643453598022\n",
      "Epoch [1/50], Step [4100/7038], D Loss: 0.2955986559391022, G Loss: 1.4935005903244019\n",
      "Epoch [1/50], Step [4200/7038], D Loss: 0.3597070574760437, G Loss: 1.5561561584472656\n",
      "Epoch [1/50], Step [4300/7038], D Loss: 0.31231939792633057, G Loss: 1.8286340236663818\n",
      "Epoch [1/50], Step [4400/7038], D Loss: 0.4761534333229065, G Loss: 1.5589125156402588\n",
      "Epoch [1/50], Step [4500/7038], D Loss: 0.42542219161987305, G Loss: 1.194370985031128\n",
      "Epoch [1/50], Step [4600/7038], D Loss: 0.49715161323547363, G Loss: 1.301539421081543\n",
      "Epoch [1/50], Step [4700/7038], D Loss: 0.7474842071533203, G Loss: 1.405033826828003\n",
      "Epoch [1/50], Step [4800/7038], D Loss: 0.23914878070354462, G Loss: 2.3889846801757812\n",
      "Epoch [1/50], Step [4900/7038], D Loss: 0.3385924696922302, G Loss: 2.210073709487915\n",
      "Epoch [1/50], Step [5000/7038], D Loss: 0.27554768323898315, G Loss: 1.8362014293670654\n",
      "Epoch [1/50], Step [5100/7038], D Loss: 0.31396859884262085, G Loss: 1.7793492078781128\n",
      "Epoch [1/50], Step [5200/7038], D Loss: 0.30727002024650574, G Loss: 1.541627049446106\n",
      "Epoch [1/50], Step [5300/7038], D Loss: 0.20000216364860535, G Loss: 1.7809643745422363\n",
      "Epoch [1/50], Step [5400/7038], D Loss: 0.4564903974533081, G Loss: 1.1937744617462158\n",
      "Epoch [1/50], Step [5500/7038], D Loss: 0.7054757475852966, G Loss: 1.4573012590408325\n",
      "Epoch [1/50], Step [5600/7038], D Loss: 0.43032121658325195, G Loss: 1.7075141668319702\n",
      "Epoch [1/50], Step [5700/7038], D Loss: 0.5466875433921814, G Loss: 1.272757649421692\n",
      "Epoch [1/50], Step [5800/7038], D Loss: 0.3285207152366638, G Loss: 1.5980827808380127\n",
      "Epoch [1/50], Step [5900/7038], D Loss: 0.5258304476737976, G Loss: 1.4760141372680664\n",
      "Epoch [1/50], Step [6000/7038], D Loss: 0.3204725384712219, G Loss: 1.6571784019470215\n",
      "Epoch [1/50], Step [6100/7038], D Loss: 0.2518027126789093, G Loss: 2.065155029296875\n",
      "Epoch [1/50], Step [6200/7038], D Loss: 0.34699180722236633, G Loss: 1.4288991689682007\n",
      "Epoch [1/50], Step [6300/7038], D Loss: 0.39651036262512207, G Loss: 1.352966547012329\n",
      "Epoch [1/50], Step [6400/7038], D Loss: 0.4181795120239258, G Loss: 1.2473636865615845\n",
      "Epoch [1/50], Step [6500/7038], D Loss: 0.5564335584640503, G Loss: 1.98159921169281\n",
      "Epoch [1/50], Step [6600/7038], D Loss: 0.34947630763053894, G Loss: 1.5731115341186523\n",
      "Epoch [1/50], Step [6700/7038], D Loss: 0.2953540086746216, G Loss: 2.060739278793335\n",
      "Epoch [1/50], Step [6800/7038], D Loss: 0.4868003726005554, G Loss: 1.8459523916244507\n",
      "Epoch [1/50], Step [6900/7038], D Loss: 0.6493172645568848, G Loss: 1.3711966276168823\n",
      "Epoch [1/50], Step [7000/7038], D Loss: 0.5391398072242737, G Loss: 1.8148493766784668\n",
      "Epoch [2/50], Step [0/7038], D Loss: 0.6970865726470947, G Loss: 1.581810474395752\n",
      "Epoch [2/50], Step [100/7038], D Loss: 0.32791876792907715, G Loss: 1.841253638267517\n",
      "Epoch [2/50], Step [200/7038], D Loss: 0.3575049638748169, G Loss: 1.6243641376495361\n",
      "Epoch [2/50], Step [300/7038], D Loss: 0.4289766550064087, G Loss: 1.3783200979232788\n",
      "Epoch [2/50], Step [400/7038], D Loss: 0.5592197179794312, G Loss: 1.3281468152999878\n",
      "Epoch [2/50], Step [500/7038], D Loss: 0.3145209848880768, G Loss: 1.9147717952728271\n",
      "Epoch [2/50], Step [600/7038], D Loss: 0.34932196140289307, G Loss: 1.5468158721923828\n",
      "Epoch [2/50], Step [700/7038], D Loss: 0.38119110465049744, G Loss: 1.6049789190292358\n",
      "Epoch [2/50], Step [800/7038], D Loss: 0.3143261671066284, G Loss: 2.3628761768341064\n",
      "Epoch [2/50], Step [900/7038], D Loss: 0.4791133403778076, G Loss: 2.1378302574157715\n",
      "Epoch [2/50], Step [1000/7038], D Loss: 0.5680288076400757, G Loss: 1.0577038526535034\n",
      "Epoch [2/50], Step [1100/7038], D Loss: 0.544922411441803, G Loss: 1.5001522302627563\n",
      "Epoch [2/50], Step [1200/7038], D Loss: 0.4279477596282959, G Loss: 1.559338927268982\n",
      "Epoch [2/50], Step [1300/7038], D Loss: 0.3440900146961212, G Loss: 2.0209155082702637\n",
      "Epoch [2/50], Step [1400/7038], D Loss: 0.6542665958404541, G Loss: 1.2657133340835571\n",
      "Epoch [2/50], Step [1500/7038], D Loss: 0.19493743777275085, G Loss: 2.4587514400482178\n",
      "Epoch [2/50], Step [1600/7038], D Loss: 0.6531121730804443, G Loss: 1.2924385070800781\n",
      "Epoch [2/50], Step [1700/7038], D Loss: 0.46663177013397217, G Loss: 1.8130161762237549\n",
      "Epoch [2/50], Step [1800/7038], D Loss: 0.5482341051101685, G Loss: 1.4122580289840698\n",
      "Epoch [2/50], Step [1900/7038], D Loss: 0.7080836296081543, G Loss: 1.7633055448532104\n",
      "Epoch [2/50], Step [2000/7038], D Loss: 0.5935349464416504, G Loss: 1.233429193496704\n",
      "Epoch [2/50], Step [2100/7038], D Loss: 0.4485176205635071, G Loss: 1.4255733489990234\n",
      "Epoch [2/50], Step [2200/7038], D Loss: 0.41846251487731934, G Loss: 1.557816743850708\n",
      "Epoch [2/50], Step [2300/7038], D Loss: 0.5591415166854858, G Loss: 1.487204670906067\n",
      "Epoch [2/50], Step [2400/7038], D Loss: 0.34443122148513794, G Loss: 1.5727248191833496\n",
      "Epoch [2/50], Step [2500/7038], D Loss: 0.364818811416626, G Loss: 1.8032009601593018\n",
      "Epoch [2/50], Step [2600/7038], D Loss: 0.36280471086502075, G Loss: 1.4021246433258057\n",
      "Epoch [2/50], Step [2700/7038], D Loss: 0.41067150235176086, G Loss: 1.6621978282928467\n",
      "Epoch [2/50], Step [2800/7038], D Loss: 0.49264585971832275, G Loss: 1.399903416633606\n",
      "Epoch [2/50], Step [2900/7038], D Loss: 0.3718636631965637, G Loss: 1.6831871271133423\n",
      "Epoch [2/50], Step [3000/7038], D Loss: 0.36888039112091064, G Loss: 1.6075477600097656\n",
      "Epoch [2/50], Step [3100/7038], D Loss: 0.4489785134792328, G Loss: 1.738481044769287\n",
      "Epoch [2/50], Step [3200/7038], D Loss: 0.4680018424987793, G Loss: 1.3841209411621094\n",
      "Epoch [2/50], Step [3300/7038], D Loss: 0.6463014483451843, G Loss: 1.0659053325653076\n",
      "Epoch [2/50], Step [3400/7038], D Loss: 0.5940243005752563, G Loss: 0.5781538486480713\n",
      "Epoch [2/50], Step [3500/7038], D Loss: 0.25953981280326843, G Loss: 2.170166254043579\n",
      "Epoch [2/50], Step [3600/7038], D Loss: 0.500373125076294, G Loss: 1.571372389793396\n",
      "Epoch [2/50], Step [3700/7038], D Loss: 0.31090492010116577, G Loss: 1.6650221347808838\n",
      "Epoch [2/50], Step [3800/7038], D Loss: 0.363797128200531, G Loss: 1.354461431503296\n",
      "Epoch [2/50], Step [3900/7038], D Loss: 0.5761756300926208, G Loss: 2.047981023788452\n",
      "Epoch [2/50], Step [4000/7038], D Loss: 0.3633835017681122, G Loss: 1.1938560009002686\n",
      "Epoch [2/50], Step [4100/7038], D Loss: 0.4691523313522339, G Loss: 1.332507610321045\n",
      "Epoch [2/50], Step [4200/7038], D Loss: 0.42803722620010376, G Loss: 1.9323670864105225\n",
      "Epoch [2/50], Step [4300/7038], D Loss: 0.39052581787109375, G Loss: 1.9903138875961304\n",
      "Epoch [2/50], Step [4400/7038], D Loss: 0.6438848376274109, G Loss: 1.622782826423645\n",
      "Epoch [2/50], Step [4500/7038], D Loss: 0.4315463900566101, G Loss: 1.4078619480133057\n",
      "Epoch [2/50], Step [4600/7038], D Loss: 0.5960120558738708, G Loss: 1.4560256004333496\n",
      "Epoch [2/50], Step [4700/7038], D Loss: 0.555759072303772, G Loss: 1.2738291025161743\n",
      "Epoch [2/50], Step [4800/7038], D Loss: 0.4139353036880493, G Loss: 1.840382695198059\n",
      "Epoch [2/50], Step [4900/7038], D Loss: 0.4406111240386963, G Loss: 1.2826013565063477\n",
      "Epoch [2/50], Step [5000/7038], D Loss: 0.5152490139007568, G Loss: 1.180764079093933\n",
      "Epoch [2/50], Step [5100/7038], D Loss: 0.365750253200531, G Loss: 1.4580421447753906\n",
      "Epoch [2/50], Step [5200/7038], D Loss: 0.35732370615005493, G Loss: 1.8199918270111084\n",
      "Epoch [2/50], Step [5300/7038], D Loss: 0.23383092880249023, G Loss: 1.9401209354400635\n",
      "Epoch [2/50], Step [5400/7038], D Loss: 0.5696777701377869, G Loss: 1.9224835634231567\n",
      "Epoch [2/50], Step [5500/7038], D Loss: 0.3851625323295593, G Loss: 1.7988758087158203\n",
      "Epoch [2/50], Step [5600/7038], D Loss: 0.560207724571228, G Loss: 1.0369608402252197\n",
      "Epoch [2/50], Step [5700/7038], D Loss: 0.3472099304199219, G Loss: 2.8351850509643555\n",
      "Epoch [2/50], Step [5800/7038], D Loss: 0.4161016643047333, G Loss: 1.8781485557556152\n",
      "Epoch [2/50], Step [5900/7038], D Loss: 0.4683234691619873, G Loss: 1.5117416381835938\n",
      "Epoch [2/50], Step [6000/7038], D Loss: 0.4913930892944336, G Loss: 1.2771044969558716\n",
      "Epoch [2/50], Step [6100/7038], D Loss: 0.3967123031616211, G Loss: 1.8696037530899048\n",
      "Epoch [2/50], Step [6200/7038], D Loss: 0.4070814847946167, G Loss: 1.6052149534225464\n",
      "Epoch [2/50], Step [6300/7038], D Loss: 0.3102504014968872, G Loss: 1.8603533506393433\n",
      "Epoch [2/50], Step [6400/7038], D Loss: 0.5565048456192017, G Loss: 2.5258588790893555\n",
      "Epoch [2/50], Step [6500/7038], D Loss: 0.7202574014663696, G Loss: 0.9615945219993591\n",
      "Epoch [2/50], Step [6600/7038], D Loss: 0.5632251501083374, G Loss: 1.6107287406921387\n",
      "Epoch [2/50], Step [6700/7038], D Loss: 0.4078860282897949, G Loss: 1.8643556833267212\n",
      "Epoch [2/50], Step [6800/7038], D Loss: 0.44982415437698364, G Loss: 1.503707766532898\n",
      "Epoch [2/50], Step [6900/7038], D Loss: 0.4885830283164978, G Loss: 1.9458719491958618\n",
      "Epoch [2/50], Step [7000/7038], D Loss: 0.5338176488876343, G Loss: 1.3468819856643677\n",
      "Epoch [3/50], Step [0/7038], D Loss: 0.517296314239502, G Loss: 1.8079637289047241\n",
      "Epoch [3/50], Step [100/7038], D Loss: 0.5097863078117371, G Loss: 1.4666482210159302\n",
      "Epoch [3/50], Step [200/7038], D Loss: 0.6489613652229309, G Loss: 1.4384809732437134\n",
      "Epoch [3/50], Step [300/7038], D Loss: 0.31685349345207214, G Loss: 1.344889521598816\n",
      "Epoch [3/50], Step [400/7038], D Loss: 0.4253802001476288, G Loss: 1.8989962339401245\n",
      "Epoch [3/50], Step [500/7038], D Loss: 0.27391213178634644, G Loss: 1.8200548887252808\n",
      "Epoch [3/50], Step [600/7038], D Loss: 0.3030931353569031, G Loss: 1.892244577407837\n",
      "Epoch [3/50], Step [700/7038], D Loss: 0.2896130681037903, G Loss: 1.6997483968734741\n",
      "Epoch [3/50], Step [800/7038], D Loss: 0.425189346075058, G Loss: 1.372457504272461\n",
      "Epoch [3/50], Step [900/7038], D Loss: 0.40805280208587646, G Loss: 1.5489593744277954\n",
      "Epoch [3/50], Step [1000/7038], D Loss: 0.41667109727859497, G Loss: 1.3137534856796265\n",
      "Epoch [3/50], Step [1100/7038], D Loss: 0.32378846406936646, G Loss: 1.50584077835083\n",
      "Epoch [3/50], Step [1200/7038], D Loss: 0.3587932586669922, G Loss: 2.049600601196289\n",
      "Epoch [3/50], Step [1300/7038], D Loss: 0.5752367973327637, G Loss: 1.4038364887237549\n",
      "Epoch [3/50], Step [1400/7038], D Loss: 0.44963040947914124, G Loss: 1.6492329835891724\n",
      "Epoch [3/50], Step [1500/7038], D Loss: 0.3879143297672272, G Loss: 1.295538067817688\n",
      "Epoch [3/50], Step [1600/7038], D Loss: 0.4357292354106903, G Loss: 1.9549345970153809\n",
      "Epoch [3/50], Step [1700/7038], D Loss: 0.28355759382247925, G Loss: 1.6708718538284302\n",
      "Epoch [3/50], Step [1800/7038], D Loss: 0.46087735891342163, G Loss: 1.5363770723342896\n",
      "Epoch [3/50], Step [1900/7038], D Loss: 0.3752288818359375, G Loss: 1.6500478982925415\n",
      "Epoch [3/50], Step [2000/7038], D Loss: 0.4528655409812927, G Loss: 1.8394523859024048\n",
      "Epoch [3/50], Step [2100/7038], D Loss: 0.38471898436546326, G Loss: 1.3929585218429565\n",
      "Epoch [3/50], Step [2200/7038], D Loss: 0.38699573278427124, G Loss: 1.2603583335876465\n",
      "Epoch [3/50], Step [2300/7038], D Loss: 0.390835165977478, G Loss: 1.7044326066970825\n",
      "Epoch [3/50], Step [2400/7038], D Loss: 0.4297983944416046, G Loss: 1.3649213314056396\n",
      "Epoch [3/50], Step [2500/7038], D Loss: 0.44233524799346924, G Loss: 1.9888050556182861\n",
      "Epoch [3/50], Step [2600/7038], D Loss: 0.38402611017227173, G Loss: 1.722758173942566\n",
      "Epoch [3/50], Step [2700/7038], D Loss: 0.4684826731681824, G Loss: 1.2242540121078491\n",
      "Epoch [3/50], Step [2800/7038], D Loss: 0.47616463899612427, G Loss: 1.6655160188674927\n",
      "Epoch [3/50], Step [2900/7038], D Loss: 0.4786052107810974, G Loss: 1.5174405574798584\n",
      "Epoch [3/50], Step [3000/7038], D Loss: 0.3905644118785858, G Loss: 1.9905328750610352\n",
      "Epoch [3/50], Step [3100/7038], D Loss: 0.4480430483818054, G Loss: 1.5637859106063843\n",
      "Epoch [3/50], Step [3200/7038], D Loss: 0.34270337224006653, G Loss: 1.4323972463607788\n",
      "Epoch [3/50], Step [3300/7038], D Loss: 0.4780857563018799, G Loss: 1.5911229848861694\n",
      "Epoch [3/50], Step [3400/7038], D Loss: 0.3785552382469177, G Loss: 1.381753921508789\n",
      "Epoch [3/50], Step [3500/7038], D Loss: 0.7734665870666504, G Loss: 1.3606520891189575\n",
      "Epoch [3/50], Step [3600/7038], D Loss: 0.2929297089576721, G Loss: 1.8387893438339233\n",
      "Epoch [3/50], Step [3700/7038], D Loss: 0.6244397163391113, G Loss: 1.291017770767212\n",
      "Epoch [3/50], Step [3800/7038], D Loss: 0.508102536201477, G Loss: 1.2385413646697998\n",
      "Epoch [3/50], Step [3900/7038], D Loss: 0.45422589778900146, G Loss: 1.6721148490905762\n",
      "Epoch [3/50], Step [4000/7038], D Loss: 0.42319256067276, G Loss: 1.4303635358810425\n",
      "Epoch [3/50], Step [4100/7038], D Loss: 0.32163459062576294, G Loss: 1.9195772409439087\n",
      "Epoch [3/50], Step [4200/7038], D Loss: 0.6251033544540405, G Loss: 1.4174141883850098\n",
      "Epoch [3/50], Step [4300/7038], D Loss: 0.3202739357948303, G Loss: 1.569291114807129\n",
      "Epoch [3/50], Step [4400/7038], D Loss: 0.3156808912754059, G Loss: 1.2075738906860352\n",
      "Epoch [3/50], Step [4500/7038], D Loss: 0.5320557355880737, G Loss: 1.2316901683807373\n",
      "Epoch [3/50], Step [4600/7038], D Loss: 0.28573793172836304, G Loss: 1.7571375370025635\n",
      "Epoch [3/50], Step [4700/7038], D Loss: 0.4640255272388458, G Loss: 1.5418617725372314\n",
      "Epoch [3/50], Step [4800/7038], D Loss: 0.6341851353645325, G Loss: 0.9503766894340515\n",
      "Epoch [3/50], Step [4900/7038], D Loss: 0.19734814763069153, G Loss: 1.793809413909912\n",
      "Epoch [3/50], Step [5000/7038], D Loss: 0.6254780292510986, G Loss: 1.1446254253387451\n",
      "Epoch [3/50], Step [5100/7038], D Loss: 0.38208115100860596, G Loss: 2.0640461444854736\n",
      "Epoch [3/50], Step [5200/7038], D Loss: 0.43909168243408203, G Loss: 1.5803030729293823\n",
      "Epoch [3/50], Step [5300/7038], D Loss: 0.3227369785308838, G Loss: 1.7644062042236328\n",
      "Epoch [3/50], Step [5400/7038], D Loss: 0.30849844217300415, G Loss: 1.8108586072921753\n",
      "Epoch [3/50], Step [5500/7038], D Loss: 0.5261304378509521, G Loss: 1.5074504613876343\n",
      "Epoch [3/50], Step [5600/7038], D Loss: 0.431313693523407, G Loss: 1.2649445533752441\n",
      "Epoch [3/50], Step [5700/7038], D Loss: 0.6544331908226013, G Loss: 1.1511976718902588\n",
      "Epoch [3/50], Step [5800/7038], D Loss: 0.4920015335083008, G Loss: 1.3128421306610107\n",
      "Epoch [3/50], Step [5900/7038], D Loss: 0.6600669622421265, G Loss: 1.9762276411056519\n",
      "Epoch [3/50], Step [6000/7038], D Loss: 0.8064039945602417, G Loss: 1.9259861707687378\n",
      "Epoch [3/50], Step [6100/7038], D Loss: 0.5107726454734802, G Loss: 1.0632379055023193\n",
      "Epoch [3/50], Step [6200/7038], D Loss: 0.6709885597229004, G Loss: 0.9752803444862366\n",
      "Epoch [3/50], Step [6300/7038], D Loss: 0.40401512384414673, G Loss: 1.2638208866119385\n",
      "Epoch [3/50], Step [6400/7038], D Loss: 0.42572253942489624, G Loss: 1.269057273864746\n",
      "Epoch [3/50], Step [6500/7038], D Loss: 0.5392889976501465, G Loss: 1.5319218635559082\n",
      "Epoch [3/50], Step [6600/7038], D Loss: 0.3710489869117737, G Loss: 1.2864593267440796\n",
      "Epoch [3/50], Step [6700/7038], D Loss: 0.4136918783187866, G Loss: 1.344273328781128\n",
      "Epoch [3/50], Step [6800/7038], D Loss: 0.4075891375541687, G Loss: 1.6770280599594116\n",
      "Epoch [3/50], Step [6900/7038], D Loss: 0.3827417492866516, G Loss: 1.7644513845443726\n",
      "Epoch [3/50], Step [7000/7038], D Loss: 0.7573946118354797, G Loss: 1.715154767036438\n",
      "Epoch [4/50], Step [0/7038], D Loss: 0.3784436285495758, G Loss: 1.3892399072647095\n",
      "Epoch [4/50], Step [100/7038], D Loss: 0.6117883920669556, G Loss: 1.0765752792358398\n",
      "Epoch [4/50], Step [200/7038], D Loss: 0.4567030668258667, G Loss: 1.5268023014068604\n",
      "Epoch [4/50], Step [300/7038], D Loss: 0.5238924026489258, G Loss: 1.1470654010772705\n",
      "Epoch [4/50], Step [400/7038], D Loss: 0.5012728571891785, G Loss: 2.2396440505981445\n",
      "Epoch [4/50], Step [500/7038], D Loss: 0.5297824144363403, G Loss: 1.5357639789581299\n",
      "Epoch [4/50], Step [600/7038], D Loss: 0.39508986473083496, G Loss: 1.5222430229187012\n",
      "Epoch [4/50], Step [700/7038], D Loss: 0.39447256922721863, G Loss: 1.4201953411102295\n",
      "Epoch [4/50], Step [800/7038], D Loss: 0.36437374353408813, G Loss: 1.6924312114715576\n",
      "Epoch [4/50], Step [900/7038], D Loss: 0.37864476442337036, G Loss: 1.3697972297668457\n",
      "Epoch [4/50], Step [1000/7038], D Loss: 0.5748662352561951, G Loss: 1.1876206398010254\n",
      "Epoch [4/50], Step [1100/7038], D Loss: 0.3642190098762512, G Loss: 1.4670807123184204\n",
      "Epoch [4/50], Step [1200/7038], D Loss: 0.47428733110427856, G Loss: 1.5793914794921875\n",
      "Epoch [4/50], Step [1300/7038], D Loss: 0.5129975080490112, G Loss: 1.5273511409759521\n",
      "Epoch [4/50], Step [1400/7038], D Loss: 0.37728482484817505, G Loss: 1.3949154615402222\n",
      "Epoch [4/50], Step [1500/7038], D Loss: 0.288332998752594, G Loss: 1.7681562900543213\n",
      "Epoch [4/50], Step [1600/7038], D Loss: 0.33687931299209595, G Loss: 1.8240607976913452\n",
      "Epoch [4/50], Step [1700/7038], D Loss: 0.4233558773994446, G Loss: 1.3502488136291504\n",
      "Epoch [4/50], Step [1800/7038], D Loss: 0.546942949295044, G Loss: 1.7079834938049316\n",
      "Epoch [4/50], Step [1900/7038], D Loss: 0.4218950867652893, G Loss: 1.649651288986206\n",
      "Epoch [4/50], Step [2000/7038], D Loss: 0.652195930480957, G Loss: 1.4349427223205566\n",
      "Epoch [4/50], Step [2100/7038], D Loss: 0.5602681636810303, G Loss: 1.149060606956482\n",
      "Epoch [4/50], Step [2200/7038], D Loss: 0.5363318920135498, G Loss: 1.3754488229751587\n",
      "Epoch [4/50], Step [2300/7038], D Loss: 0.40082991123199463, G Loss: 1.4831552505493164\n",
      "Epoch [4/50], Step [2400/7038], D Loss: 0.3239012658596039, G Loss: 1.7049790620803833\n",
      "Epoch [4/50], Step [2500/7038], D Loss: 0.31690511107444763, G Loss: 1.6325786113739014\n",
      "Epoch [4/50], Step [2600/7038], D Loss: 0.47061920166015625, G Loss: 1.4533331394195557\n",
      "Epoch [4/50], Step [2700/7038], D Loss: 0.4120008945465088, G Loss: 1.3678960800170898\n",
      "Epoch [4/50], Step [2800/7038], D Loss: 0.24428662657737732, G Loss: 2.259587049484253\n",
      "Epoch [4/50], Step [2900/7038], D Loss: 0.4796915352344513, G Loss: 1.1602171659469604\n",
      "Epoch [4/50], Step [3000/7038], D Loss: 0.5182133316993713, G Loss: 1.2807188034057617\n",
      "Epoch [4/50], Step [3100/7038], D Loss: 0.5286470055580139, G Loss: 1.549686074256897\n",
      "Epoch [4/50], Step [3200/7038], D Loss: 0.6548017263412476, G Loss: 1.4355506896972656\n",
      "Epoch [4/50], Step [3300/7038], D Loss: 0.4984514117240906, G Loss: 1.0030485391616821\n",
      "Epoch [4/50], Step [3400/7038], D Loss: 0.5211371779441833, G Loss: 1.4793943166732788\n",
      "Epoch [4/50], Step [3500/7038], D Loss: 0.35007762908935547, G Loss: 1.512133240699768\n",
      "Epoch [4/50], Step [3600/7038], D Loss: 0.49887821078300476, G Loss: 1.5233232975006104\n",
      "Epoch [4/50], Step [3700/7038], D Loss: 0.5372376441955566, G Loss: 1.654178261756897\n",
      "Epoch [4/50], Step [3800/7038], D Loss: 0.386712908744812, G Loss: 1.535874605178833\n",
      "Epoch [4/50], Step [3900/7038], D Loss: 0.5810418128967285, G Loss: 0.8811313509941101\n",
      "Epoch [4/50], Step [4000/7038], D Loss: 0.6400444507598877, G Loss: 1.2137941122055054\n",
      "Epoch [4/50], Step [4100/7038], D Loss: 0.31411439180374146, G Loss: 1.9151049852371216\n",
      "Epoch [4/50], Step [4200/7038], D Loss: 0.40691128373146057, G Loss: 1.3158317804336548\n",
      "Epoch [4/50], Step [4300/7038], D Loss: 0.33301106095314026, G Loss: 1.4680534601211548\n",
      "Epoch [4/50], Step [4400/7038], D Loss: 0.3737894594669342, G Loss: 1.5893136262893677\n",
      "Epoch [4/50], Step [4500/7038], D Loss: 0.48875585198402405, G Loss: 1.2988046407699585\n",
      "Epoch [4/50], Step [4600/7038], D Loss: 0.4852362871170044, G Loss: 1.2122972011566162\n",
      "Epoch [4/50], Step [4700/7038], D Loss: 0.6992745399475098, G Loss: 1.2570812702178955\n",
      "Epoch [4/50], Step [4800/7038], D Loss: 0.5580940842628479, G Loss: 1.6306109428405762\n",
      "Epoch [4/50], Step [4900/7038], D Loss: 0.3922632038593292, G Loss: 1.6433987617492676\n",
      "Epoch [4/50], Step [5000/7038], D Loss: 0.6653799414634705, G Loss: 1.03355073928833\n",
      "Epoch [4/50], Step [5100/7038], D Loss: 0.30352097749710083, G Loss: 1.4961786270141602\n",
      "Epoch [4/50], Step [5200/7038], D Loss: 0.5973415374755859, G Loss: 1.218417763710022\n",
      "Epoch [4/50], Step [5300/7038], D Loss: 0.2520453631877899, G Loss: 1.8970121145248413\n",
      "Epoch [4/50], Step [5400/7038], D Loss: 0.45142364501953125, G Loss: 1.2928764820098877\n",
      "Epoch [4/50], Step [5500/7038], D Loss: 0.4771135747432709, G Loss: 1.3279608488082886\n",
      "Epoch [4/50], Step [5600/7038], D Loss: 0.3510182499885559, G Loss: 1.9063360691070557\n",
      "Epoch [4/50], Step [5700/7038], D Loss: 0.547049880027771, G Loss: 1.0222110748291016\n",
      "Epoch [4/50], Step [5800/7038], D Loss: 0.5021626949310303, G Loss: 1.6160457134246826\n",
      "Epoch [4/50], Step [5900/7038], D Loss: 0.4051659405231476, G Loss: 1.488281488418579\n",
      "Epoch [4/50], Step [6000/7038], D Loss: 0.3897607624530792, G Loss: 1.424513339996338\n",
      "Epoch [4/50], Step [6100/7038], D Loss: 0.7190736532211304, G Loss: 1.7349722385406494\n",
      "Epoch [4/50], Step [6200/7038], D Loss: 0.3960150182247162, G Loss: 1.9841188192367554\n",
      "Epoch [4/50], Step [6300/7038], D Loss: 0.4305102825164795, G Loss: 1.6649960279464722\n",
      "Epoch [4/50], Step [6400/7038], D Loss: 0.28481999039649963, G Loss: 1.5928996801376343\n",
      "Epoch [4/50], Step [6500/7038], D Loss: 0.5848280191421509, G Loss: 1.5419931411743164\n",
      "Epoch [4/50], Step [6600/7038], D Loss: 0.38403427600860596, G Loss: 1.666520357131958\n",
      "Epoch [4/50], Step [6700/7038], D Loss: 0.4204167425632477, G Loss: 1.457440972328186\n",
      "Epoch [4/50], Step [6800/7038], D Loss: 0.49421149492263794, G Loss: 1.787147879600525\n",
      "Epoch [4/50], Step [6900/7038], D Loss: 0.37347880005836487, G Loss: 1.2734805345535278\n",
      "Epoch [4/50], Step [7000/7038], D Loss: 0.4204068183898926, G Loss: 1.5706549882888794\n",
      "Epoch [5/50], Step [0/7038], D Loss: 0.466044545173645, G Loss: 1.276739478111267\n",
      "Epoch [5/50], Step [100/7038], D Loss: 0.690574049949646, G Loss: 1.2814828157424927\n",
      "Epoch [5/50], Step [200/7038], D Loss: 0.381793737411499, G Loss: 1.6261049509048462\n",
      "Epoch [5/50], Step [300/7038], D Loss: 0.406264066696167, G Loss: 1.690019130706787\n",
      "Epoch [5/50], Step [400/7038], D Loss: 0.4734935760498047, G Loss: 1.216387152671814\n",
      "Epoch [5/50], Step [500/7038], D Loss: 0.5726351737976074, G Loss: 1.301744818687439\n",
      "Epoch [5/50], Step [600/7038], D Loss: 0.4537409543991089, G Loss: 1.095819115638733\n",
      "Epoch [5/50], Step [700/7038], D Loss: 0.5278724431991577, G Loss: 1.322948932647705\n",
      "Epoch [5/50], Step [800/7038], D Loss: 0.47366100549697876, G Loss: 1.104143500328064\n",
      "Epoch [5/50], Step [900/7038], D Loss: 0.49377673864364624, G Loss: 1.3549708127975464\n",
      "Epoch [5/50], Step [1000/7038], D Loss: 0.35938596725463867, G Loss: 1.5207489728927612\n",
      "Epoch [5/50], Step [1100/7038], D Loss: 0.5306735038757324, G Loss: 1.1228241920471191\n",
      "Epoch [5/50], Step [1200/7038], D Loss: 0.7394923567771912, G Loss: 1.194177269935608\n",
      "Epoch [5/50], Step [1300/7038], D Loss: 0.33877474069595337, G Loss: 1.5441981554031372\n",
      "Epoch [5/50], Step [1400/7038], D Loss: 0.6925094723701477, G Loss: 1.576979160308838\n",
      "Epoch [5/50], Step [1500/7038], D Loss: 0.5337628722190857, G Loss: 1.3325042724609375\n",
      "Epoch [5/50], Step [1600/7038], D Loss: 0.4584394693374634, G Loss: 1.5855928659439087\n",
      "Epoch [5/50], Step [1700/7038], D Loss: 0.5904939770698547, G Loss: 1.3617918491363525\n",
      "Epoch [5/50], Step [1800/7038], D Loss: 0.5808335542678833, G Loss: 1.167467474937439\n",
      "Epoch [5/50], Step [1900/7038], D Loss: 0.4527781009674072, G Loss: 1.1093764305114746\n",
      "Epoch [5/50], Step [2000/7038], D Loss: 0.5311880707740784, G Loss: 1.571750283241272\n",
      "Epoch [5/50], Step [2100/7038], D Loss: 0.3702465295791626, G Loss: 1.6974284648895264\n",
      "Epoch [5/50], Step [2200/7038], D Loss: 0.3579191565513611, G Loss: 1.4850993156433105\n",
      "Epoch [5/50], Step [2300/7038], D Loss: 0.31034040451049805, G Loss: 1.9150747060775757\n",
      "Epoch [5/50], Step [2400/7038], D Loss: 0.4797338545322418, G Loss: 1.5992703437805176\n",
      "Epoch [5/50], Step [2500/7038], D Loss: 0.4114975333213806, G Loss: 1.4449598789215088\n",
      "Epoch [5/50], Step [2600/7038], D Loss: 0.45477429032325745, G Loss: 1.1968839168548584\n",
      "Epoch [5/50], Step [2700/7038], D Loss: 0.32529813051223755, G Loss: 1.6333308219909668\n",
      "Epoch [5/50], Step [2800/7038], D Loss: 0.6310602426528931, G Loss: 1.2849292755126953\n",
      "Epoch [5/50], Step [2900/7038], D Loss: 0.27721428871154785, G Loss: 1.9255702495574951\n",
      "Epoch [5/50], Step [3000/7038], D Loss: 0.5528738498687744, G Loss: 1.4821404218673706\n",
      "Epoch [5/50], Step [3100/7038], D Loss: 0.5736356973648071, G Loss: 1.0906219482421875\n",
      "Epoch [5/50], Step [3200/7038], D Loss: 0.5674458742141724, G Loss: 1.2074167728424072\n",
      "Epoch [5/50], Step [3300/7038], D Loss: 0.4109283685684204, G Loss: 1.2240443229675293\n",
      "Epoch [5/50], Step [3400/7038], D Loss: 0.5672228932380676, G Loss: 1.4549403190612793\n",
      "Epoch [5/50], Step [3500/7038], D Loss: 0.3779570460319519, G Loss: 1.26511812210083\n",
      "Epoch [5/50], Step [3600/7038], D Loss: 0.4381011724472046, G Loss: 1.3129063844680786\n",
      "Epoch [5/50], Step [3700/7038], D Loss: 0.4791871905326843, G Loss: 1.1692413091659546\n",
      "Epoch [5/50], Step [3800/7038], D Loss: 0.4235629439353943, G Loss: 1.383516788482666\n",
      "Epoch [5/50], Step [3900/7038], D Loss: 0.39950627088546753, G Loss: 1.5797253847122192\n",
      "Epoch [5/50], Step [4000/7038], D Loss: 0.46584680676460266, G Loss: 1.6865675449371338\n",
      "Epoch [5/50], Step [4100/7038], D Loss: 0.5517914295196533, G Loss: 0.9065445065498352\n",
      "Epoch [5/50], Step [4200/7038], D Loss: 0.30148592591285706, G Loss: 1.4505064487457275\n",
      "Epoch [5/50], Step [4300/7038], D Loss: 0.431205689907074, G Loss: 1.3732670545578003\n",
      "Epoch [5/50], Step [4400/7038], D Loss: 0.8363568782806396, G Loss: 1.416015386581421\n",
      "Epoch [5/50], Step [4500/7038], D Loss: 0.710529088973999, G Loss: 1.0139976739883423\n",
      "Epoch [5/50], Step [4600/7038], D Loss: 0.601799488067627, G Loss: 1.6739561557769775\n",
      "Epoch [5/50], Step [4700/7038], D Loss: 0.3564298748970032, G Loss: 1.4398303031921387\n",
      "Epoch [5/50], Step [4800/7038], D Loss: 0.5750485062599182, G Loss: 1.8379533290863037\n",
      "Epoch [5/50], Step [4900/7038], D Loss: 0.9300179481506348, G Loss: 2.3645966053009033\n",
      "Epoch [5/50], Step [5000/7038], D Loss: 0.47810471057891846, G Loss: 1.3042407035827637\n",
      "Epoch [5/50], Step [5100/7038], D Loss: 0.42472386360168457, G Loss: 1.178396224975586\n",
      "Epoch [5/50], Step [5200/7038], D Loss: 0.6323779821395874, G Loss: 1.36524498462677\n",
      "Epoch [5/50], Step [5300/7038], D Loss: 0.6979373097419739, G Loss: 1.1607788801193237\n",
      "Epoch [5/50], Step [5400/7038], D Loss: 0.22434112429618835, G Loss: 2.087512254714966\n",
      "Epoch [5/50], Step [5500/7038], D Loss: 0.3216535449028015, G Loss: 1.4634521007537842\n",
      "Epoch [5/50], Step [5600/7038], D Loss: 0.4418942928314209, G Loss: 1.3441157341003418\n",
      "Epoch [5/50], Step [5700/7038], D Loss: 0.529837429523468, G Loss: 1.5042716264724731\n",
      "Epoch [5/50], Step [5800/7038], D Loss: 0.6766108870506287, G Loss: 1.0849651098251343\n",
      "Epoch [5/50], Step [5900/7038], D Loss: 0.7233339548110962, G Loss: 0.8690096735954285\n",
      "Epoch [5/50], Step [6000/7038], D Loss: 0.388605535030365, G Loss: 1.2248072624206543\n",
      "Epoch [5/50], Step [6100/7038], D Loss: 0.2797112762928009, G Loss: 1.4334412813186646\n",
      "Epoch [5/50], Step [6200/7038], D Loss: 0.40870875120162964, G Loss: 1.5642355680465698\n",
      "Epoch [5/50], Step [6300/7038], D Loss: 0.5067406892776489, G Loss: 1.654865026473999\n",
      "Epoch [5/50], Step [6400/7038], D Loss: 0.553056001663208, G Loss: 1.050522804260254\n",
      "Epoch [5/50], Step [6500/7038], D Loss: 0.3105728030204773, G Loss: 1.530712604522705\n",
      "Epoch [5/50], Step [6600/7038], D Loss: 0.6671863794326782, G Loss: 1.752457857131958\n",
      "Epoch [5/50], Step [6700/7038], D Loss: 0.47714921832084656, G Loss: 1.776748776435852\n",
      "Epoch [5/50], Step [6800/7038], D Loss: 0.5536465048789978, G Loss: 1.753180742263794\n",
      "Epoch [5/50], Step [6900/7038], D Loss: 0.6402414441108704, G Loss: 1.2370295524597168\n",
      "Epoch [5/50], Step [7000/7038], D Loss: 0.14612457156181335, G Loss: 2.310319185256958\n",
      "Epoch [6/50], Step [0/7038], D Loss: 0.6190208196640015, G Loss: 1.4791250228881836\n",
      "Epoch [6/50], Step [100/7038], D Loss: 0.5400936603546143, G Loss: 1.3760603666305542\n",
      "Epoch [6/50], Step [200/7038], D Loss: 0.49542245268821716, G Loss: 1.9841939210891724\n",
      "Epoch [6/50], Step [300/7038], D Loss: 0.5031399726867676, G Loss: 1.2835508584976196\n",
      "Epoch [6/50], Step [400/7038], D Loss: 0.40329867601394653, G Loss: 1.4747616052627563\n",
      "Epoch [6/50], Step [500/7038], D Loss: 0.5217956304550171, G Loss: 1.4009288549423218\n",
      "Epoch [6/50], Step [600/7038], D Loss: 0.36238306760787964, G Loss: 1.4254913330078125\n",
      "Epoch [6/50], Step [700/7038], D Loss: 0.5444835424423218, G Loss: 1.1952736377716064\n",
      "Epoch [6/50], Step [800/7038], D Loss: 0.35224661231040955, G Loss: 1.8843512535095215\n",
      "Epoch [6/50], Step [900/7038], D Loss: 0.6922479271888733, G Loss: 1.7197457551956177\n",
      "Epoch [6/50], Step [1000/7038], D Loss: 0.3338567018508911, G Loss: 1.6719274520874023\n",
      "Epoch [6/50], Step [1100/7038], D Loss: 0.6793052554130554, G Loss: 2.2892558574676514\n",
      "Epoch [6/50], Step [1200/7038], D Loss: 0.589367151260376, G Loss: 1.620241403579712\n",
      "Epoch [6/50], Step [1300/7038], D Loss: 0.6385726928710938, G Loss: 1.1197528839111328\n",
      "Epoch [6/50], Step [1400/7038], D Loss: 0.7423161268234253, G Loss: 1.3734384775161743\n",
      "Epoch [6/50], Step [1500/7038], D Loss: 0.4080810546875, G Loss: 1.2543925046920776\n",
      "Epoch [6/50], Step [1600/7038], D Loss: 0.30946213006973267, G Loss: 1.5602750778198242\n",
      "Epoch [6/50], Step [1700/7038], D Loss: 0.4782615303993225, G Loss: 1.2930717468261719\n",
      "Epoch [6/50], Step [1800/7038], D Loss: 0.5071388483047485, G Loss: 1.3051096200942993\n",
      "Epoch [6/50], Step [1900/7038], D Loss: 0.24634450674057007, G Loss: 1.6298117637634277\n",
      "Epoch [6/50], Step [2000/7038], D Loss: 0.5485972762107849, G Loss: 1.1142947673797607\n",
      "Epoch [6/50], Step [2100/7038], D Loss: 0.4548532962799072, G Loss: 1.2697902917861938\n",
      "Epoch [6/50], Step [2200/7038], D Loss: 0.5757240056991577, G Loss: 1.781527042388916\n",
      "Epoch [6/50], Step [2300/7038], D Loss: 0.7212792634963989, G Loss: 1.5122666358947754\n",
      "Epoch [6/50], Step [2400/7038], D Loss: 0.5796896815299988, G Loss: 1.173581838607788\n",
      "Epoch [6/50], Step [2500/7038], D Loss: 0.6971378922462463, G Loss: 1.1720057725906372\n",
      "Epoch [6/50], Step [2600/7038], D Loss: 0.49518021941185, G Loss: 1.7427091598510742\n",
      "Epoch [6/50], Step [2700/7038], D Loss: 0.35762110352516174, G Loss: 1.458579659461975\n",
      "Epoch [6/50], Step [2800/7038], D Loss: 0.3342607021331787, G Loss: 1.6671454906463623\n",
      "Epoch [6/50], Step [2900/7038], D Loss: 0.47053104639053345, G Loss: 1.2844526767730713\n",
      "Epoch [6/50], Step [3000/7038], D Loss: 1.1156173944473267, G Loss: 1.4970035552978516\n",
      "Epoch [6/50], Step [3100/7038], D Loss: 0.5143730640411377, G Loss: 1.3030706644058228\n",
      "Epoch [6/50], Step [3200/7038], D Loss: 0.4139898419380188, G Loss: 1.4832053184509277\n",
      "Epoch [6/50], Step [3300/7038], D Loss: 0.4760799705982208, G Loss: 1.6094255447387695\n",
      "Epoch [6/50], Step [3400/7038], D Loss: 0.40585535764694214, G Loss: 1.3264766931533813\n",
      "Epoch [6/50], Step [3500/7038], D Loss: 0.5370935201644897, G Loss: 1.3681588172912598\n",
      "Epoch [6/50], Step [3600/7038], D Loss: 0.4880264401435852, G Loss: 1.2252227067947388\n",
      "Epoch [6/50], Step [3700/7038], D Loss: 0.5956273078918457, G Loss: 1.1008814573287964\n",
      "Epoch [6/50], Step [3800/7038], D Loss: 0.3471566438674927, G Loss: 1.755724310874939\n",
      "Epoch [6/50], Step [3900/7038], D Loss: 0.4089127779006958, G Loss: 1.7937723398208618\n",
      "Epoch [6/50], Step [4000/7038], D Loss: 0.638403058052063, G Loss: 1.0383155345916748\n",
      "Epoch [6/50], Step [4100/7038], D Loss: 0.4340301752090454, G Loss: 1.4125728607177734\n",
      "Epoch [6/50], Step [4200/7038], D Loss: 0.6114529371261597, G Loss: 0.9333611726760864\n",
      "Epoch [6/50], Step [4300/7038], D Loss: 0.3876025080680847, G Loss: 1.7073768377304077\n",
      "Epoch [6/50], Step [4400/7038], D Loss: 0.3890652358531952, G Loss: 1.2403525114059448\n",
      "Epoch [6/50], Step [4500/7038], D Loss: 0.6270755529403687, G Loss: 0.9757260680198669\n",
      "Epoch [6/50], Step [4600/7038], D Loss: 0.270615816116333, G Loss: 1.7363579273223877\n",
      "Epoch [6/50], Step [4700/7038], D Loss: 0.534276008605957, G Loss: 1.139036774635315\n",
      "Epoch [6/50], Step [4800/7038], D Loss: 0.45476606488227844, G Loss: 1.3740426301956177\n",
      "Epoch [6/50], Step [4900/7038], D Loss: 0.35360297560691833, G Loss: 1.5674673318862915\n",
      "Epoch [6/50], Step [5000/7038], D Loss: 0.48220112919807434, G Loss: 1.338476538658142\n",
      "Epoch [6/50], Step [5100/7038], D Loss: 0.3462655246257782, G Loss: 1.3656474351882935\n",
      "Epoch [6/50], Step [5200/7038], D Loss: 0.5298517942428589, G Loss: 1.5121359825134277\n",
      "Epoch [6/50], Step [5300/7038], D Loss: 0.3475727438926697, G Loss: 1.2367006540298462\n",
      "Epoch [6/50], Step [5400/7038], D Loss: 0.4574410617351532, G Loss: 1.2112332582473755\n",
      "Epoch [6/50], Step [5500/7038], D Loss: 0.5735121965408325, G Loss: 1.267757773399353\n",
      "Epoch [6/50], Step [5600/7038], D Loss: 0.3765103220939636, G Loss: 1.564685344696045\n",
      "Epoch [6/50], Step [5700/7038], D Loss: 0.6828548908233643, G Loss: 1.1572012901306152\n",
      "Epoch [6/50], Step [5800/7038], D Loss: 0.45605766773223877, G Loss: 1.5817078351974487\n",
      "Epoch [6/50], Step [5900/7038], D Loss: 0.263206422328949, G Loss: 1.6949827671051025\n",
      "Epoch [6/50], Step [6000/7038], D Loss: 0.5108051300048828, G Loss: 1.3136674165725708\n",
      "Epoch [6/50], Step [6100/7038], D Loss: 0.5284265875816345, G Loss: 1.1921025514602661\n",
      "Epoch [6/50], Step [6200/7038], D Loss: 0.5893681049346924, G Loss: 1.2622908353805542\n",
      "Epoch [6/50], Step [6300/7038], D Loss: 0.2995046377182007, G Loss: 1.7658742666244507\n",
      "Epoch [6/50], Step [6400/7038], D Loss: 0.5901185870170593, G Loss: 1.3608276844024658\n",
      "Epoch [6/50], Step [6500/7038], D Loss: 0.45798972249031067, G Loss: 1.6037092208862305\n",
      "Epoch [6/50], Step [6600/7038], D Loss: 0.31577885150909424, G Loss: 1.4427884817123413\n",
      "Epoch [6/50], Step [6700/7038], D Loss: 0.34124964475631714, G Loss: 1.5028520822525024\n",
      "Epoch [6/50], Step [6800/7038], D Loss: 0.7990542650222778, G Loss: 1.3705447912216187\n",
      "Epoch [6/50], Step [6900/7038], D Loss: 0.38585662841796875, G Loss: 1.3842531442642212\n",
      "Epoch [6/50], Step [7000/7038], D Loss: 0.5824989080429077, G Loss: 1.1331355571746826\n",
      "Epoch [7/50], Step [0/7038], D Loss: 0.72971510887146, G Loss: 1.2142865657806396\n",
      "Epoch [7/50], Step [100/7038], D Loss: 0.5916852951049805, G Loss: 1.2012768983840942\n",
      "Epoch [7/50], Step [200/7038], D Loss: 0.45839449763298035, G Loss: 1.3737504482269287\n",
      "Epoch [7/50], Step [300/7038], D Loss: 0.589991569519043, G Loss: 1.2988903522491455\n",
      "Epoch [7/50], Step [400/7038], D Loss: 0.5607321262359619, G Loss: 0.9530425071716309\n",
      "Epoch [7/50], Step [500/7038], D Loss: 0.48253563046455383, G Loss: 1.5029484033584595\n",
      "Epoch [7/50], Step [600/7038], D Loss: 0.5455971956253052, G Loss: 1.1987959146499634\n",
      "Epoch [7/50], Step [700/7038], D Loss: 0.5079250335693359, G Loss: 1.2917548418045044\n",
      "Epoch [7/50], Step [800/7038], D Loss: 0.4524614214897156, G Loss: 1.7107058763504028\n",
      "Epoch [7/50], Step [900/7038], D Loss: 0.43647247552871704, G Loss: 1.4013729095458984\n",
      "Epoch [7/50], Step [1000/7038], D Loss: 0.348224014043808, G Loss: 1.5306116342544556\n",
      "Epoch [7/50], Step [1100/7038], D Loss: 0.32576054334640503, G Loss: 1.6733607053756714\n",
      "Epoch [7/50], Step [1200/7038], D Loss: 0.6056662797927856, G Loss: 1.164883017539978\n",
      "Epoch [7/50], Step [1300/7038], D Loss: 0.646141767501831, G Loss: 1.3329066038131714\n",
      "Epoch [7/50], Step [1400/7038], D Loss: 0.6198425889015198, G Loss: 0.8110448718070984\n",
      "Epoch [7/50], Step [1500/7038], D Loss: 0.3566744923591614, G Loss: 1.4774836301803589\n",
      "Epoch [7/50], Step [1600/7038], D Loss: 0.6232792139053345, G Loss: 1.2767928838729858\n",
      "Epoch [7/50], Step [1700/7038], D Loss: 0.42381954193115234, G Loss: 1.6522613763809204\n",
      "Epoch [7/50], Step [1800/7038], D Loss: 0.5326584577560425, G Loss: 1.125032663345337\n",
      "Epoch [7/50], Step [1900/7038], D Loss: 0.5319610834121704, G Loss: 1.4175951480865479\n",
      "Epoch [7/50], Step [2000/7038], D Loss: 0.4619675576686859, G Loss: 1.0856540203094482\n",
      "Epoch [7/50], Step [2100/7038], D Loss: 0.520016074180603, G Loss: 1.1737918853759766\n",
      "Epoch [7/50], Step [2200/7038], D Loss: 0.6228615641593933, G Loss: 1.4216642379760742\n",
      "Epoch [7/50], Step [2300/7038], D Loss: 0.46735820174217224, G Loss: 1.3073707818984985\n",
      "Epoch [7/50], Step [2400/7038], D Loss: 0.49580883979797363, G Loss: 1.1615681648254395\n",
      "Epoch [7/50], Step [2500/7038], D Loss: 0.5356338620185852, G Loss: 1.5677987337112427\n",
      "Epoch [7/50], Step [2600/7038], D Loss: 0.5400567054748535, G Loss: 1.5169188976287842\n",
      "Epoch [7/50], Step [2700/7038], D Loss: 0.6842467188835144, G Loss: 1.2221468687057495\n",
      "Epoch [7/50], Step [2800/7038], D Loss: 0.5194606184959412, G Loss: 1.5081170797348022\n",
      "Epoch [7/50], Step [2900/7038], D Loss: 0.4830133616924286, G Loss: 1.3195055723190308\n",
      "Epoch [7/50], Step [3000/7038], D Loss: 0.4574510455131531, G Loss: 1.2820513248443604\n",
      "Epoch [7/50], Step [3100/7038], D Loss: 0.8671315312385559, G Loss: 0.9334789514541626\n",
      "Epoch [7/50], Step [3200/7038], D Loss: 0.3941238820552826, G Loss: 1.5384585857391357\n",
      "Epoch [7/50], Step [3300/7038], D Loss: 0.40134915709495544, G Loss: 1.3927605152130127\n",
      "Epoch [7/50], Step [3400/7038], D Loss: 0.5900669693946838, G Loss: 1.2037869691848755\n",
      "Epoch [7/50], Step [3500/7038], D Loss: 0.37140795588493347, G Loss: 1.6375738382339478\n",
      "Epoch [7/50], Step [3600/7038], D Loss: 0.4777039885520935, G Loss: 1.5498415231704712\n",
      "Epoch [7/50], Step [3700/7038], D Loss: 0.35303765535354614, G Loss: 1.6247074604034424\n",
      "Epoch [7/50], Step [3800/7038], D Loss: 0.7617673873901367, G Loss: 2.2718865871429443\n",
      "Epoch [7/50], Step [3900/7038], D Loss: 0.5185253620147705, G Loss: 1.2991394996643066\n",
      "Epoch [7/50], Step [4000/7038], D Loss: 0.4744468629360199, G Loss: 1.468508243560791\n",
      "Epoch [7/50], Step [4100/7038], D Loss: 0.49493953585624695, G Loss: 1.1191380023956299\n",
      "Epoch [7/50], Step [4200/7038], D Loss: 0.6436583995819092, G Loss: 1.1135883331298828\n",
      "Epoch [7/50], Step [4300/7038], D Loss: 0.48898041248321533, G Loss: 2.1165552139282227\n",
      "Epoch [7/50], Step [4400/7038], D Loss: 0.604385256767273, G Loss: 1.0856796503067017\n",
      "Epoch [7/50], Step [4500/7038], D Loss: 0.4590305685997009, G Loss: 1.3125145435333252\n",
      "Epoch [7/50], Step [4600/7038], D Loss: 0.4090169072151184, G Loss: 1.3369989395141602\n",
      "Epoch [7/50], Step [4700/7038], D Loss: 0.4123181104660034, G Loss: 1.34096097946167\n",
      "Epoch [7/50], Step [4800/7038], D Loss: 0.5996696949005127, G Loss: 1.4112462997436523\n",
      "Epoch [7/50], Step [4900/7038], D Loss: 0.5817194581031799, G Loss: 1.4363373517990112\n",
      "Epoch [7/50], Step [5000/7038], D Loss: 0.5535063147544861, G Loss: 1.340082049369812\n",
      "Epoch [7/50], Step [5100/7038], D Loss: 0.47510915994644165, G Loss: 1.3170758485794067\n",
      "Epoch [7/50], Step [5200/7038], D Loss: 0.5739713907241821, G Loss: 1.1282191276550293\n",
      "Epoch [7/50], Step [5300/7038], D Loss: 0.47980719804763794, G Loss: 1.4435927867889404\n",
      "Epoch [7/50], Step [5400/7038], D Loss: 0.40666624903678894, G Loss: 1.4011088609695435\n",
      "Epoch [7/50], Step [5500/7038], D Loss: 0.6048390865325928, G Loss: 0.9441421031951904\n",
      "Epoch [7/50], Step [5600/7038], D Loss: 0.5269487500190735, G Loss: 1.0963449478149414\n",
      "Epoch [7/50], Step [5700/7038], D Loss: 0.41633468866348267, G Loss: 1.456856608390808\n",
      "Epoch [7/50], Step [5800/7038], D Loss: 0.9492225646972656, G Loss: 1.256520390510559\n",
      "Epoch [7/50], Step [5900/7038], D Loss: 0.3798213601112366, G Loss: 1.6828794479370117\n",
      "Epoch [7/50], Step [6000/7038], D Loss: 0.5433894395828247, G Loss: 0.9437968730926514\n",
      "Epoch [7/50], Step [6100/7038], D Loss: 0.6711569428443909, G Loss: 0.9636867046356201\n",
      "Epoch [7/50], Step [6200/7038], D Loss: 0.4169880151748657, G Loss: 1.614005208015442\n",
      "Epoch [7/50], Step [6300/7038], D Loss: 0.38636907935142517, G Loss: 1.4229578971862793\n",
      "Epoch [7/50], Step [6400/7038], D Loss: 0.4540228247642517, G Loss: 1.7723333835601807\n",
      "Epoch [7/50], Step [6500/7038], D Loss: 0.6996263265609741, G Loss: 1.2608963251113892\n",
      "Epoch [7/50], Step [6600/7038], D Loss: 0.4583429992198944, G Loss: 1.2773622274398804\n",
      "Epoch [7/50], Step [6700/7038], D Loss: 0.39831143617630005, G Loss: 1.4853322505950928\n",
      "Epoch [7/50], Step [6800/7038], D Loss: 0.4376722574234009, G Loss: 1.281270980834961\n",
      "Epoch [7/50], Step [6900/7038], D Loss: 0.6640906929969788, G Loss: 1.1763840913772583\n",
      "Epoch [7/50], Step [7000/7038], D Loss: 0.6253368258476257, G Loss: 1.3387770652770996\n",
      "Epoch [8/50], Step [0/7038], D Loss: 0.6840710639953613, G Loss: 1.7388436794281006\n",
      "Epoch [8/50], Step [100/7038], D Loss: 0.5911063551902771, G Loss: 1.0491188764572144\n",
      "Epoch [8/50], Step [200/7038], D Loss: 0.7009061574935913, G Loss: 0.7773990035057068\n",
      "Epoch [8/50], Step [300/7038], D Loss: 0.5843909382820129, G Loss: 1.431634545326233\n",
      "Epoch [8/50], Step [400/7038], D Loss: 0.44047415256500244, G Loss: 1.3740650415420532\n",
      "Epoch [8/50], Step [500/7038], D Loss: 0.45075249671936035, G Loss: 1.557166576385498\n",
      "Epoch [8/50], Step [600/7038], D Loss: 0.43976202607154846, G Loss: 1.5095065832138062\n",
      "Epoch [8/50], Step [700/7038], D Loss: 0.5385757088661194, G Loss: 1.1315501928329468\n",
      "Epoch [8/50], Step [800/7038], D Loss: 0.4040880799293518, G Loss: 1.4238399267196655\n",
      "Epoch [8/50], Step [900/7038], D Loss: 0.5936949849128723, G Loss: 0.9754799008369446\n",
      "Epoch [8/50], Step [1000/7038], D Loss: 0.6220625042915344, G Loss: 1.2212642431259155\n",
      "Epoch [8/50], Step [1100/7038], D Loss: 0.28801581263542175, G Loss: 1.5782586336135864\n",
      "Epoch [8/50], Step [1200/7038], D Loss: 0.47643399238586426, G Loss: 1.2663376331329346\n",
      "Epoch [8/50], Step [1300/7038], D Loss: 0.5528680086135864, G Loss: 1.0645755529403687\n",
      "Epoch [8/50], Step [1400/7038], D Loss: 0.40895068645477295, G Loss: 1.7180203199386597\n",
      "Epoch [8/50], Step [1500/7038], D Loss: 0.4495229125022888, G Loss: 1.2958766222000122\n",
      "Epoch [8/50], Step [1600/7038], D Loss: 0.6676633954048157, G Loss: 1.2519395351409912\n",
      "Epoch [8/50], Step [1700/7038], D Loss: 0.46853262186050415, G Loss: 1.2510242462158203\n",
      "Epoch [8/50], Step [1800/7038], D Loss: 0.5656725168228149, G Loss: 1.4438532590866089\n",
      "Epoch [8/50], Step [1900/7038], D Loss: 0.4828798472881317, G Loss: 1.30074942111969\n",
      "Epoch [8/50], Step [2000/7038], D Loss: 0.5348341464996338, G Loss: 1.2235159873962402\n",
      "Epoch [8/50], Step [2100/7038], D Loss: 0.6327915787696838, G Loss: 1.1759155988693237\n",
      "Epoch [8/50], Step [2200/7038], D Loss: 0.3914095163345337, G Loss: 1.373201608657837\n",
      "Epoch [8/50], Step [2300/7038], D Loss: 0.3412325084209442, G Loss: 1.3816825151443481\n",
      "Epoch [8/50], Step [2400/7038], D Loss: 0.501146674156189, G Loss: 1.0552823543548584\n",
      "Epoch [8/50], Step [2500/7038], D Loss: 0.3563001751899719, G Loss: 1.72020423412323\n",
      "Epoch [8/50], Step [2600/7038], D Loss: 0.5994989275932312, G Loss: 1.4362260103225708\n",
      "Epoch [8/50], Step [2700/7038], D Loss: 0.4520670473575592, G Loss: 1.6332533359527588\n",
      "Epoch [8/50], Step [2800/7038], D Loss: 0.47951799631118774, G Loss: 1.1285525560379028\n",
      "Epoch [8/50], Step [2900/7038], D Loss: 0.6844609379768372, G Loss: 1.2114248275756836\n",
      "Epoch [8/50], Step [3000/7038], D Loss: 0.3572683334350586, G Loss: 1.7293283939361572\n",
      "Epoch [8/50], Step [3100/7038], D Loss: 0.5875313878059387, G Loss: 1.4778940677642822\n",
      "Epoch [8/50], Step [3200/7038], D Loss: 0.8119035363197327, G Loss: 1.0896514654159546\n",
      "Epoch [8/50], Step [3300/7038], D Loss: 0.640055775642395, G Loss: 1.6112669706344604\n",
      "Epoch [8/50], Step [3400/7038], D Loss: 0.438977986574173, G Loss: 1.2377749681472778\n",
      "Epoch [8/50], Step [3500/7038], D Loss: 0.5806318521499634, G Loss: 0.9103413224220276\n",
      "Epoch [8/50], Step [3600/7038], D Loss: 0.3702664077281952, G Loss: 1.3509021997451782\n",
      "Epoch [8/50], Step [3700/7038], D Loss: 0.48374056816101074, G Loss: 1.9554657936096191\n",
      "Epoch [8/50], Step [3800/7038], D Loss: 0.38482666015625, G Loss: 1.4843264818191528\n",
      "Epoch [8/50], Step [3900/7038], D Loss: 0.5025205016136169, G Loss: 1.2052260637283325\n",
      "Epoch [8/50], Step [4000/7038], D Loss: 0.4129711389541626, G Loss: 1.2300066947937012\n",
      "Epoch [8/50], Step [4100/7038], D Loss: 0.46115103363990784, G Loss: 1.239673376083374\n",
      "Epoch [8/50], Step [4200/7038], D Loss: 0.5065641403198242, G Loss: 1.3938525915145874\n",
      "Epoch [8/50], Step [4300/7038], D Loss: 0.6832417249679565, G Loss: 1.4330991506576538\n",
      "Epoch [8/50], Step [4400/7038], D Loss: 0.4445667862892151, G Loss: 1.6193485260009766\n",
      "Epoch [8/50], Step [4500/7038], D Loss: 0.6732800006866455, G Loss: 1.2634618282318115\n",
      "Epoch [8/50], Step [4600/7038], D Loss: 0.6091195344924927, G Loss: 1.1014492511749268\n",
      "Epoch [8/50], Step [4700/7038], D Loss: 0.719548761844635, G Loss: 1.3542964458465576\n",
      "Epoch [8/50], Step [4800/7038], D Loss: 0.5467075705528259, G Loss: 1.28854501247406\n",
      "Epoch [8/50], Step [4900/7038], D Loss: 0.4750429391860962, G Loss: 1.439764142036438\n",
      "Epoch [8/50], Step [5000/7038], D Loss: 1.0218909978866577, G Loss: 3.6005022525787354\n",
      "Epoch [8/50], Step [5100/7038], D Loss: 0.7424516677856445, G Loss: 1.3309749364852905\n",
      "Epoch [8/50], Step [5200/7038], D Loss: 0.6723946332931519, G Loss: 1.0271661281585693\n",
      "Epoch [8/50], Step [5300/7038], D Loss: 0.5667693018913269, G Loss: 1.010707974433899\n",
      "Epoch [8/50], Step [5400/7038], D Loss: 0.3798636198043823, G Loss: 1.3434853553771973\n",
      "Epoch [8/50], Step [5500/7038], D Loss: 0.7570360898971558, G Loss: 1.2739098072052002\n",
      "Epoch [8/50], Step [5600/7038], D Loss: 0.5644829273223877, G Loss: 1.2064663171768188\n",
      "Epoch [8/50], Step [5700/7038], D Loss: 0.4969066381454468, G Loss: 1.3640919923782349\n",
      "Epoch [8/50], Step [5800/7038], D Loss: 0.5405858755111694, G Loss: 1.1642308235168457\n",
      "Epoch [8/50], Step [5900/7038], D Loss: 0.3825547695159912, G Loss: 1.3958719968795776\n",
      "Epoch [8/50], Step [6000/7038], D Loss: 0.750654935836792, G Loss: 1.3726465702056885\n",
      "Epoch [8/50], Step [6100/7038], D Loss: 0.6338502764701843, G Loss: 1.7068655490875244\n",
      "Epoch [8/50], Step [6200/7038], D Loss: 0.36259889602661133, G Loss: 1.344297170639038\n",
      "Epoch [8/50], Step [6300/7038], D Loss: 0.6805365085601807, G Loss: 1.4242587089538574\n",
      "Epoch [8/50], Step [6400/7038], D Loss: 0.43037930130958557, G Loss: 1.192505955696106\n",
      "Epoch [8/50], Step [6500/7038], D Loss: 0.45536401867866516, G Loss: 1.3791687488555908\n",
      "Epoch [8/50], Step [6600/7038], D Loss: 0.7385358810424805, G Loss: 1.5204578638076782\n",
      "Epoch [8/50], Step [6700/7038], D Loss: 0.39193904399871826, G Loss: 1.391486644744873\n",
      "Epoch [8/50], Step [6800/7038], D Loss: 0.4025615453720093, G Loss: 1.4682179689407349\n",
      "Epoch [8/50], Step [6900/7038], D Loss: 0.41239237785339355, G Loss: 1.3678840398788452\n",
      "Epoch [8/50], Step [7000/7038], D Loss: 0.6045894622802734, G Loss: 1.076667070388794\n",
      "Epoch [9/50], Step [0/7038], D Loss: 0.5451208353042603, G Loss: 1.0728152990341187\n",
      "Epoch [9/50], Step [100/7038], D Loss: 0.7611596584320068, G Loss: 1.1848610639572144\n",
      "Epoch [9/50], Step [200/7038], D Loss: 0.3010578751564026, G Loss: 1.5129384994506836\n",
      "Epoch [9/50], Step [300/7038], D Loss: 0.4865012466907501, G Loss: 1.3560967445373535\n",
      "Epoch [9/50], Step [400/7038], D Loss: 0.41645801067352295, G Loss: 1.3372712135314941\n",
      "Epoch [9/50], Step [500/7038], D Loss: 0.42409396171569824, G Loss: 1.4549992084503174\n",
      "Epoch [9/50], Step [600/7038], D Loss: 0.45741328597068787, G Loss: 1.316859483718872\n",
      "Epoch [9/50], Step [700/7038], D Loss: 0.38072261214256287, G Loss: 1.3327590227127075\n",
      "Epoch [9/50], Step [800/7038], D Loss: 0.3824397623538971, G Loss: 1.1844627857208252\n",
      "Epoch [9/50], Step [900/7038], D Loss: 0.5289543867111206, G Loss: 1.0150625705718994\n",
      "Epoch [9/50], Step [1000/7038], D Loss: 0.6975394487380981, G Loss: 1.0071938037872314\n",
      "Epoch [9/50], Step [1100/7038], D Loss: 0.5165126323699951, G Loss: 1.0952177047729492\n",
      "Epoch [9/50], Step [1200/7038], D Loss: 0.4746110141277313, G Loss: 1.3914989233016968\n",
      "Epoch [9/50], Step [1300/7038], D Loss: 0.43771588802337646, G Loss: 1.5141290426254272\n",
      "Epoch [9/50], Step [1400/7038], D Loss: 0.5279847383499146, G Loss: 1.1612119674682617\n",
      "Epoch [9/50], Step [1500/7038], D Loss: 0.36710458993911743, G Loss: 1.4560185670852661\n",
      "Epoch [9/50], Step [1600/7038], D Loss: 0.46920904517173767, G Loss: 1.5477699041366577\n",
      "Epoch [9/50], Step [1700/7038], D Loss: 0.48453715443611145, G Loss: 1.3209670782089233\n",
      "Epoch [9/50], Step [1800/7038], D Loss: 0.43631261587142944, G Loss: 1.2378153800964355\n",
      "Epoch [9/50], Step [1900/7038], D Loss: 0.4083143472671509, G Loss: 1.1918953657150269\n",
      "Epoch [9/50], Step [2000/7038], D Loss: 0.5536288619041443, G Loss: 1.1818807125091553\n",
      "Epoch [9/50], Step [2100/7038], D Loss: 0.43984150886535645, G Loss: 1.8651580810546875\n",
      "Epoch [9/50], Step [2200/7038], D Loss: 0.41503196954727173, G Loss: 1.440908670425415\n",
      "Epoch [9/50], Step [2300/7038], D Loss: 0.5151610374450684, G Loss: 1.1820124387741089\n",
      "Epoch [9/50], Step [2400/7038], D Loss: 0.6956343650817871, G Loss: 1.1807583570480347\n",
      "Epoch [9/50], Step [2500/7038], D Loss: 0.555234968662262, G Loss: 1.2545405626296997\n",
      "Epoch [9/50], Step [2600/7038], D Loss: 0.8331292867660522, G Loss: 2.0277493000030518\n",
      "Epoch [9/50], Step [2700/7038], D Loss: 0.4804363548755646, G Loss: 1.7975342273712158\n",
      "Epoch [9/50], Step [2800/7038], D Loss: 0.5011477470397949, G Loss: 1.5674806833267212\n",
      "Epoch [9/50], Step [2900/7038], D Loss: 0.39518722891807556, G Loss: 1.8459383249282837\n",
      "Epoch [9/50], Step [3000/7038], D Loss: 0.41251784563064575, G Loss: 1.4264426231384277\n",
      "Epoch [9/50], Step [3100/7038], D Loss: 0.4911957383155823, G Loss: 1.238724946975708\n",
      "Epoch [9/50], Step [3200/7038], D Loss: 0.4393160343170166, G Loss: 1.6539336442947388\n",
      "Epoch [9/50], Step [3300/7038], D Loss: 0.3209038972854614, G Loss: 1.4917243719100952\n",
      "Epoch [9/50], Step [3400/7038], D Loss: 0.47018885612487793, G Loss: 1.339189052581787\n",
      "Epoch [9/50], Step [3500/7038], D Loss: 0.5428454875946045, G Loss: 1.421273112297058\n",
      "Epoch [9/50], Step [3600/7038], D Loss: 0.7666495442390442, G Loss: 0.9037781953811646\n",
      "Epoch [9/50], Step [3700/7038], D Loss: 0.5837167501449585, G Loss: 1.5204161405563354\n",
      "Epoch [9/50], Step [3800/7038], D Loss: 0.542780339717865, G Loss: 1.2563146352767944\n",
      "Epoch [9/50], Step [3900/7038], D Loss: 0.4625818133354187, G Loss: 1.227696418762207\n",
      "Epoch [9/50], Step [4000/7038], D Loss: 0.4851788878440857, G Loss: 0.9940826296806335\n",
      "Epoch [9/50], Step [4100/7038], D Loss: 0.44049879908561707, G Loss: 1.7357823848724365\n",
      "Epoch [9/50], Step [4200/7038], D Loss: 0.6366966962814331, G Loss: 1.185050368309021\n",
      "Epoch [9/50], Step [4300/7038], D Loss: 0.48612409830093384, G Loss: 1.0772086381912231\n",
      "Epoch [9/50], Step [4400/7038], D Loss: 0.30878061056137085, G Loss: 2.0733187198638916\n",
      "Epoch [9/50], Step [4500/7038], D Loss: 0.5076531767845154, G Loss: 1.2963850498199463\n",
      "Epoch [9/50], Step [4600/7038], D Loss: 0.6282097101211548, G Loss: 1.3850682973861694\n",
      "Epoch [9/50], Step [4700/7038], D Loss: 0.4266306757926941, G Loss: 1.3532471656799316\n",
      "Epoch [9/50], Step [4800/7038], D Loss: 0.5977631211280823, G Loss: 1.377663254737854\n",
      "Epoch [9/50], Step [4900/7038], D Loss: 0.3697262108325958, G Loss: 1.2435252666473389\n",
      "Epoch [9/50], Step [5000/7038], D Loss: 0.6794946193695068, G Loss: 1.3141428232192993\n",
      "Epoch [9/50], Step [5100/7038], D Loss: 0.45475971698760986, G Loss: 1.3043406009674072\n",
      "Epoch [9/50], Step [5200/7038], D Loss: 0.5469615459442139, G Loss: 1.1877729892730713\n",
      "Epoch [9/50], Step [5300/7038], D Loss: 0.42677563428878784, G Loss: 1.419723391532898\n",
      "Epoch [9/50], Step [5400/7038], D Loss: 0.5949702262878418, G Loss: 1.5133984088897705\n",
      "Epoch [9/50], Step [5500/7038], D Loss: 0.4693378210067749, G Loss: 1.8389699459075928\n",
      "Epoch [9/50], Step [5600/7038], D Loss: 0.6122040748596191, G Loss: 1.1013755798339844\n",
      "Epoch [9/50], Step [5700/7038], D Loss: 0.6254549026489258, G Loss: 1.2769855260849\n",
      "Epoch [9/50], Step [5800/7038], D Loss: 0.4497241973876953, G Loss: 1.328710913658142\n",
      "Epoch [9/50], Step [5900/7038], D Loss: 0.5273244380950928, G Loss: 1.5221210718154907\n",
      "Epoch [9/50], Step [6000/7038], D Loss: 0.3644222617149353, G Loss: 1.2129631042480469\n",
      "Epoch [9/50], Step [6100/7038], D Loss: 0.5858043432235718, G Loss: 1.4087380170822144\n",
      "Epoch [9/50], Step [6200/7038], D Loss: 0.6801216006278992, G Loss: 2.2238385677337646\n",
      "Epoch [9/50], Step [6300/7038], D Loss: 0.6165727972984314, G Loss: 1.1446125507354736\n",
      "Epoch [9/50], Step [6400/7038], D Loss: 0.7778735160827637, G Loss: 1.417638897895813\n",
      "Epoch [9/50], Step [6500/7038], D Loss: 0.6627644300460815, G Loss: 1.080186367034912\n",
      "Epoch [9/50], Step [6600/7038], D Loss: 0.6213858723640442, G Loss: 0.798142671585083\n",
      "Epoch [9/50], Step [6700/7038], D Loss: 0.6693359613418579, G Loss: 1.1776187419891357\n",
      "Epoch [9/50], Step [6800/7038], D Loss: 0.3725881576538086, G Loss: 1.5962573289871216\n",
      "Epoch [9/50], Step [6900/7038], D Loss: 0.764357328414917, G Loss: 1.3939052820205688\n",
      "Epoch [9/50], Step [7000/7038], D Loss: 0.5428808927536011, G Loss: 1.2407615184783936\n",
      "Epoch [10/50], Step [0/7038], D Loss: 0.7549828290939331, G Loss: 1.3371585607528687\n",
      "Epoch [10/50], Step [100/7038], D Loss: 0.6740663647651672, G Loss: 1.1161088943481445\n",
      "Epoch [10/50], Step [200/7038], D Loss: 0.4084739685058594, G Loss: 1.3911911249160767\n",
      "Epoch [10/50], Step [300/7038], D Loss: 0.4610956609249115, G Loss: 1.762948751449585\n",
      "Epoch [10/50], Step [400/7038], D Loss: 0.6954225301742554, G Loss: 1.3189702033996582\n",
      "Epoch [10/50], Step [500/7038], D Loss: 0.4941149353981018, G Loss: 1.2814370393753052\n",
      "Epoch [10/50], Step [600/7038], D Loss: 0.6522107124328613, G Loss: 1.3846240043640137\n",
      "Epoch [10/50], Step [700/7038], D Loss: 0.6400979161262512, G Loss: 1.165085792541504\n",
      "Epoch [10/50], Step [800/7038], D Loss: 0.5029783844947815, G Loss: 1.3807235956192017\n",
      "Epoch [10/50], Step [900/7038], D Loss: 0.5334384441375732, G Loss: 1.040771722793579\n",
      "Epoch [10/50], Step [1000/7038], D Loss: 0.3938746750354767, G Loss: 1.2521916627883911\n",
      "Epoch [10/50], Step [1100/7038], D Loss: 0.551220715045929, G Loss: 0.9019114971160889\n",
      "Epoch [10/50], Step [1200/7038], D Loss: 0.685272216796875, G Loss: 0.9755946397781372\n",
      "Epoch [10/50], Step [1300/7038], D Loss: 0.42286020517349243, G Loss: 1.4281479120254517\n",
      "Epoch [10/50], Step [1400/7038], D Loss: 0.4699869453907013, G Loss: 1.1692487001419067\n",
      "Epoch [10/50], Step [1500/7038], D Loss: 0.593089759349823, G Loss: 1.010786533355713\n",
      "Epoch [10/50], Step [1600/7038], D Loss: 0.47803807258605957, G Loss: 1.2028064727783203\n",
      "Epoch [10/50], Step [1700/7038], D Loss: 0.45437824726104736, G Loss: 1.3639676570892334\n",
      "Epoch [10/50], Step [1800/7038], D Loss: 0.5078700184822083, G Loss: 1.0975455045700073\n",
      "Epoch [10/50], Step [1900/7038], D Loss: 0.4942171573638916, G Loss: 1.230396032333374\n",
      "Epoch [10/50], Step [2000/7038], D Loss: 0.9970020055770874, G Loss: 1.1695059537887573\n",
      "Epoch [10/50], Step [2100/7038], D Loss: 0.5683502554893494, G Loss: 1.0520460605621338\n",
      "Epoch [10/50], Step [2200/7038], D Loss: 0.5809281468391418, G Loss: 1.219587802886963\n",
      "Epoch [10/50], Step [2300/7038], D Loss: 0.33613768219947815, G Loss: 1.6190117597579956\n",
      "Epoch [10/50], Step [2400/7038], D Loss: 0.416317880153656, G Loss: 1.4495317935943604\n",
      "Epoch [10/50], Step [2500/7038], D Loss: 0.4417295753955841, G Loss: 1.0690889358520508\n",
      "Epoch [10/50], Step [2600/7038], D Loss: 0.7292360067367554, G Loss: 1.8698217868804932\n",
      "Epoch [10/50], Step [2700/7038], D Loss: 0.44039463996887207, G Loss: 1.2826992273330688\n",
      "Epoch [10/50], Step [2800/7038], D Loss: 0.39866793155670166, G Loss: 1.31175696849823\n",
      "Epoch [10/50], Step [2900/7038], D Loss: 0.4881506562232971, G Loss: 1.294946551322937\n",
      "Epoch [10/50], Step [3000/7038], D Loss: 0.4911037087440491, G Loss: 1.2258780002593994\n",
      "Epoch [10/50], Step [3100/7038], D Loss: 0.5455302596092224, G Loss: 1.0525072813034058\n",
      "Epoch [10/50], Step [3200/7038], D Loss: 0.5069728493690491, G Loss: 1.7454473972320557\n",
      "Epoch [10/50], Step [3300/7038], D Loss: 0.43088608980178833, G Loss: 1.3097310066223145\n",
      "Epoch [10/50], Step [3400/7038], D Loss: 0.5614659786224365, G Loss: 1.1696691513061523\n",
      "Epoch [10/50], Step [3500/7038], D Loss: 0.5785396099090576, G Loss: 1.212844729423523\n",
      "Epoch [10/50], Step [3600/7038], D Loss: 0.5000921487808228, G Loss: 1.5571995973587036\n",
      "Epoch [10/50], Step [3700/7038], D Loss: 0.33567696809768677, G Loss: 1.492687463760376\n",
      "Epoch [10/50], Step [3800/7038], D Loss: 0.7044881582260132, G Loss: 2.1815054416656494\n",
      "Epoch [10/50], Step [3900/7038], D Loss: 0.5114494562149048, G Loss: 1.3479496240615845\n",
      "Epoch [10/50], Step [4000/7038], D Loss: 0.614527702331543, G Loss: 1.2524305582046509\n",
      "Epoch [10/50], Step [4100/7038], D Loss: 0.47049278020858765, G Loss: 1.2347413301467896\n",
      "Epoch [10/50], Step [4200/7038], D Loss: 0.6117470264434814, G Loss: 1.0196510553359985\n",
      "Epoch [10/50], Step [4300/7038], D Loss: 0.3832569420337677, G Loss: 1.4876768589019775\n",
      "Epoch [10/50], Step [4400/7038], D Loss: 0.4069923758506775, G Loss: 1.4510241746902466\n",
      "Epoch [10/50], Step [4500/7038], D Loss: 0.546620786190033, G Loss: 1.5159465074539185\n",
      "Epoch [10/50], Step [4600/7038], D Loss: 0.6220495700836182, G Loss: 1.2946877479553223\n",
      "Epoch [10/50], Step [4700/7038], D Loss: 0.7590325474739075, G Loss: 1.4224170446395874\n",
      "Epoch [10/50], Step [4800/7038], D Loss: 0.5801316499710083, G Loss: 1.1603621244430542\n",
      "Epoch [10/50], Step [4900/7038], D Loss: 0.4982631206512451, G Loss: 1.3659727573394775\n",
      "Epoch [10/50], Step [5000/7038], D Loss: 0.5351706743240356, G Loss: 1.0200601816177368\n",
      "Epoch [10/50], Step [5100/7038], D Loss: 0.5257002115249634, G Loss: 1.4825420379638672\n",
      "Epoch [10/50], Step [5200/7038], D Loss: 0.5014203786849976, G Loss: 1.517532229423523\n",
      "Epoch [10/50], Step [5300/7038], D Loss: 0.6060393452644348, G Loss: 1.169407844543457\n",
      "Epoch [10/50], Step [5400/7038], D Loss: 0.6054882407188416, G Loss: 1.2411826848983765\n",
      "Epoch [10/50], Step [5500/7038], D Loss: 0.8243025541305542, G Loss: 0.8704208135604858\n",
      "Epoch [10/50], Step [5600/7038], D Loss: 0.4885066747665405, G Loss: 1.2816214561462402\n",
      "Epoch [10/50], Step [5700/7038], D Loss: 0.5080782175064087, G Loss: 1.1842191219329834\n",
      "Epoch [10/50], Step [5800/7038], D Loss: 0.6866689920425415, G Loss: 1.0360198020935059\n",
      "Epoch [10/50], Step [5900/7038], D Loss: 0.7910000681877136, G Loss: 0.9890534281730652\n",
      "Epoch [10/50], Step [6000/7038], D Loss: 0.5583418011665344, G Loss: 1.5055630207061768\n",
      "Epoch [10/50], Step [6100/7038], D Loss: 0.5168035626411438, G Loss: 1.0107901096343994\n",
      "Epoch [10/50], Step [6200/7038], D Loss: 0.6328619718551636, G Loss: 1.2488735914230347\n",
      "Epoch [10/50], Step [6300/7038], D Loss: 0.5546932220458984, G Loss: 1.1178816556930542\n",
      "Epoch [10/50], Step [6400/7038], D Loss: 0.45749497413635254, G Loss: 1.0962780714035034\n",
      "Epoch [10/50], Step [6500/7038], D Loss: 0.5783698558807373, G Loss: 0.9922076463699341\n",
      "Epoch [10/50], Step [6600/7038], D Loss: 0.9125549793243408, G Loss: 1.2019628286361694\n",
      "Epoch [10/50], Step [6700/7038], D Loss: 0.5124215483665466, G Loss: 2.050144910812378\n",
      "Epoch [10/50], Step [6800/7038], D Loss: 0.41802215576171875, G Loss: 1.3109252452850342\n",
      "Epoch [10/50], Step [6900/7038], D Loss: 0.3691115379333496, G Loss: 1.427190899848938\n",
      "Epoch [10/50], Step [7000/7038], D Loss: 0.495143324136734, G Loss: 1.166711449623108\n",
      "Epoch [11/50], Step [0/7038], D Loss: 0.5418447852134705, G Loss: 1.4244438409805298\n",
      "Epoch [11/50], Step [100/7038], D Loss: 0.42942965030670166, G Loss: 1.3151745796203613\n",
      "Epoch [11/50], Step [200/7038], D Loss: 0.44464439153671265, G Loss: 1.1458888053894043\n",
      "Epoch [11/50], Step [300/7038], D Loss: 0.6406440138816833, G Loss: 0.8911420702934265\n",
      "Epoch [11/50], Step [400/7038], D Loss: 0.8115417957305908, G Loss: 1.0118401050567627\n",
      "Epoch [11/50], Step [500/7038], D Loss: 0.4855439066886902, G Loss: 1.0886021852493286\n",
      "Epoch [11/50], Step [600/7038], D Loss: 0.29189857840538025, G Loss: 1.5810606479644775\n",
      "Epoch [11/50], Step [700/7038], D Loss: 0.5530752539634705, G Loss: 1.4505339860916138\n",
      "Epoch [11/50], Step [800/7038], D Loss: 0.6391587853431702, G Loss: 0.977575957775116\n",
      "Epoch [11/50], Step [900/7038], D Loss: 0.48793667554855347, G Loss: 1.300642967224121\n",
      "Epoch [11/50], Step [1000/7038], D Loss: 1.0323115587234497, G Loss: 1.7181850671768188\n",
      "Epoch [11/50], Step [1100/7038], D Loss: 0.49324920773506165, G Loss: 1.3341329097747803\n",
      "Epoch [11/50], Step [1200/7038], D Loss: 0.429618775844574, G Loss: 1.4358621835708618\n",
      "Epoch [11/50], Step [1300/7038], D Loss: 0.706472635269165, G Loss: 1.0136239528656006\n",
      "Epoch [11/50], Step [1400/7038], D Loss: 0.4734939932823181, G Loss: 1.3509272336959839\n",
      "Epoch [11/50], Step [1500/7038], D Loss: 0.5548839569091797, G Loss: 1.0167707204818726\n",
      "Epoch [11/50], Step [1600/7038], D Loss: 0.6070549488067627, G Loss: 1.0856564044952393\n",
      "Epoch [11/50], Step [1700/7038], D Loss: 0.664371132850647, G Loss: 1.1758928298950195\n",
      "Epoch [11/50], Step [1800/7038], D Loss: 0.47530674934387207, G Loss: 1.5473302602767944\n",
      "Epoch [11/50], Step [1900/7038], D Loss: 0.49859803915023804, G Loss: 1.1948658227920532\n",
      "Epoch [11/50], Step [2000/7038], D Loss: 0.6060126423835754, G Loss: 0.9760001301765442\n",
      "Epoch [11/50], Step [2100/7038], D Loss: 0.5828704237937927, G Loss: 0.9794025421142578\n",
      "Epoch [11/50], Step [2200/7038], D Loss: 0.48069125413894653, G Loss: 1.1979434490203857\n",
      "Epoch [11/50], Step [2300/7038], D Loss: 0.4615298807621002, G Loss: 1.1806141138076782\n",
      "Epoch [11/50], Step [2400/7038], D Loss: 0.7457574605941772, G Loss: 1.1238361597061157\n",
      "Epoch [11/50], Step [2500/7038], D Loss: 0.7221617698669434, G Loss: 1.681280493736267\n",
      "Epoch [11/50], Step [2600/7038], D Loss: 0.771660566329956, G Loss: 2.1984241008758545\n",
      "Epoch [11/50], Step [2700/7038], D Loss: 0.280143678188324, G Loss: 1.6811108589172363\n",
      "Epoch [11/50], Step [2800/7038], D Loss: 0.4067627787590027, G Loss: 1.5231220722198486\n",
      "Epoch [11/50], Step [2900/7038], D Loss: 0.5987512469291687, G Loss: 1.232745885848999\n",
      "Epoch [11/50], Step [3000/7038], D Loss: 0.71546870470047, G Loss: 1.0953524112701416\n",
      "Epoch [11/50], Step [3100/7038], D Loss: 0.4998247027397156, G Loss: 1.2237948179244995\n",
      "Epoch [11/50], Step [3200/7038], D Loss: 0.5011458396911621, G Loss: 1.4700360298156738\n",
      "Epoch [11/50], Step [3300/7038], D Loss: 0.5172140598297119, G Loss: 1.0467169284820557\n",
      "Epoch [11/50], Step [3400/7038], D Loss: 0.4737725853919983, G Loss: 1.360817313194275\n",
      "Epoch [11/50], Step [3500/7038], D Loss: 0.6340903043746948, G Loss: 0.959804892539978\n",
      "Epoch [11/50], Step [3600/7038], D Loss: 0.43649524450302124, G Loss: 1.2045977115631104\n",
      "Epoch [11/50], Step [3700/7038], D Loss: 0.6588362455368042, G Loss: 1.0330122709274292\n",
      "Epoch [11/50], Step [3800/7038], D Loss: 0.5446273684501648, G Loss: 1.172603726387024\n",
      "Epoch [11/50], Step [3900/7038], D Loss: 0.6068966388702393, G Loss: 1.027421474456787\n",
      "Epoch [11/50], Step [4000/7038], D Loss: 0.9188997745513916, G Loss: 1.3347063064575195\n",
      "Epoch [11/50], Step [4100/7038], D Loss: 0.5485249161720276, G Loss: 1.3596793413162231\n",
      "Epoch [11/50], Step [4200/7038], D Loss: 0.46757882833480835, G Loss: 1.4417474269866943\n",
      "Epoch [11/50], Step [4300/7038], D Loss: 0.4836220145225525, G Loss: 1.4281818866729736\n",
      "Epoch [11/50], Step [4400/7038], D Loss: 0.5729285478591919, G Loss: 1.2974284887313843\n",
      "Epoch [11/50], Step [4500/7038], D Loss: 0.4040314853191376, G Loss: 1.3404666185379028\n",
      "Epoch [11/50], Step [4600/7038], D Loss: 0.6683818697929382, G Loss: 1.138463020324707\n",
      "Epoch [11/50], Step [4700/7038], D Loss: 0.3667938709259033, G Loss: 1.46184504032135\n",
      "Epoch [11/50], Step [4800/7038], D Loss: 0.6204367280006409, G Loss: 1.1973215341567993\n",
      "Epoch [11/50], Step [4900/7038], D Loss: 0.4852995276451111, G Loss: 1.252379059791565\n",
      "Epoch [11/50], Step [5000/7038], D Loss: 0.6000849008560181, G Loss: 1.3138545751571655\n",
      "Epoch [11/50], Step [5100/7038], D Loss: 0.43057674169540405, G Loss: 1.3330190181732178\n",
      "Epoch [11/50], Step [5200/7038], D Loss: 0.4419209361076355, G Loss: 1.3345832824707031\n",
      "Epoch [11/50], Step [5300/7038], D Loss: 0.5918476581573486, G Loss: 1.3806079626083374\n",
      "Epoch [11/50], Step [5400/7038], D Loss: 0.5019124150276184, G Loss: 1.4185165166854858\n",
      "Epoch [11/50], Step [5500/7038], D Loss: 0.4585307240486145, G Loss: 1.3805848360061646\n",
      "Epoch [11/50], Step [5600/7038], D Loss: 0.3322006165981293, G Loss: 1.607797622680664\n",
      "Epoch [11/50], Step [5700/7038], D Loss: 0.45406192541122437, G Loss: 1.2305139303207397\n",
      "Epoch [11/50], Step [5800/7038], D Loss: 0.5394076108932495, G Loss: 1.2213166952133179\n",
      "Epoch [11/50], Step [5900/7038], D Loss: 0.6449350118637085, G Loss: 1.1263529062271118\n",
      "Epoch [11/50], Step [6000/7038], D Loss: 0.9062250852584839, G Loss: 1.2247416973114014\n",
      "Epoch [11/50], Step [6100/7038], D Loss: 0.4472867250442505, G Loss: 1.0833812952041626\n",
      "Epoch [11/50], Step [6200/7038], D Loss: 0.45352625846862793, G Loss: 1.1806739568710327\n",
      "Epoch [11/50], Step [6300/7038], D Loss: 0.5889588594436646, G Loss: 1.0947465896606445\n",
      "Epoch [11/50], Step [6400/7038], D Loss: 0.38463446497917175, G Loss: 1.6156989336013794\n",
      "Epoch [11/50], Step [6500/7038], D Loss: 0.6873118877410889, G Loss: 1.4335533380508423\n",
      "Epoch [11/50], Step [6600/7038], D Loss: 0.45234745740890503, G Loss: 1.6201415061950684\n",
      "Epoch [11/50], Step [6700/7038], D Loss: 0.5598627328872681, G Loss: 1.2927879095077515\n",
      "Epoch [11/50], Step [6800/7038], D Loss: 0.5511011481285095, G Loss: 1.000356674194336\n",
      "Epoch [11/50], Step [6900/7038], D Loss: 0.45890092849731445, G Loss: 1.2054009437561035\n",
      "Epoch [11/50], Step [7000/7038], D Loss: 0.5193449854850769, G Loss: 1.117005705833435\n",
      "Epoch [12/50], Step [0/7038], D Loss: 0.49341413378715515, G Loss: 1.5432120561599731\n",
      "Epoch [12/50], Step [100/7038], D Loss: 0.5396962761878967, G Loss: 1.9804750680923462\n",
      "Epoch [12/50], Step [200/7038], D Loss: 0.39177626371383667, G Loss: 1.4283448457717896\n",
      "Epoch [12/50], Step [300/7038], D Loss: 0.5769882202148438, G Loss: 1.3287822008132935\n",
      "Epoch [12/50], Step [400/7038], D Loss: 0.5980598330497742, G Loss: 1.2306857109069824\n",
      "Epoch [12/50], Step [500/7038], D Loss: 0.5846632122993469, G Loss: 1.0010285377502441\n",
      "Epoch [12/50], Step [600/7038], D Loss: 0.6102674603462219, G Loss: 1.0600558519363403\n",
      "Epoch [12/50], Step [700/7038], D Loss: 0.49775832891464233, G Loss: 1.1479551792144775\n",
      "Epoch [12/50], Step [800/7038], D Loss: 0.3706493675708771, G Loss: 1.6306349039077759\n",
      "Epoch [12/50], Step [900/7038], D Loss: 0.43674057722091675, G Loss: 1.1769963502883911\n",
      "Epoch [12/50], Step [1000/7038], D Loss: 0.6587475538253784, G Loss: 1.346178650856018\n",
      "Epoch [12/50], Step [1100/7038], D Loss: 0.5346720814704895, G Loss: 1.5398502349853516\n",
      "Epoch [12/50], Step [1200/7038], D Loss: 0.778611958026886, G Loss: 1.7477582693099976\n",
      "Epoch [12/50], Step [1300/7038], D Loss: 0.44380778074264526, G Loss: 1.5873953104019165\n",
      "Epoch [12/50], Step [1400/7038], D Loss: 0.46559908986091614, G Loss: 2.025559902191162\n",
      "Epoch [12/50], Step [1500/7038], D Loss: 0.41850197315216064, G Loss: 1.3847410678863525\n",
      "Epoch [12/50], Step [1600/7038], D Loss: 0.40417158603668213, G Loss: 1.315271019935608\n",
      "Epoch [12/50], Step [1700/7038], D Loss: 0.3884599804878235, G Loss: 1.3854531049728394\n",
      "Epoch [12/50], Step [1800/7038], D Loss: 0.5130180716514587, G Loss: 1.0677601099014282\n",
      "Epoch [12/50], Step [1900/7038], D Loss: 0.4429550766944885, G Loss: 1.7630152702331543\n",
      "Epoch [12/50], Step [2000/7038], D Loss: 0.7161471247673035, G Loss: 0.9481609463691711\n",
      "Epoch [12/50], Step [2100/7038], D Loss: 0.4176182150840759, G Loss: 1.5059078931808472\n",
      "Epoch [12/50], Step [2200/7038], D Loss: 0.5705717206001282, G Loss: 1.2893625497817993\n",
      "Epoch [12/50], Step [2300/7038], D Loss: 0.6878225803375244, G Loss: 1.2031395435333252\n",
      "Epoch [12/50], Step [2400/7038], D Loss: 0.6678896546363831, G Loss: 0.9423418641090393\n",
      "Epoch [12/50], Step [2500/7038], D Loss: 0.7208640575408936, G Loss: 0.9791763424873352\n",
      "Epoch [12/50], Step [2600/7038], D Loss: 0.732779860496521, G Loss: 1.3553636074066162\n",
      "Epoch [12/50], Step [2700/7038], D Loss: 0.6904078722000122, G Loss: 1.195090413093567\n",
      "Epoch [12/50], Step [2800/7038], D Loss: 0.5515413284301758, G Loss: 1.1571409702301025\n",
      "Epoch [12/50], Step [2900/7038], D Loss: 0.6113846898078918, G Loss: 1.079132080078125\n",
      "Epoch [12/50], Step [3000/7038], D Loss: 0.627295732498169, G Loss: 0.9404252171516418\n",
      "Epoch [12/50], Step [3100/7038], D Loss: 0.5497355461120605, G Loss: 1.2840073108673096\n",
      "Epoch [12/50], Step [3200/7038], D Loss: 0.37850886583328247, G Loss: 1.4726793766021729\n",
      "Epoch [12/50], Step [3300/7038], D Loss: 0.4306020736694336, G Loss: 1.1205263137817383\n",
      "Epoch [12/50], Step [3400/7038], D Loss: 0.5092903971672058, G Loss: 1.0981500148773193\n",
      "Epoch [12/50], Step [3500/7038], D Loss: 0.6379963159561157, G Loss: 1.0387119054794312\n",
      "Epoch [12/50], Step [3600/7038], D Loss: 0.2944796085357666, G Loss: 1.371502161026001\n",
      "Epoch [12/50], Step [3700/7038], D Loss: 0.33935004472732544, G Loss: 1.3266466856002808\n",
      "Epoch [12/50], Step [3800/7038], D Loss: 0.6262938976287842, G Loss: 0.885134220123291\n",
      "Epoch [12/50], Step [3900/7038], D Loss: 0.3039596676826477, G Loss: 1.519004225730896\n",
      "Epoch [12/50], Step [4000/7038], D Loss: 0.3989245891571045, G Loss: 1.3442379236221313\n",
      "Epoch [12/50], Step [4100/7038], D Loss: 0.39909207820892334, G Loss: 1.1704349517822266\n",
      "Epoch [12/50], Step [4200/7038], D Loss: 0.4487413167953491, G Loss: 1.5692634582519531\n",
      "Epoch [12/50], Step [4300/7038], D Loss: 0.39485469460487366, G Loss: 1.5793139934539795\n",
      "Epoch [12/50], Step [4400/7038], D Loss: 0.7144781351089478, G Loss: 1.4118319749832153\n",
      "Epoch [12/50], Step [4500/7038], D Loss: 0.9165962934494019, G Loss: 0.9609288573265076\n",
      "Epoch [12/50], Step [4600/7038], D Loss: 0.46983832120895386, G Loss: 1.266477108001709\n",
      "Epoch [12/50], Step [4700/7038], D Loss: 0.6257609724998474, G Loss: 1.0101993083953857\n",
      "Epoch [12/50], Step [4800/7038], D Loss: 0.5109159350395203, G Loss: 1.1204578876495361\n",
      "Epoch [12/50], Step [4900/7038], D Loss: 0.49035578966140747, G Loss: 1.3053687810897827\n",
      "Epoch [12/50], Step [5000/7038], D Loss: 0.43993598222732544, G Loss: 1.4049506187438965\n",
      "Epoch [12/50], Step [5100/7038], D Loss: 0.799917995929718, G Loss: 1.3047893047332764\n",
      "Epoch [12/50], Step [5200/7038], D Loss: 0.5881025791168213, G Loss: 1.180991768836975\n",
      "Epoch [12/50], Step [5300/7038], D Loss: 0.5590177774429321, G Loss: 1.1589888334274292\n",
      "Epoch [12/50], Step [5400/7038], D Loss: 0.45811572670936584, G Loss: 1.269749641418457\n",
      "Epoch [12/50], Step [5500/7038], D Loss: 0.4086548686027527, G Loss: 1.135573387145996\n",
      "Epoch [12/50], Step [5600/7038], D Loss: 0.5668935775756836, G Loss: 0.969274640083313\n",
      "Epoch [12/50], Step [5700/7038], D Loss: 0.5880997180938721, G Loss: 1.0937305688858032\n",
      "Epoch [12/50], Step [5800/7038], D Loss: 0.5357313752174377, G Loss: 1.570680856704712\n",
      "Epoch [12/50], Step [5900/7038], D Loss: 0.4875407814979553, G Loss: 1.1564691066741943\n",
      "Epoch [12/50], Step [6000/7038], D Loss: 0.5391476154327393, G Loss: 1.2943028211593628\n",
      "Epoch [12/50], Step [6100/7038], D Loss: 0.5475802421569824, G Loss: 1.414250373840332\n",
      "Epoch [12/50], Step [6200/7038], D Loss: 0.4532009959220886, G Loss: 1.308404803276062\n",
      "Epoch [12/50], Step [6300/7038], D Loss: 0.5062423944473267, G Loss: 1.077532410621643\n",
      "Epoch [12/50], Step [6400/7038], D Loss: 0.705504834651947, G Loss: 1.126854419708252\n",
      "Epoch [12/50], Step [6500/7038], D Loss: 0.3861025869846344, G Loss: 1.5128377676010132\n",
      "Epoch [12/50], Step [6600/7038], D Loss: 0.4976097047328949, G Loss: 1.3809356689453125\n",
      "Epoch [12/50], Step [6700/7038], D Loss: 0.5047190189361572, G Loss: 1.2318947315216064\n",
      "Epoch [12/50], Step [6800/7038], D Loss: 0.4129759967327118, G Loss: 1.5428612232208252\n",
      "Epoch [12/50], Step [6900/7038], D Loss: 0.3909050226211548, G Loss: 1.488523006439209\n",
      "Epoch [12/50], Step [7000/7038], D Loss: 0.4122732877731323, G Loss: 1.646743893623352\n",
      "Epoch [13/50], Step [0/7038], D Loss: 0.40936970710754395, G Loss: 1.443647027015686\n",
      "Epoch [13/50], Step [100/7038], D Loss: 0.4167625904083252, G Loss: 1.2534139156341553\n",
      "Epoch [13/50], Step [200/7038], D Loss: 0.4430316090583801, G Loss: 1.2720597982406616\n",
      "Epoch [13/50], Step [300/7038], D Loss: 0.4761357307434082, G Loss: 1.5047887563705444\n",
      "Epoch [13/50], Step [400/7038], D Loss: 0.42752504348754883, G Loss: 1.5098774433135986\n",
      "Epoch [13/50], Step [500/7038], D Loss: 0.6093255281448364, G Loss: 1.2043824195861816\n",
      "Epoch [13/50], Step [600/7038], D Loss: 0.4873505234718323, G Loss: 1.478339433670044\n",
      "Epoch [13/50], Step [700/7038], D Loss: 0.3827957212924957, G Loss: 1.5535480976104736\n",
      "Epoch [13/50], Step [800/7038], D Loss: 0.617997944355011, G Loss: 1.3956815004348755\n",
      "Epoch [13/50], Step [900/7038], D Loss: 0.3535007834434509, G Loss: 1.3148810863494873\n",
      "Epoch [13/50], Step [1000/7038], D Loss: 0.7602783441543579, G Loss: 1.5789604187011719\n",
      "Epoch [13/50], Step [1100/7038], D Loss: 0.5257729291915894, G Loss: 1.0621389150619507\n",
      "Epoch [13/50], Step [1200/7038], D Loss: 0.42786264419555664, G Loss: 1.444730520248413\n",
      "Epoch [13/50], Step [1300/7038], D Loss: 0.5323531627655029, G Loss: 1.111606478691101\n",
      "Epoch [13/50], Step [1400/7038], D Loss: 0.5749768018722534, G Loss: 0.9878842830657959\n",
      "Epoch [13/50], Step [1500/7038], D Loss: 0.38210275769233704, G Loss: 1.7430081367492676\n",
      "Epoch [13/50], Step [1600/7038], D Loss: 0.556860625743866, G Loss: 1.456489086151123\n",
      "Epoch [13/50], Step [1700/7038], D Loss: 0.5756686925888062, G Loss: 1.263247013092041\n",
      "Epoch [13/50], Step [1800/7038], D Loss: 0.46076270937919617, G Loss: 1.127710223197937\n",
      "Epoch [13/50], Step [1900/7038], D Loss: 0.3286438584327698, G Loss: 1.4186676740646362\n",
      "Epoch [13/50], Step [2000/7038], D Loss: 0.4805625081062317, G Loss: 1.3952465057373047\n",
      "Epoch [13/50], Step [2100/7038], D Loss: 0.4431116580963135, G Loss: 1.1860231161117554\n",
      "Epoch [13/50], Step [2200/7038], D Loss: 0.5568509101867676, G Loss: 1.059080958366394\n",
      "Epoch [13/50], Step [2300/7038], D Loss: 0.6346303224563599, G Loss: 1.304740071296692\n",
      "Epoch [13/50], Step [2400/7038], D Loss: 0.6239026784896851, G Loss: 1.1347445249557495\n",
      "Epoch [13/50], Step [2500/7038], D Loss: 0.5935453176498413, G Loss: 1.803832769393921\n",
      "Epoch [13/50], Step [2600/7038], D Loss: 0.6544539332389832, G Loss: 0.8744716048240662\n",
      "Epoch [13/50], Step [2700/7038], D Loss: 0.568295419216156, G Loss: 1.0209403038024902\n",
      "Epoch [13/50], Step [2800/7038], D Loss: 0.44224947690963745, G Loss: 1.7013194561004639\n",
      "Epoch [13/50], Step [2900/7038], D Loss: 0.7107336521148682, G Loss: 1.1089274883270264\n",
      "Epoch [13/50], Step [3000/7038], D Loss: 0.5653765797615051, G Loss: 1.3605724573135376\n",
      "Epoch [13/50], Step [3100/7038], D Loss: 0.3417031764984131, G Loss: 1.6078314781188965\n",
      "Epoch [13/50], Step [3200/7038], D Loss: 0.5489168167114258, G Loss: 1.1823369264602661\n",
      "Epoch [13/50], Step [3300/7038], D Loss: 0.6423972249031067, G Loss: 1.2385461330413818\n",
      "Epoch [13/50], Step [3400/7038], D Loss: 0.6787358522415161, G Loss: 1.0475645065307617\n",
      "Epoch [13/50], Step [3500/7038], D Loss: 0.38601863384246826, G Loss: 1.2071248292922974\n",
      "Epoch [13/50], Step [3600/7038], D Loss: 0.4875171184539795, G Loss: 1.3939979076385498\n",
      "Epoch [13/50], Step [3700/7038], D Loss: 0.42112502455711365, G Loss: 1.4266122579574585\n",
      "Epoch [13/50], Step [3800/7038], D Loss: 0.8097814321517944, G Loss: 1.551903247833252\n",
      "Epoch [13/50], Step [3900/7038], D Loss: 0.2870199680328369, G Loss: 1.8638832569122314\n",
      "Epoch [13/50], Step [4000/7038], D Loss: 0.49979421496391296, G Loss: 1.286034107208252\n",
      "Epoch [13/50], Step [4100/7038], D Loss: 0.5361971855163574, G Loss: 1.3537544012069702\n",
      "Epoch [13/50], Step [4200/7038], D Loss: 0.6878633499145508, G Loss: 1.2753820419311523\n",
      "Epoch [13/50], Step [4300/7038], D Loss: 0.5926920771598816, G Loss: 1.3227810859680176\n",
      "Epoch [13/50], Step [4400/7038], D Loss: 0.43539464473724365, G Loss: 1.620451807975769\n",
      "Epoch [13/50], Step [4500/7038], D Loss: 0.7032904624938965, G Loss: 1.0556721687316895\n",
      "Epoch [13/50], Step [4600/7038], D Loss: 0.5750844478607178, G Loss: 0.9668667912483215\n",
      "Epoch [13/50], Step [4700/7038], D Loss: 0.4053834080696106, G Loss: 1.4100518226623535\n",
      "Epoch [13/50], Step [4800/7038], D Loss: 0.30890941619873047, G Loss: 1.7808302640914917\n",
      "Epoch [13/50], Step [4900/7038], D Loss: 0.6221553087234497, G Loss: 0.8372890949249268\n",
      "Epoch [13/50], Step [5000/7038], D Loss: 0.5619670748710632, G Loss: 1.2696905136108398\n",
      "Epoch [13/50], Step [5100/7038], D Loss: 0.6181517839431763, G Loss: 1.2971441745758057\n",
      "Epoch [13/50], Step [5200/7038], D Loss: 0.787293553352356, G Loss: 1.0747973918914795\n",
      "Epoch [13/50], Step [5300/7038], D Loss: 0.48129379749298096, G Loss: 1.1264684200286865\n",
      "Epoch [13/50], Step [5400/7038], D Loss: 0.5419570207595825, G Loss: 0.8885196447372437\n",
      "Epoch [13/50], Step [5500/7038], D Loss: 0.7847727537155151, G Loss: 1.0437692403793335\n",
      "Epoch [13/50], Step [5600/7038], D Loss: 0.9059705138206482, G Loss: 1.2597248554229736\n",
      "Epoch [13/50], Step [5700/7038], D Loss: 0.6270145177841187, G Loss: 1.2407846450805664\n",
      "Epoch [13/50], Step [5800/7038], D Loss: 0.40885400772094727, G Loss: 1.0303703546524048\n",
      "Epoch [13/50], Step [5900/7038], D Loss: 0.36495786905288696, G Loss: 1.4923405647277832\n",
      "Epoch [13/50], Step [6000/7038], D Loss: 0.43763506412506104, G Loss: 1.2600131034851074\n",
      "Epoch [13/50], Step [6100/7038], D Loss: 0.5157918930053711, G Loss: 1.066884994506836\n",
      "Epoch [13/50], Step [6200/7038], D Loss: 0.44821298122406006, G Loss: 1.3141804933547974\n",
      "Epoch [13/50], Step [6300/7038], D Loss: 0.35460615158081055, G Loss: 1.8452967405319214\n",
      "Epoch [13/50], Step [6400/7038], D Loss: 0.38892072439193726, G Loss: 1.3439513444900513\n",
      "Epoch [13/50], Step [6500/7038], D Loss: 0.6313557028770447, G Loss: 1.025763750076294\n",
      "Epoch [13/50], Step [6600/7038], D Loss: 0.46634870767593384, G Loss: 1.0653809309005737\n",
      "Epoch [13/50], Step [6700/7038], D Loss: 0.6368370056152344, G Loss: 0.8292409181594849\n",
      "Epoch [13/50], Step [6800/7038], D Loss: 0.3617888391017914, G Loss: 1.455980896949768\n",
      "Epoch [13/50], Step [6900/7038], D Loss: 0.5754433870315552, G Loss: 1.218403697013855\n",
      "Epoch [13/50], Step [7000/7038], D Loss: 0.7111120223999023, G Loss: 0.9647680521011353\n",
      "Epoch [14/50], Step [0/7038], D Loss: 0.48152947425842285, G Loss: 1.279280424118042\n",
      "Epoch [14/50], Step [100/7038], D Loss: 0.545120358467102, G Loss: 1.7539844512939453\n",
      "Epoch [14/50], Step [200/7038], D Loss: 0.5302741527557373, G Loss: 1.1875416040420532\n",
      "Epoch [14/50], Step [300/7038], D Loss: 0.5761837959289551, G Loss: 1.5404304265975952\n",
      "Epoch [14/50], Step [400/7038], D Loss: 0.38453665375709534, G Loss: 1.551098108291626\n",
      "Epoch [14/50], Step [500/7038], D Loss: 0.6893502473831177, G Loss: 0.9456784725189209\n",
      "Epoch [14/50], Step [600/7038], D Loss: 0.5699220895767212, G Loss: 1.306939959526062\n",
      "Epoch [14/50], Step [700/7038], D Loss: 0.534367561340332, G Loss: 1.327396035194397\n",
      "Epoch [14/50], Step [800/7038], D Loss: 0.5516303181648254, G Loss: 0.9913136959075928\n",
      "Epoch [14/50], Step [900/7038], D Loss: 0.5490584969520569, G Loss: 1.2209360599517822\n",
      "Epoch [14/50], Step [1000/7038], D Loss: 0.5089204907417297, G Loss: 1.3081415891647339\n",
      "Epoch [14/50], Step [1100/7038], D Loss: 0.6298732757568359, G Loss: 1.3393418788909912\n",
      "Epoch [14/50], Step [1200/7038], D Loss: 0.5914021134376526, G Loss: 1.3891801834106445\n",
      "Epoch [14/50], Step [1300/7038], D Loss: 0.7605668306350708, G Loss: 2.478524923324585\n",
      "Epoch [14/50], Step [1400/7038], D Loss: 0.4528751075267792, G Loss: 1.340528964996338\n",
      "Epoch [14/50], Step [1500/7038], D Loss: 0.4811824560165405, G Loss: 1.371429443359375\n",
      "Epoch [14/50], Step [1600/7038], D Loss: 0.43628066778182983, G Loss: 1.4027905464172363\n",
      "Epoch [14/50], Step [1700/7038], D Loss: 0.8434419631958008, G Loss: 1.1762827634811401\n",
      "Epoch [14/50], Step [1800/7038], D Loss: 0.5201613903045654, G Loss: 1.2900147438049316\n",
      "Epoch [14/50], Step [1900/7038], D Loss: 0.630966067314148, G Loss: 0.9745844602584839\n",
      "Epoch [14/50], Step [2000/7038], D Loss: 0.7926200032234192, G Loss: 1.0564616918563843\n",
      "Epoch [14/50], Step [2100/7038], D Loss: 0.5051981210708618, G Loss: 1.2068337202072144\n",
      "Epoch [14/50], Step [2200/7038], D Loss: 0.6154309511184692, G Loss: 1.161328673362732\n",
      "Epoch [14/50], Step [2300/7038], D Loss: 0.5852715969085693, G Loss: 1.115885615348816\n",
      "Epoch [14/50], Step [2400/7038], D Loss: 0.48170244693756104, G Loss: 1.336891531944275\n",
      "Epoch [14/50], Step [2500/7038], D Loss: 0.7376627326011658, G Loss: 1.1679205894470215\n",
      "Epoch [14/50], Step [2600/7038], D Loss: 0.364360511302948, G Loss: 1.2843492031097412\n",
      "Epoch [14/50], Step [2700/7038], D Loss: 0.4944624900817871, G Loss: 1.5700037479400635\n",
      "Epoch [14/50], Step [2800/7038], D Loss: 0.5295510292053223, G Loss: 1.4422416687011719\n",
      "Epoch [14/50], Step [2900/7038], D Loss: 0.5996794700622559, G Loss: 1.113243579864502\n",
      "Epoch [14/50], Step [3000/7038], D Loss: 0.41808900237083435, G Loss: 1.288967251777649\n",
      "Epoch [14/50], Step [3100/7038], D Loss: 0.6619967222213745, G Loss: 1.5165107250213623\n",
      "Epoch [14/50], Step [3200/7038], D Loss: 0.4967374801635742, G Loss: 1.3865543603897095\n",
      "Epoch [14/50], Step [3300/7038], D Loss: 0.4432080090045929, G Loss: 1.5480363368988037\n",
      "Epoch [14/50], Step [3400/7038], D Loss: 0.4434683322906494, G Loss: 1.2920598983764648\n",
      "Epoch [14/50], Step [3500/7038], D Loss: 0.36807987093925476, G Loss: 1.44483482837677\n",
      "Epoch [14/50], Step [3600/7038], D Loss: 0.5332545638084412, G Loss: 1.5482933521270752\n",
      "Epoch [14/50], Step [3700/7038], D Loss: 0.5579797029495239, G Loss: 1.006466269493103\n",
      "Epoch [14/50], Step [3800/7038], D Loss: 0.5109668970108032, G Loss: 1.2345895767211914\n",
      "Epoch [14/50], Step [3900/7038], D Loss: 0.7283826470375061, G Loss: 1.0556244850158691\n",
      "Epoch [14/50], Step [4000/7038], D Loss: 0.441913366317749, G Loss: 1.1889891624450684\n",
      "Epoch [14/50], Step [4100/7038], D Loss: 0.3673093914985657, G Loss: 1.2960094213485718\n",
      "Epoch [14/50], Step [4200/7038], D Loss: 0.5038875341415405, G Loss: 1.077497959136963\n",
      "Epoch [14/50], Step [4300/7038], D Loss: 0.6144213676452637, G Loss: 1.9989376068115234\n",
      "Epoch [14/50], Step [4400/7038], D Loss: 0.5757846236228943, G Loss: 1.1054474115371704\n",
      "Epoch [14/50], Step [4500/7038], D Loss: 0.3869769275188446, G Loss: 1.3336172103881836\n",
      "Epoch [14/50], Step [4600/7038], D Loss: 0.5985866785049438, G Loss: 0.9351673722267151\n",
      "Epoch [14/50], Step [4700/7038], D Loss: 0.8468512296676636, G Loss: 1.0872834920883179\n",
      "Epoch [14/50], Step [4800/7038], D Loss: 0.7198436856269836, G Loss: 0.8072049021720886\n",
      "Epoch [14/50], Step [4900/7038], D Loss: 0.7080347537994385, G Loss: 1.2163360118865967\n",
      "Epoch [14/50], Step [5000/7038], D Loss: 0.5423820614814758, G Loss: 1.2052676677703857\n",
      "Epoch [14/50], Step [5100/7038], D Loss: 0.5798217058181763, G Loss: 1.3003123998641968\n",
      "Epoch [14/50], Step [5200/7038], D Loss: 0.4325934946537018, G Loss: 1.5155080556869507\n",
      "Epoch [14/50], Step [5300/7038], D Loss: 0.6406792998313904, G Loss: 1.152829885482788\n",
      "Epoch [14/50], Step [5400/7038], D Loss: 0.4754699468612671, G Loss: 1.1670327186584473\n",
      "Epoch [14/50], Step [5500/7038], D Loss: 0.3728078007698059, G Loss: 1.5712711811065674\n",
      "Epoch [14/50], Step [5600/7038], D Loss: 0.5754327774047852, G Loss: 1.1305055618286133\n",
      "Epoch [14/50], Step [5700/7038], D Loss: 0.5051342248916626, G Loss: 1.1353869438171387\n",
      "Epoch [14/50], Step [5800/7038], D Loss: 0.5179033875465393, G Loss: 1.3831102848052979\n",
      "Epoch [14/50], Step [5900/7038], D Loss: 0.4596538543701172, G Loss: 1.2873252630233765\n",
      "Epoch [14/50], Step [6000/7038], D Loss: 0.7125813961029053, G Loss: 1.231236219406128\n",
      "Epoch [14/50], Step [6100/7038], D Loss: 0.26605501770973206, G Loss: 1.7489900588989258\n",
      "Epoch [14/50], Step [6200/7038], D Loss: 0.6404728293418884, G Loss: 0.909337043762207\n",
      "Epoch [14/50], Step [6300/7038], D Loss: 0.42290329933166504, G Loss: 1.125577688217163\n",
      "Epoch [14/50], Step [6400/7038], D Loss: 0.6185635924339294, G Loss: 1.2722563743591309\n",
      "Epoch [14/50], Step [6500/7038], D Loss: 0.4740908145904541, G Loss: 1.3505158424377441\n",
      "Epoch [14/50], Step [6600/7038], D Loss: 0.5489598512649536, G Loss: 1.0116426944732666\n",
      "Epoch [14/50], Step [6700/7038], D Loss: 0.4666024148464203, G Loss: 1.2377063035964966\n",
      "Epoch [14/50], Step [6800/7038], D Loss: 0.7818414568901062, G Loss: 1.4913603067398071\n",
      "Epoch [14/50], Step [6900/7038], D Loss: 0.7732569575309753, G Loss: 0.9125841856002808\n",
      "Epoch [14/50], Step [7000/7038], D Loss: 0.3817657232284546, G Loss: 1.4929015636444092\n",
      "Epoch [15/50], Step [0/7038], D Loss: 0.4717209041118622, G Loss: 1.8624167442321777\n",
      "Epoch [15/50], Step [100/7038], D Loss: 0.41509485244750977, G Loss: 1.2391408681869507\n",
      "Epoch [15/50], Step [200/7038], D Loss: 0.46170711517333984, G Loss: 1.2936089038848877\n",
      "Epoch [15/50], Step [300/7038], D Loss: 0.44171661138534546, G Loss: 1.4872602224349976\n",
      "Epoch [15/50], Step [400/7038], D Loss: 0.40965452790260315, G Loss: 1.6433745622634888\n",
      "Epoch [15/50], Step [500/7038], D Loss: 0.851244330406189, G Loss: 1.1359370946884155\n",
      "Epoch [15/50], Step [600/7038], D Loss: 0.3951464891433716, G Loss: 1.7773380279541016\n",
      "Epoch [15/50], Step [700/7038], D Loss: 0.6730911731719971, G Loss: 1.1139582395553589\n",
      "Epoch [15/50], Step [800/7038], D Loss: 0.5025489926338196, G Loss: 1.2404639720916748\n",
      "Epoch [15/50], Step [900/7038], D Loss: 0.40677136182785034, G Loss: 1.749606728553772\n",
      "Epoch [15/50], Step [1000/7038], D Loss: 0.7251021862030029, G Loss: 1.097894549369812\n",
      "Epoch [15/50], Step [1100/7038], D Loss: 0.43995532393455505, G Loss: 1.407711386680603\n",
      "Epoch [15/50], Step [1200/7038], D Loss: 0.5133635997772217, G Loss: 1.5755404233932495\n",
      "Epoch [15/50], Step [1300/7038], D Loss: 0.4586654603481293, G Loss: 1.0728117227554321\n",
      "Epoch [15/50], Step [1400/7038], D Loss: 0.5645318031311035, G Loss: 1.6014323234558105\n",
      "Epoch [15/50], Step [1500/7038], D Loss: 0.56736159324646, G Loss: 1.146670937538147\n",
      "Epoch [15/50], Step [1600/7038], D Loss: 0.4343317449092865, G Loss: 1.5460537672042847\n",
      "Epoch [15/50], Step [1700/7038], D Loss: 0.4941829741001129, G Loss: 1.1485209465026855\n",
      "Epoch [15/50], Step [1800/7038], D Loss: 0.5755612850189209, G Loss: 1.0402393341064453\n",
      "Epoch [15/50], Step [1900/7038], D Loss: 0.49469855427742004, G Loss: 1.3815138339996338\n",
      "Epoch [15/50], Step [2000/7038], D Loss: 0.795176088809967, G Loss: 1.0898187160491943\n",
      "Epoch [15/50], Step [2100/7038], D Loss: 0.4446674883365631, G Loss: 1.339016079902649\n",
      "Epoch [15/50], Step [2200/7038], D Loss: 0.6904951333999634, G Loss: 1.1320325136184692\n",
      "Epoch [15/50], Step [2300/7038], D Loss: 0.671631395816803, G Loss: 1.0903031826019287\n",
      "Epoch [15/50], Step [2400/7038], D Loss: 0.7202185392379761, G Loss: 1.1548988819122314\n",
      "Epoch [15/50], Step [2500/7038], D Loss: 0.7316229343414307, G Loss: 1.6519960165023804\n",
      "Epoch [15/50], Step [2600/7038], D Loss: 0.564512312412262, G Loss: 1.3903826475143433\n",
      "Epoch [15/50], Step [2700/7038], D Loss: 0.49679601192474365, G Loss: 1.2620011568069458\n",
      "Epoch [15/50], Step [2800/7038], D Loss: 0.36083707213401794, G Loss: 1.5456137657165527\n",
      "Epoch [15/50], Step [2900/7038], D Loss: 0.48899412155151367, G Loss: 1.1043540239334106\n",
      "Epoch [15/50], Step [3000/7038], D Loss: 0.6869920492172241, G Loss: 1.0128804445266724\n",
      "Epoch [15/50], Step [3100/7038], D Loss: 0.3460869789123535, G Loss: 1.7452340126037598\n",
      "Epoch [15/50], Step [3200/7038], D Loss: 0.6670770049095154, G Loss: 1.6729635000228882\n",
      "Epoch [15/50], Step [3300/7038], D Loss: 0.3175019919872284, G Loss: 1.6373552083969116\n",
      "Epoch [15/50], Step [3400/7038], D Loss: 0.6063913106918335, G Loss: 1.3486706018447876\n",
      "Epoch [15/50], Step [3500/7038], D Loss: 0.6095967888832092, G Loss: 1.0069396495819092\n",
      "Epoch [15/50], Step [3600/7038], D Loss: 0.7329157590866089, G Loss: 0.9239299297332764\n",
      "Epoch [15/50], Step [3700/7038], D Loss: 0.5007219314575195, G Loss: 1.5999929904937744\n",
      "Epoch [15/50], Step [3800/7038], D Loss: 0.6926234364509583, G Loss: 1.3695368766784668\n",
      "Epoch [15/50], Step [3900/7038], D Loss: 0.6021374464035034, G Loss: 1.0535991191864014\n",
      "Epoch [15/50], Step [4000/7038], D Loss: 0.6228722929954529, G Loss: 0.9055215120315552\n",
      "Epoch [15/50], Step [4100/7038], D Loss: 0.4719344973564148, G Loss: 0.8997129797935486\n",
      "Epoch [15/50], Step [4200/7038], D Loss: 0.6607992649078369, G Loss: 1.5888577699661255\n",
      "Epoch [15/50], Step [4300/7038], D Loss: 0.44648176431655884, G Loss: 1.0954071283340454\n",
      "Epoch [15/50], Step [4400/7038], D Loss: 0.6543229818344116, G Loss: 1.2531328201293945\n",
      "Epoch [15/50], Step [4500/7038], D Loss: 0.8034706711769104, G Loss: 1.2252329587936401\n",
      "Epoch [15/50], Step [4600/7038], D Loss: 0.5638373494148254, G Loss: 1.839970588684082\n",
      "Epoch [15/50], Step [4700/7038], D Loss: 0.7830511331558228, G Loss: 1.092747688293457\n",
      "Epoch [15/50], Step [4800/7038], D Loss: 0.644767165184021, G Loss: 0.9619408249855042\n",
      "Epoch [15/50], Step [4900/7038], D Loss: 0.7008386850357056, G Loss: 1.1940215826034546\n",
      "Epoch [15/50], Step [5000/7038], D Loss: 1.0023003816604614, G Loss: 3.5699994564056396\n",
      "Epoch [15/50], Step [5100/7038], D Loss: 0.7518318295478821, G Loss: 1.1004177331924438\n",
      "Epoch [15/50], Step [5200/7038], D Loss: 0.6414309740066528, G Loss: 1.0880396366119385\n",
      "Epoch [15/50], Step [5300/7038], D Loss: 0.4283313751220703, G Loss: 1.3608585596084595\n",
      "Epoch [15/50], Step [5400/7038], D Loss: 0.36276257038116455, G Loss: 1.5772895812988281\n",
      "Epoch [15/50], Step [5500/7038], D Loss: 0.40362492203712463, G Loss: 1.9339582920074463\n",
      "Epoch [15/50], Step [5600/7038], D Loss: 0.5507548451423645, G Loss: 0.9670715928077698\n",
      "Epoch [15/50], Step [5700/7038], D Loss: 0.7415045499801636, G Loss: 0.9987568855285645\n",
      "Epoch [15/50], Step [5800/7038], D Loss: 0.4720301330089569, G Loss: 1.443636178970337\n",
      "Epoch [15/50], Step [5900/7038], D Loss: 0.5743787884712219, G Loss: 1.6706929206848145\n",
      "Epoch [15/50], Step [6000/7038], D Loss: 0.44165951013565063, G Loss: 1.147555947303772\n",
      "Epoch [15/50], Step [6100/7038], D Loss: 0.31977200508117676, G Loss: 1.6023471355438232\n",
      "Epoch [15/50], Step [6200/7038], D Loss: 0.5105690360069275, G Loss: 1.3127135038375854\n",
      "Epoch [15/50], Step [6300/7038], D Loss: 0.45788896083831787, G Loss: 1.1192395687103271\n",
      "Epoch [15/50], Step [6400/7038], D Loss: 0.46890342235565186, G Loss: 1.0854551792144775\n",
      "Epoch [15/50], Step [6500/7038], D Loss: 0.5279050469398499, G Loss: 1.022355079650879\n",
      "Epoch [15/50], Step [6600/7038], D Loss: 0.5577328205108643, G Loss: 1.1310261487960815\n",
      "Epoch [15/50], Step [6700/7038], D Loss: 0.6951323747634888, G Loss: 1.3851845264434814\n",
      "Epoch [15/50], Step [6800/7038], D Loss: 0.6039865612983704, G Loss: 1.13950777053833\n",
      "Epoch [15/50], Step [6900/7038], D Loss: 0.45567548274993896, G Loss: 1.161820411682129\n",
      "Epoch [15/50], Step [7000/7038], D Loss: 0.49426281452178955, G Loss: 1.207485556602478\n",
      "Epoch [16/50], Step [0/7038], D Loss: 0.640747606754303, G Loss: 0.8670741319656372\n",
      "Epoch [16/50], Step [100/7038], D Loss: 0.38230884075164795, G Loss: 1.2007945775985718\n",
      "Epoch [16/50], Step [200/7038], D Loss: 0.5529849529266357, G Loss: 1.3777062892913818\n",
      "Epoch [16/50], Step [300/7038], D Loss: 0.4632423520088196, G Loss: 1.0017439126968384\n",
      "Epoch [16/50], Step [400/7038], D Loss: 0.37115103006362915, G Loss: 1.6243577003479004\n",
      "Epoch [16/50], Step [500/7038], D Loss: 0.6353347301483154, G Loss: 1.162819743156433\n",
      "Epoch [16/50], Step [600/7038], D Loss: 0.5803987383842468, G Loss: 1.4486172199249268\n",
      "Epoch [16/50], Step [700/7038], D Loss: 0.5814701318740845, G Loss: 1.2225573062896729\n",
      "Epoch [16/50], Step [800/7038], D Loss: 0.6005536317825317, G Loss: 1.2634321451187134\n",
      "Epoch [16/50], Step [900/7038], D Loss: 0.33020418882369995, G Loss: 1.314318060874939\n",
      "Epoch [16/50], Step [1000/7038], D Loss: 0.42106279730796814, G Loss: 1.1898928880691528\n",
      "Epoch [16/50], Step [1100/7038], D Loss: 0.4200361371040344, G Loss: 1.3460692167282104\n",
      "Epoch [16/50], Step [1200/7038], D Loss: 0.7353383302688599, G Loss: 0.8539965152740479\n",
      "Epoch [16/50], Step [1300/7038], D Loss: 0.4354965090751648, G Loss: 1.452113389968872\n",
      "Epoch [16/50], Step [1400/7038], D Loss: 0.5277073979377747, G Loss: 1.0195302963256836\n",
      "Epoch [16/50], Step [1500/7038], D Loss: 0.6030211448669434, G Loss: 0.8923799991607666\n",
      "Epoch [16/50], Step [1600/7038], D Loss: 0.475261390209198, G Loss: 1.3752930164337158\n",
      "Epoch [16/50], Step [1700/7038], D Loss: 0.4009873867034912, G Loss: 1.45770263671875\n",
      "Epoch [16/50], Step [1800/7038], D Loss: 0.4005642831325531, G Loss: 1.3393256664276123\n",
      "Epoch [16/50], Step [1900/7038], D Loss: 0.4613141715526581, G Loss: 1.183790922164917\n",
      "Epoch [16/50], Step [2000/7038], D Loss: 0.46927380561828613, G Loss: 1.2704670429229736\n",
      "Epoch [16/50], Step [2100/7038], D Loss: 0.4605231285095215, G Loss: 1.1080029010772705\n",
      "Epoch [16/50], Step [2200/7038], D Loss: 0.6178351044654846, G Loss: 1.0880614519119263\n",
      "Epoch [16/50], Step [2300/7038], D Loss: 0.5118834972381592, G Loss: 1.1718857288360596\n",
      "Epoch [16/50], Step [2400/7038], D Loss: 0.6875201463699341, G Loss: 1.5716297626495361\n",
      "Epoch [16/50], Step [2500/7038], D Loss: 0.44823965430259705, G Loss: 1.1639741659164429\n",
      "Epoch [16/50], Step [2600/7038], D Loss: 0.5832281112670898, G Loss: 1.3920581340789795\n",
      "Epoch [16/50], Step [2700/7038], D Loss: 0.5389449596405029, G Loss: 1.0411770343780518\n",
      "Epoch [16/50], Step [2800/7038], D Loss: 0.4952937364578247, G Loss: 1.4679474830627441\n",
      "Epoch [16/50], Step [2900/7038], D Loss: 0.7672731876373291, G Loss: 1.0325398445129395\n",
      "Epoch [16/50], Step [3000/7038], D Loss: 0.6589558720588684, G Loss: 1.1621050834655762\n",
      "Epoch [16/50], Step [3100/7038], D Loss: 0.6177892684936523, G Loss: 1.2344790697097778\n",
      "Epoch [16/50], Step [3200/7038], D Loss: 0.3537769615650177, G Loss: 1.566605806350708\n",
      "Epoch [16/50], Step [3300/7038], D Loss: 0.39160096645355225, G Loss: 1.275819182395935\n",
      "Epoch [16/50], Step [3400/7038], D Loss: 0.343178391456604, G Loss: 1.554771065711975\n",
      "Epoch [16/50], Step [3500/7038], D Loss: 0.9113498330116272, G Loss: 1.2357652187347412\n",
      "Epoch [16/50], Step [3600/7038], D Loss: 0.5608233213424683, G Loss: 1.6165488958358765\n",
      "Epoch [16/50], Step [3700/7038], D Loss: 0.4479601979255676, G Loss: 1.1101419925689697\n",
      "Epoch [16/50], Step [3800/7038], D Loss: 0.435430109500885, G Loss: 1.1204067468643188\n",
      "Epoch [16/50], Step [3900/7038], D Loss: 0.4591907262802124, G Loss: 1.3286693096160889\n",
      "Epoch [16/50], Step [4000/7038], D Loss: 0.6459690928459167, G Loss: 0.9127703905105591\n",
      "Epoch [16/50], Step [4100/7038], D Loss: 0.8375979661941528, G Loss: 1.2278690338134766\n",
      "Epoch [16/50], Step [4200/7038], D Loss: 0.5601247549057007, G Loss: 1.4968605041503906\n",
      "Epoch [16/50], Step [4300/7038], D Loss: 0.5322118997573853, G Loss: 1.3745778799057007\n",
      "Epoch [16/50], Step [4400/7038], D Loss: 0.5053185224533081, G Loss: 1.6718149185180664\n",
      "Epoch [16/50], Step [4500/7038], D Loss: 0.46833908557891846, G Loss: 1.5361876487731934\n",
      "Epoch [16/50], Step [4600/7038], D Loss: 0.27932482957839966, G Loss: 1.7220468521118164\n",
      "Epoch [16/50], Step [4700/7038], D Loss: 0.3425731360912323, G Loss: 2.0154078006744385\n",
      "Epoch [16/50], Step [4800/7038], D Loss: 0.6054624915122986, G Loss: 1.0719530582427979\n",
      "Epoch [16/50], Step [4900/7038], D Loss: 0.6228910684585571, G Loss: 0.955255389213562\n",
      "Epoch [16/50], Step [5000/7038], D Loss: 0.5225386619567871, G Loss: 1.4215596914291382\n",
      "Epoch [16/50], Step [5100/7038], D Loss: 0.518794596195221, G Loss: 1.232923150062561\n",
      "Epoch [16/50], Step [5200/7038], D Loss: 0.4091113209724426, G Loss: 1.4683111906051636\n",
      "Epoch [16/50], Step [5300/7038], D Loss: 0.6165501475334167, G Loss: 1.1095893383026123\n",
      "Epoch [16/50], Step [5400/7038], D Loss: 0.362064003944397, G Loss: 1.4248765707015991\n",
      "Epoch [16/50], Step [5500/7038], D Loss: 0.561615526676178, G Loss: 1.209717035293579\n",
      "Epoch [16/50], Step [5600/7038], D Loss: 0.40381619334220886, G Loss: 1.5994726419448853\n",
      "Epoch [16/50], Step [5700/7038], D Loss: 0.3154768943786621, G Loss: 1.4494757652282715\n",
      "Epoch [16/50], Step [5800/7038], D Loss: 0.9093078374862671, G Loss: 1.3434803485870361\n",
      "Epoch [16/50], Step [5900/7038], D Loss: 1.0200648307800293, G Loss: 1.4770698547363281\n",
      "Epoch [16/50], Step [6000/7038], D Loss: 0.6000099182128906, G Loss: 1.2310612201690674\n",
      "Epoch [16/50], Step [6100/7038], D Loss: 0.5625276565551758, G Loss: 1.586958885192871\n",
      "Epoch [16/50], Step [6200/7038], D Loss: 0.867644727230072, G Loss: 1.3590408563613892\n",
      "Epoch [16/50], Step [6300/7038], D Loss: 0.4379623532295227, G Loss: 1.2304452657699585\n",
      "Epoch [16/50], Step [6400/7038], D Loss: 0.5007269382476807, G Loss: 1.0511876344680786\n",
      "Epoch [16/50], Step [6500/7038], D Loss: 0.6705116033554077, G Loss: 1.4070017337799072\n",
      "Epoch [16/50], Step [6600/7038], D Loss: 0.593228280544281, G Loss: 0.93477863073349\n",
      "Epoch [16/50], Step [6700/7038], D Loss: 0.8125327825546265, G Loss: 1.3068244457244873\n",
      "Epoch [16/50], Step [6800/7038], D Loss: 0.3952385485172272, G Loss: 1.3239140510559082\n",
      "Epoch [16/50], Step [6900/7038], D Loss: 0.39076799154281616, G Loss: 1.5411863327026367\n",
      "Epoch [16/50], Step [7000/7038], D Loss: 0.41955068707466125, G Loss: 1.5265768766403198\n",
      "Epoch [17/50], Step [0/7038], D Loss: 0.3732474446296692, G Loss: 1.474716305732727\n",
      "Epoch [17/50], Step [100/7038], D Loss: 0.41199731826782227, G Loss: 1.1871836185455322\n",
      "Epoch [17/50], Step [200/7038], D Loss: 0.5258793830871582, G Loss: 1.005961298942566\n",
      "Epoch [17/50], Step [300/7038], D Loss: 0.5099896192550659, G Loss: 1.4233744144439697\n",
      "Epoch [17/50], Step [400/7038], D Loss: 0.49481797218322754, G Loss: 1.632145643234253\n",
      "Epoch [17/50], Step [500/7038], D Loss: 0.7007666826248169, G Loss: 1.310361623764038\n",
      "Epoch [17/50], Step [600/7038], D Loss: 0.5205153226852417, G Loss: 1.3971413373947144\n",
      "Epoch [17/50], Step [700/7038], D Loss: 0.4636673331260681, G Loss: 2.0564708709716797\n",
      "Epoch [17/50], Step [800/7038], D Loss: 0.41589298844337463, G Loss: 1.1346832513809204\n",
      "Epoch [17/50], Step [900/7038], D Loss: 0.6574357748031616, G Loss: 1.619511365890503\n",
      "Epoch [17/50], Step [1000/7038], D Loss: 0.7525439262390137, G Loss: 1.2188597917556763\n",
      "Epoch [17/50], Step [1100/7038], D Loss: 0.744662880897522, G Loss: 1.027777910232544\n",
      "Epoch [17/50], Step [1200/7038], D Loss: 0.5823224782943726, G Loss: 1.0829824209213257\n",
      "Epoch [17/50], Step [1300/7038], D Loss: 0.18598365783691406, G Loss: 2.046220302581787\n",
      "Epoch [17/50], Step [1400/7038], D Loss: 0.5400924682617188, G Loss: 1.2235087156295776\n",
      "Epoch [17/50], Step [1500/7038], D Loss: 0.4200151264667511, G Loss: 1.2990896701812744\n",
      "Epoch [17/50], Step [1600/7038], D Loss: 0.42953211069107056, G Loss: 1.4106473922729492\n",
      "Epoch [17/50], Step [1700/7038], D Loss: 0.4952049255371094, G Loss: 1.0512397289276123\n",
      "Epoch [17/50], Step [1800/7038], D Loss: 0.34152376651763916, G Loss: 1.550947904586792\n",
      "Epoch [17/50], Step [1900/7038], D Loss: 0.6584550142288208, G Loss: 1.0739881992340088\n",
      "Epoch [17/50], Step [2000/7038], D Loss: 0.4172956943511963, G Loss: 1.310976505279541\n",
      "Epoch [17/50], Step [2100/7038], D Loss: 0.6251763105392456, G Loss: 1.3371562957763672\n",
      "Epoch [17/50], Step [2200/7038], D Loss: 0.8085572719573975, G Loss: 1.4808107614517212\n",
      "Epoch [17/50], Step [2300/7038], D Loss: 0.5032961368560791, G Loss: 1.2488161325454712\n",
      "Epoch [17/50], Step [2400/7038], D Loss: 0.370687335729599, G Loss: 1.442751169204712\n",
      "Epoch [17/50], Step [2500/7038], D Loss: 0.42049697041511536, G Loss: 0.9977300763130188\n",
      "Epoch [17/50], Step [2600/7038], D Loss: 0.49707546830177307, G Loss: 1.1730151176452637\n",
      "Epoch [17/50], Step [2700/7038], D Loss: 0.376096248626709, G Loss: 1.3747409582138062\n",
      "Epoch [17/50], Step [2800/7038], D Loss: 0.49501800537109375, G Loss: 1.3115687370300293\n",
      "Epoch [17/50], Step [2900/7038], D Loss: 0.4012107253074646, G Loss: 1.426185131072998\n",
      "Epoch [17/50], Step [3000/7038], D Loss: 0.35019418597221375, G Loss: 1.586951494216919\n",
      "Epoch [17/50], Step [3100/7038], D Loss: 0.5596993565559387, G Loss: 1.0126047134399414\n",
      "Epoch [17/50], Step [3200/7038], D Loss: 0.5603569149971008, G Loss: 1.052623987197876\n",
      "Epoch [17/50], Step [3300/7038], D Loss: 0.5248820185661316, G Loss: 1.9910104274749756\n",
      "Epoch [17/50], Step [3400/7038], D Loss: 0.44372984766960144, G Loss: 1.470130443572998\n",
      "Epoch [17/50], Step [3500/7038], D Loss: 0.7059369087219238, G Loss: 1.3008358478546143\n",
      "Epoch [17/50], Step [3600/7038], D Loss: 0.6594328880310059, G Loss: 1.2525407075881958\n",
      "Epoch [17/50], Step [3700/7038], D Loss: 0.5271350145339966, G Loss: 1.3028169870376587\n",
      "Epoch [17/50], Step [3800/7038], D Loss: 0.337511271238327, G Loss: 1.4328620433807373\n",
      "Epoch [17/50], Step [3900/7038], D Loss: 0.6177154183387756, G Loss: 1.2558811902999878\n",
      "Epoch [17/50], Step [4000/7038], D Loss: 0.462930828332901, G Loss: 1.0951400995254517\n",
      "Epoch [17/50], Step [4100/7038], D Loss: 0.430594265460968, G Loss: 1.5003477334976196\n",
      "Epoch [17/50], Step [4200/7038], D Loss: 0.486922025680542, G Loss: 1.3053607940673828\n",
      "Epoch [17/50], Step [4300/7038], D Loss: 0.5581657290458679, G Loss: 1.002590298652649\n",
      "Epoch [17/50], Step [4400/7038], D Loss: 0.4771868884563446, G Loss: 1.6437073945999146\n",
      "Epoch [17/50], Step [4500/7038], D Loss: 0.5469842553138733, G Loss: 1.2366290092468262\n",
      "Epoch [17/50], Step [4600/7038], D Loss: 0.4937789738178253, G Loss: 1.1987190246582031\n",
      "Epoch [17/50], Step [4700/7038], D Loss: 0.7314649224281311, G Loss: 1.7277874946594238\n",
      "Epoch [17/50], Step [4800/7038], D Loss: 0.3800826072692871, G Loss: 1.2699296474456787\n",
      "Epoch [17/50], Step [4900/7038], D Loss: 0.7256917953491211, G Loss: 1.0369184017181396\n",
      "Epoch [17/50], Step [5000/7038], D Loss: 0.4210919141769409, G Loss: 1.468323826789856\n",
      "Epoch [17/50], Step [5100/7038], D Loss: 0.29909080266952515, G Loss: 1.8442267179489136\n",
      "Epoch [17/50], Step [5200/7038], D Loss: 0.649797260761261, G Loss: 1.0480636358261108\n",
      "Epoch [17/50], Step [5300/7038], D Loss: 0.4569670557975769, G Loss: 0.9618147015571594\n",
      "Epoch [17/50], Step [5400/7038], D Loss: 0.6373094320297241, G Loss: 1.435258388519287\n",
      "Epoch [17/50], Step [5500/7038], D Loss: 0.5753359794616699, G Loss: 1.509522557258606\n",
      "Epoch [17/50], Step [5600/7038], D Loss: 0.41433873772621155, G Loss: 1.3307515382766724\n",
      "Epoch [17/50], Step [5700/7038], D Loss: 0.5767197012901306, G Loss: 1.101650595664978\n",
      "Epoch [17/50], Step [5800/7038], D Loss: 0.758599579334259, G Loss: 1.1843162775039673\n",
      "Epoch [17/50], Step [5900/7038], D Loss: 0.4674079716205597, G Loss: 1.4289907217025757\n",
      "Epoch [17/50], Step [6000/7038], D Loss: 0.36218011379241943, G Loss: 1.3787018060684204\n",
      "Epoch [17/50], Step [6100/7038], D Loss: 0.4150208830833435, G Loss: 1.467104196548462\n",
      "Epoch [17/50], Step [6200/7038], D Loss: 0.2989477515220642, G Loss: 1.6369985342025757\n",
      "Epoch [17/50], Step [6300/7038], D Loss: 0.4088864326477051, G Loss: 1.4337036609649658\n",
      "Epoch [17/50], Step [6400/7038], D Loss: 0.46283361315727234, G Loss: 1.227899432182312\n",
      "Epoch [17/50], Step [6500/7038], D Loss: 0.5709106922149658, G Loss: 0.9600624442100525\n",
      "Epoch [17/50], Step [6600/7038], D Loss: 0.42531827092170715, G Loss: 1.2250193357467651\n",
      "Epoch [17/50], Step [6700/7038], D Loss: 0.4100835621356964, G Loss: 1.5077959299087524\n",
      "Epoch [17/50], Step [6800/7038], D Loss: 0.5335170030593872, G Loss: 1.5753061771392822\n",
      "Epoch [17/50], Step [6900/7038], D Loss: 0.4004869759082794, G Loss: 1.494976282119751\n",
      "Epoch [17/50], Step [7000/7038], D Loss: 0.34999585151672363, G Loss: 2.0764806270599365\n",
      "Epoch [18/50], Step [0/7038], D Loss: 0.4649103283882141, G Loss: 1.0806734561920166\n",
      "Epoch [18/50], Step [100/7038], D Loss: 0.4713486433029175, G Loss: 1.4475327730178833\n",
      "Epoch [18/50], Step [200/7038], D Loss: 0.5344802141189575, G Loss: 1.4815274477005005\n",
      "Epoch [18/50], Step [300/7038], D Loss: 0.40213680267333984, G Loss: 1.4262505769729614\n",
      "Epoch [18/50], Step [400/7038], D Loss: 0.7513681650161743, G Loss: 1.244168996810913\n",
      "Epoch [18/50], Step [500/7038], D Loss: 0.48988938331604004, G Loss: 1.368465781211853\n",
      "Epoch [18/50], Step [600/7038], D Loss: 0.6882758140563965, G Loss: 1.2263633012771606\n",
      "Epoch [18/50], Step [700/7038], D Loss: 0.42842066287994385, G Loss: 1.3517926931381226\n",
      "Epoch [18/50], Step [800/7038], D Loss: 0.37707504630088806, G Loss: 1.369872808456421\n",
      "Epoch [18/50], Step [900/7038], D Loss: 0.2858603596687317, G Loss: 1.419187068939209\n",
      "Epoch [18/50], Step [1000/7038], D Loss: 0.6538873910903931, G Loss: 1.1639149188995361\n",
      "Epoch [18/50], Step [1100/7038], D Loss: 0.6047190427780151, G Loss: 1.2529652118682861\n",
      "Epoch [18/50], Step [1200/7038], D Loss: 0.4650498628616333, G Loss: 1.2781319618225098\n",
      "Epoch [18/50], Step [1300/7038], D Loss: 0.6911027431488037, G Loss: 1.083247184753418\n",
      "Epoch [18/50], Step [1400/7038], D Loss: 0.6825292706489563, G Loss: 1.5597758293151855\n",
      "Epoch [18/50], Step [1500/7038], D Loss: 0.648199200630188, G Loss: 1.1163978576660156\n",
      "Epoch [18/50], Step [1600/7038], D Loss: 0.4074085056781769, G Loss: 1.564334750175476\n",
      "Epoch [18/50], Step [1700/7038], D Loss: 0.422098308801651, G Loss: 1.391528606414795\n",
      "Epoch [18/50], Step [1800/7038], D Loss: 0.6281653046607971, G Loss: 1.3959439992904663\n",
      "Epoch [18/50], Step [1900/7038], D Loss: 0.43880170583724976, G Loss: 1.5008184909820557\n",
      "Epoch [18/50], Step [2000/7038], D Loss: 0.4701077342033386, G Loss: 1.055793046951294\n",
      "Epoch [18/50], Step [2100/7038], D Loss: 0.594919741153717, G Loss: 1.4355355501174927\n",
      "Epoch [18/50], Step [2200/7038], D Loss: 0.755486249923706, G Loss: 1.2355496883392334\n",
      "Epoch [18/50], Step [2300/7038], D Loss: 0.5182993412017822, G Loss: 1.3658318519592285\n",
      "Epoch [18/50], Step [2400/7038], D Loss: 0.5425156354904175, G Loss: 0.9486733078956604\n",
      "Epoch [18/50], Step [2500/7038], D Loss: 0.5096505284309387, G Loss: 1.1125544309616089\n",
      "Epoch [18/50], Step [2600/7038], D Loss: 0.5147132873535156, G Loss: 1.1943036317825317\n",
      "Epoch [18/50], Step [2700/7038], D Loss: 0.6331005096435547, G Loss: 2.0250301361083984\n",
      "Epoch [18/50], Step [2800/7038], D Loss: 0.2926938831806183, G Loss: 2.0403964519500732\n",
      "Epoch [18/50], Step [2900/7038], D Loss: 0.6948185563087463, G Loss: 1.2831212282180786\n",
      "Epoch [18/50], Step [3000/7038], D Loss: 0.5898192524909973, G Loss: 1.7539854049682617\n",
      "Epoch [18/50], Step [3100/7038], D Loss: 0.42093560099601746, G Loss: 1.7233269214630127\n",
      "Epoch [18/50], Step [3200/7038], D Loss: 0.6859856843948364, G Loss: 0.8998736143112183\n",
      "Epoch [18/50], Step [3300/7038], D Loss: 0.6350675225257874, G Loss: 1.1943409442901611\n",
      "Epoch [18/50], Step [3400/7038], D Loss: 0.5988088846206665, G Loss: 1.2824023962020874\n",
      "Epoch [18/50], Step [3500/7038], D Loss: 0.7283443808555603, G Loss: 1.3259977102279663\n",
      "Epoch [18/50], Step [3600/7038], D Loss: 0.45337387919425964, G Loss: 1.299831509590149\n",
      "Epoch [18/50], Step [3700/7038], D Loss: 0.489271879196167, G Loss: 1.354432463645935\n",
      "Epoch [18/50], Step [3800/7038], D Loss: 0.5039135813713074, G Loss: 1.2003536224365234\n",
      "Epoch [18/50], Step [3900/7038], D Loss: 0.5836601257324219, G Loss: 1.0095107555389404\n",
      "Epoch [18/50], Step [4000/7038], D Loss: 0.5681898593902588, G Loss: 1.8405581712722778\n",
      "Epoch [18/50], Step [4100/7038], D Loss: 0.4574522376060486, G Loss: 1.752809762954712\n",
      "Epoch [18/50], Step [4200/7038], D Loss: 0.5626670718193054, G Loss: 1.7042040824890137\n",
      "Epoch [18/50], Step [4300/7038], D Loss: 0.4351489543914795, G Loss: 1.3648219108581543\n",
      "Epoch [18/50], Step [4400/7038], D Loss: 0.5554835200309753, G Loss: 1.703244686126709\n",
      "Epoch [18/50], Step [4500/7038], D Loss: 0.42353764176368713, G Loss: 1.4241317510604858\n",
      "Epoch [18/50], Step [4600/7038], D Loss: 0.6668182015419006, G Loss: 1.3993802070617676\n",
      "Epoch [18/50], Step [4700/7038], D Loss: 0.4588143229484558, G Loss: 1.2587586641311646\n",
      "Epoch [18/50], Step [4800/7038], D Loss: 0.4696784019470215, G Loss: 1.4217551946640015\n",
      "Epoch [18/50], Step [4900/7038], D Loss: 0.45011746883392334, G Loss: 1.4180290699005127\n",
      "Epoch [18/50], Step [5000/7038], D Loss: 0.4259881377220154, G Loss: 1.3518202304840088\n",
      "Epoch [18/50], Step [5100/7038], D Loss: 0.7189339995384216, G Loss: 1.0420136451721191\n",
      "Epoch [18/50], Step [5200/7038], D Loss: 0.4288110136985779, G Loss: 1.5367001295089722\n",
      "Epoch [18/50], Step [5300/7038], D Loss: 0.5650614500045776, G Loss: 0.9633623361587524\n",
      "Epoch [18/50], Step [5400/7038], D Loss: 0.48806390166282654, G Loss: 1.8790805339813232\n",
      "Epoch [18/50], Step [5500/7038], D Loss: 0.7693628072738647, G Loss: 1.3251968622207642\n",
      "Epoch [18/50], Step [5600/7038], D Loss: 0.49731212854385376, G Loss: 1.191489577293396\n",
      "Epoch [18/50], Step [5700/7038], D Loss: 0.4558177590370178, G Loss: 1.3224812746047974\n",
      "Epoch [18/50], Step [5800/7038], D Loss: 0.5240612030029297, G Loss: 0.9352573752403259\n",
      "Epoch [18/50], Step [5900/7038], D Loss: 0.863155722618103, G Loss: 1.1624919176101685\n",
      "Epoch [18/50], Step [6000/7038], D Loss: 0.5721213817596436, G Loss: 1.4685982465744019\n",
      "Epoch [18/50], Step [6100/7038], D Loss: 0.4015902280807495, G Loss: 1.5213240385055542\n",
      "Epoch [18/50], Step [6200/7038], D Loss: 0.5363548994064331, G Loss: 1.4443634748458862\n",
      "Epoch [18/50], Step [6300/7038], D Loss: 0.4309225380420685, G Loss: 1.4854894876480103\n",
      "Epoch [18/50], Step [6400/7038], D Loss: 0.6595609188079834, G Loss: 0.9236114621162415\n",
      "Epoch [18/50], Step [6500/7038], D Loss: 0.3999931216239929, G Loss: 1.411035180091858\n",
      "Epoch [18/50], Step [6600/7038], D Loss: 0.5430653095245361, G Loss: 1.1322431564331055\n",
      "Epoch [18/50], Step [6700/7038], D Loss: 0.4286370873451233, G Loss: 1.6963298320770264\n",
      "Epoch [18/50], Step [6800/7038], D Loss: 0.46631747484207153, G Loss: 1.3008612394332886\n",
      "Epoch [18/50], Step [6900/7038], D Loss: 0.585492730140686, G Loss: 1.1465901136398315\n",
      "Epoch [18/50], Step [7000/7038], D Loss: 0.4195988178253174, G Loss: 1.1698009967803955\n",
      "Epoch [19/50], Step [0/7038], D Loss: 0.3718709945678711, G Loss: 1.400753140449524\n",
      "Epoch [19/50], Step [100/7038], D Loss: 0.448045015335083, G Loss: 1.1996808052062988\n",
      "Epoch [19/50], Step [200/7038], D Loss: 0.44212836027145386, G Loss: 1.177205204963684\n",
      "Epoch [19/50], Step [300/7038], D Loss: 0.45665299892425537, G Loss: 1.2438642978668213\n",
      "Epoch [19/50], Step [400/7038], D Loss: 0.45695340633392334, G Loss: 1.5327653884887695\n",
      "Epoch [19/50], Step [500/7038], D Loss: 0.5075505971908569, G Loss: 1.5189095735549927\n",
      "Epoch [19/50], Step [600/7038], D Loss: 0.5189037322998047, G Loss: 1.077480435371399\n",
      "Epoch [19/50], Step [700/7038], D Loss: 0.45688772201538086, G Loss: 1.4513161182403564\n",
      "Epoch [19/50], Step [800/7038], D Loss: 0.29074448347091675, G Loss: 1.9615801572799683\n",
      "Epoch [19/50], Step [900/7038], D Loss: 0.74293053150177, G Loss: 1.4546175003051758\n",
      "Epoch [19/50], Step [1000/7038], D Loss: 0.5307354927062988, G Loss: 0.9964548945426941\n",
      "Epoch [19/50], Step [1100/7038], D Loss: 0.49039486050605774, G Loss: 1.1593950986862183\n",
      "Epoch [19/50], Step [1200/7038], D Loss: 0.4373307228088379, G Loss: 1.1641111373901367\n",
      "Epoch [19/50], Step [1300/7038], D Loss: 0.7327967882156372, G Loss: 1.070440411567688\n",
      "Epoch [19/50], Step [1400/7038], D Loss: 0.4228067398071289, G Loss: 1.1724506616592407\n",
      "Epoch [19/50], Step [1500/7038], D Loss: 0.6428768634796143, G Loss: 1.7729978561401367\n",
      "Epoch [19/50], Step [1600/7038], D Loss: 0.5941690802574158, G Loss: 1.1948415040969849\n",
      "Epoch [19/50], Step [1700/7038], D Loss: 0.38737526535987854, G Loss: 1.3053241968154907\n",
      "Epoch [19/50], Step [1800/7038], D Loss: 0.668323278427124, G Loss: 1.087471604347229\n",
      "Epoch [19/50], Step [1900/7038], D Loss: 0.5585029721260071, G Loss: 1.4396780729293823\n",
      "Epoch [19/50], Step [2000/7038], D Loss: 0.5666435956954956, G Loss: 1.141895055770874\n",
      "Epoch [19/50], Step [2100/7038], D Loss: 0.6375088095664978, G Loss: 1.0553719997406006\n",
      "Epoch [19/50], Step [2200/7038], D Loss: 0.5827758312225342, G Loss: 1.4174174070358276\n",
      "Epoch [19/50], Step [2300/7038], D Loss: 0.6542215347290039, G Loss: 1.188766360282898\n",
      "Epoch [19/50], Step [2400/7038], D Loss: 0.49406197667121887, G Loss: 1.4181368350982666\n",
      "Epoch [19/50], Step [2500/7038], D Loss: 0.4122222363948822, G Loss: 1.2908419370651245\n",
      "Epoch [19/50], Step [2600/7038], D Loss: 0.5203064680099487, G Loss: 1.0576531887054443\n",
      "Epoch [19/50], Step [2700/7038], D Loss: 0.7193748950958252, G Loss: 1.3868967294692993\n",
      "Epoch [19/50], Step [2800/7038], D Loss: 0.5872917175292969, G Loss: 1.0595660209655762\n",
      "Epoch [19/50], Step [2900/7038], D Loss: 0.5060352087020874, G Loss: 1.299638271331787\n",
      "Epoch [19/50], Step [3000/7038], D Loss: 0.40190255641937256, G Loss: 1.4008132219314575\n",
      "Epoch [19/50], Step [3100/7038], D Loss: 0.550359845161438, G Loss: 1.0001682043075562\n",
      "Epoch [19/50], Step [3200/7038], D Loss: 0.587475061416626, G Loss: 1.3183473348617554\n",
      "Epoch [19/50], Step [3300/7038], D Loss: 0.5549086332321167, G Loss: 1.2507268190383911\n",
      "Epoch [19/50], Step [3400/7038], D Loss: 0.6679792404174805, G Loss: 1.054893970489502\n",
      "Epoch [19/50], Step [3500/7038], D Loss: 0.5868490934371948, G Loss: 1.0668931007385254\n",
      "Epoch [19/50], Step [3600/7038], D Loss: 0.40880343317985535, G Loss: 1.8356127738952637\n",
      "Epoch [19/50], Step [3700/7038], D Loss: 0.6102281808853149, G Loss: 1.1538211107254028\n",
      "Epoch [19/50], Step [3800/7038], D Loss: 0.36860018968582153, G Loss: 1.1891663074493408\n",
      "Epoch [19/50], Step [3900/7038], D Loss: 0.7132429480552673, G Loss: 1.6654789447784424\n",
      "Epoch [19/50], Step [4000/7038], D Loss: 0.6013578176498413, G Loss: 1.4957787990570068\n",
      "Epoch [19/50], Step [4100/7038], D Loss: 0.471111536026001, G Loss: 1.3335057497024536\n",
      "Epoch [19/50], Step [4200/7038], D Loss: 0.3779919445514679, G Loss: 1.1615526676177979\n",
      "Epoch [19/50], Step [4300/7038], D Loss: 0.45856624841690063, G Loss: 1.160714030265808\n",
      "Epoch [19/50], Step [4400/7038], D Loss: 0.45582807064056396, G Loss: 1.33157217502594\n",
      "Epoch [19/50], Step [4500/7038], D Loss: 0.41029155254364014, G Loss: 1.1100406646728516\n",
      "Epoch [19/50], Step [4600/7038], D Loss: 0.4188057780265808, G Loss: 1.4525718688964844\n",
      "Epoch [19/50], Step [4700/7038], D Loss: 0.24275675415992737, G Loss: 1.9383560419082642\n",
      "Epoch [19/50], Step [4800/7038], D Loss: 0.42715662717819214, G Loss: 1.5136058330535889\n",
      "Epoch [19/50], Step [4900/7038], D Loss: 0.661973774433136, G Loss: 0.9409526586532593\n",
      "Epoch [19/50], Step [5000/7038], D Loss: 0.49512535333633423, G Loss: 1.13247549533844\n",
      "Epoch [19/50], Step [5100/7038], D Loss: 0.5292233228683472, G Loss: 1.2745578289031982\n",
      "Epoch [19/50], Step [5200/7038], D Loss: 0.6177271008491516, G Loss: 1.0872286558151245\n",
      "Epoch [19/50], Step [5300/7038], D Loss: 0.5112793445587158, G Loss: 1.3408610820770264\n",
      "Epoch [19/50], Step [5400/7038], D Loss: 0.6834191083908081, G Loss: 1.6362823247909546\n",
      "Epoch [19/50], Step [5500/7038], D Loss: 0.7118200063705444, G Loss: 1.3810166120529175\n",
      "Epoch [19/50], Step [5600/7038], D Loss: 0.5041360259056091, G Loss: 1.4631153345108032\n",
      "Epoch [19/50], Step [5700/7038], D Loss: 0.4326941668987274, G Loss: 1.3376725912094116\n",
      "Epoch [19/50], Step [5800/7038], D Loss: 0.38510823249816895, G Loss: 1.3817815780639648\n",
      "Epoch [19/50], Step [5900/7038], D Loss: 0.8464253544807434, G Loss: 1.1241939067840576\n",
      "Epoch [19/50], Step [6000/7038], D Loss: 0.5560531616210938, G Loss: 1.144464373588562\n",
      "Epoch [19/50], Step [6100/7038], D Loss: 0.39492231607437134, G Loss: 1.4157661199569702\n",
      "Epoch [19/50], Step [6200/7038], D Loss: 0.47353190183639526, G Loss: 1.3979299068450928\n",
      "Epoch [19/50], Step [6300/7038], D Loss: 0.5303338766098022, G Loss: 0.9956146478652954\n",
      "Epoch [19/50], Step [6400/7038], D Loss: 0.76218181848526, G Loss: 1.4014111757278442\n",
      "Epoch [19/50], Step [6500/7038], D Loss: 0.5711973309516907, G Loss: 1.3452930450439453\n",
      "Epoch [19/50], Step [6600/7038], D Loss: 0.4035526216030121, G Loss: 1.3698447942733765\n",
      "Epoch [19/50], Step [6700/7038], D Loss: 0.4177449941635132, G Loss: 1.1543341875076294\n",
      "Epoch [19/50], Step [6800/7038], D Loss: 0.36101987957954407, G Loss: 1.4876903295516968\n",
      "Epoch [19/50], Step [6900/7038], D Loss: 0.3339259624481201, G Loss: 1.8224672079086304\n",
      "Epoch [19/50], Step [7000/7038], D Loss: 0.6032783389091492, G Loss: 1.407885193824768\n",
      "Epoch [20/50], Step [0/7038], D Loss: 0.38274654746055603, G Loss: 1.4219739437103271\n",
      "Epoch [20/50], Step [100/7038], D Loss: 0.4525858163833618, G Loss: 1.2029657363891602\n",
      "Epoch [20/50], Step [200/7038], D Loss: 0.4714387059211731, G Loss: 1.2173347473144531\n",
      "Epoch [20/50], Step [300/7038], D Loss: 0.5422096252441406, G Loss: 1.2753703594207764\n",
      "Epoch [20/50], Step [400/7038], D Loss: 0.6365982294082642, G Loss: 1.6340456008911133\n",
      "Epoch [20/50], Step [500/7038], D Loss: 0.47223955392837524, G Loss: 1.4163603782653809\n",
      "Epoch [20/50], Step [600/7038], D Loss: 0.5523024797439575, G Loss: 1.2614707946777344\n",
      "Epoch [20/50], Step [700/7038], D Loss: 0.4754544198513031, G Loss: 1.2501832246780396\n",
      "Epoch [20/50], Step [800/7038], D Loss: 0.5422916412353516, G Loss: 1.0967799425125122\n",
      "Epoch [20/50], Step [900/7038], D Loss: 0.674347460269928, G Loss: 1.0546619892120361\n",
      "Epoch [20/50], Step [1000/7038], D Loss: 0.556489109992981, G Loss: 1.6307331323623657\n",
      "Epoch [20/50], Step [1100/7038], D Loss: 0.5581823587417603, G Loss: 1.6234992742538452\n",
      "Epoch [20/50], Step [1200/7038], D Loss: 0.43597739934921265, G Loss: 1.253311276435852\n",
      "Epoch [20/50], Step [1300/7038], D Loss: 0.49927234649658203, G Loss: 1.265723705291748\n",
      "Epoch [20/50], Step [1400/7038], D Loss: 0.5183097124099731, G Loss: 1.4534507989883423\n",
      "Epoch [20/50], Step [1500/7038], D Loss: 0.6176851987838745, G Loss: 1.0686404705047607\n",
      "Epoch [20/50], Step [1600/7038], D Loss: 0.4563569128513336, G Loss: 1.2372547388076782\n",
      "Epoch [20/50], Step [1700/7038], D Loss: 0.4765419661998749, G Loss: 1.175776481628418\n",
      "Epoch [20/50], Step [1800/7038], D Loss: 0.4420122802257538, G Loss: 1.5658875703811646\n",
      "Epoch [20/50], Step [1900/7038], D Loss: 0.5171934366226196, G Loss: 1.103165626525879\n",
      "Epoch [20/50], Step [2000/7038], D Loss: 0.38228335976600647, G Loss: 2.153250217437744\n",
      "Epoch [20/50], Step [2100/7038], D Loss: 0.43374010920524597, G Loss: 1.4949084520339966\n",
      "Epoch [20/50], Step [2200/7038], D Loss: 0.35746634006500244, G Loss: 1.4375907182693481\n",
      "Epoch [20/50], Step [2300/7038], D Loss: 0.4582529067993164, G Loss: 1.2732688188552856\n",
      "Epoch [20/50], Step [2400/7038], D Loss: 0.5927951335906982, G Loss: 1.291243076324463\n",
      "Epoch [20/50], Step [2500/7038], D Loss: 0.554191529750824, G Loss: 0.9904722571372986\n",
      "Epoch [20/50], Step [2600/7038], D Loss: 0.48749691247940063, G Loss: 0.9783855676651001\n",
      "Epoch [20/50], Step [2700/7038], D Loss: 0.5284644365310669, G Loss: 1.1139028072357178\n",
      "Epoch [20/50], Step [2800/7038], D Loss: 0.5550159215927124, G Loss: 1.5524859428405762\n",
      "Epoch [20/50], Step [2900/7038], D Loss: 0.5056955814361572, G Loss: 1.1449470520019531\n",
      "Epoch [20/50], Step [3000/7038], D Loss: 0.4909481406211853, G Loss: 1.3539845943450928\n",
      "Epoch [20/50], Step [3100/7038], D Loss: 0.5064071416854858, G Loss: 1.2252198457717896\n",
      "Epoch [20/50], Step [3200/7038], D Loss: 0.3346288204193115, G Loss: 1.4725350141525269\n",
      "Epoch [20/50], Step [3300/7038], D Loss: 0.6249018311500549, G Loss: 1.4908407926559448\n",
      "Epoch [20/50], Step [3400/7038], D Loss: 0.31706303358078003, G Loss: 1.7498277425765991\n",
      "Epoch [20/50], Step [3500/7038], D Loss: 0.6915269494056702, G Loss: 1.3460900783538818\n",
      "Epoch [20/50], Step [3600/7038], D Loss: 0.5883107781410217, G Loss: 1.3670008182525635\n",
      "Epoch [20/50], Step [3700/7038], D Loss: 0.4976847767829895, G Loss: 1.1315557956695557\n",
      "Epoch [20/50], Step [3800/7038], D Loss: 0.314497709274292, G Loss: 1.4547061920166016\n",
      "Epoch [20/50], Step [3900/7038], D Loss: 0.480396032333374, G Loss: 1.202231526374817\n",
      "Epoch [20/50], Step [4000/7038], D Loss: 0.469418466091156, G Loss: 1.1336487531661987\n",
      "Epoch [20/50], Step [4100/7038], D Loss: 0.5405850410461426, G Loss: 1.4501832723617554\n",
      "Epoch [20/50], Step [4200/7038], D Loss: 0.5007063150405884, G Loss: 1.495384693145752\n",
      "Epoch [20/50], Step [4300/7038], D Loss: 0.657852828502655, G Loss: 1.6597836017608643\n",
      "Epoch [20/50], Step [4400/7038], D Loss: 0.5258678793907166, G Loss: 1.8584754467010498\n",
      "Epoch [20/50], Step [4500/7038], D Loss: 0.481224000453949, G Loss: 1.3203712701797485\n",
      "Epoch [20/50], Step [4600/7038], D Loss: 0.4749997854232788, G Loss: 1.2502000331878662\n",
      "Epoch [20/50], Step [4700/7038], D Loss: 0.4923839569091797, G Loss: 1.6783475875854492\n",
      "Epoch [20/50], Step [4800/7038], D Loss: 0.3022865653038025, G Loss: 1.561977505683899\n",
      "Epoch [20/50], Step [4900/7038], D Loss: 0.789013147354126, G Loss: 1.161186695098877\n",
      "Epoch [20/50], Step [5000/7038], D Loss: 0.7357074618339539, G Loss: 1.383500576019287\n",
      "Epoch [20/50], Step [5100/7038], D Loss: 0.5405828356742859, G Loss: 1.3027830123901367\n",
      "Epoch [20/50], Step [5200/7038], D Loss: 0.37232133746147156, G Loss: 1.4422205686569214\n",
      "Epoch [20/50], Step [5300/7038], D Loss: 0.5182880163192749, G Loss: 1.1746476888656616\n",
      "Epoch [20/50], Step [5400/7038], D Loss: 0.5150550007820129, G Loss: 1.0312397480010986\n",
      "Epoch [20/50], Step [5500/7038], D Loss: 0.5448044538497925, G Loss: 0.8534292578697205\n",
      "Epoch [20/50], Step [5600/7038], D Loss: 0.50370192527771, G Loss: 1.1782656908035278\n",
      "Epoch [20/50], Step [5700/7038], D Loss: 0.5476160645484924, G Loss: 1.045169472694397\n",
      "Epoch [20/50], Step [5800/7038], D Loss: 0.6257113218307495, G Loss: 1.2309781312942505\n",
      "Epoch [20/50], Step [5900/7038], D Loss: 0.5371213555335999, G Loss: 1.432926058769226\n",
      "Epoch [20/50], Step [6000/7038], D Loss: 0.543687105178833, G Loss: 1.3042658567428589\n",
      "Epoch [20/50], Step [6100/7038], D Loss: 0.2705931067466736, G Loss: 1.713248610496521\n",
      "Epoch [20/50], Step [6200/7038], D Loss: 0.8468296527862549, G Loss: 1.5905083417892456\n",
      "Epoch [20/50], Step [6300/7038], D Loss: 0.5857734680175781, G Loss: 1.164411187171936\n",
      "Epoch [20/50], Step [6400/7038], D Loss: 0.5620346069335938, G Loss: 0.9113077521324158\n",
      "Epoch [20/50], Step [6500/7038], D Loss: 0.4322149157524109, G Loss: 1.7487785816192627\n",
      "Epoch [20/50], Step [6600/7038], D Loss: 0.4601317048072815, G Loss: 1.5571873188018799\n",
      "Epoch [20/50], Step [6700/7038], D Loss: 0.5875468254089355, G Loss: 1.3186432123184204\n",
      "Epoch [20/50], Step [6800/7038], D Loss: 0.39515405893325806, G Loss: 1.3425395488739014\n",
      "Epoch [20/50], Step [6900/7038], D Loss: 0.5220284461975098, G Loss: 1.076108694076538\n",
      "Epoch [20/50], Step [7000/7038], D Loss: 0.21768343448638916, G Loss: 1.7954155206680298\n",
      "Epoch [21/50], Step [0/7038], D Loss: 0.36516761779785156, G Loss: 1.7930117845535278\n",
      "Epoch [21/50], Step [100/7038], D Loss: 0.3886690139770508, G Loss: 1.4423625469207764\n",
      "Epoch [21/50], Step [200/7038], D Loss: 0.3001392185688019, G Loss: 1.4473949670791626\n",
      "Epoch [21/50], Step [300/7038], D Loss: 0.7684975266456604, G Loss: 0.7702583074569702\n",
      "Epoch [21/50], Step [400/7038], D Loss: 0.5361698865890503, G Loss: 1.2885425090789795\n",
      "Epoch [21/50], Step [500/7038], D Loss: 0.49769875407218933, G Loss: 1.0517592430114746\n",
      "Epoch [21/50], Step [600/7038], D Loss: 0.36705875396728516, G Loss: 1.5350629091262817\n",
      "Epoch [21/50], Step [700/7038], D Loss: 0.5843535661697388, G Loss: 1.0098975896835327\n",
      "Epoch [21/50], Step [800/7038], D Loss: 0.5141665935516357, G Loss: 1.2240113019943237\n",
      "Epoch [21/50], Step [900/7038], D Loss: 0.3135392963886261, G Loss: 1.7622640132904053\n",
      "Epoch [21/50], Step [1000/7038], D Loss: 0.4432719647884369, G Loss: 1.3902288675308228\n",
      "Epoch [21/50], Step [1100/7038], D Loss: 0.4474799931049347, G Loss: 1.465934157371521\n",
      "Epoch [21/50], Step [1200/7038], D Loss: 0.4158971309661865, G Loss: 1.1190134286880493\n",
      "Epoch [21/50], Step [1300/7038], D Loss: 0.5688282251358032, G Loss: 1.2639501094818115\n",
      "Epoch [21/50], Step [1400/7038], D Loss: 0.37346965074539185, G Loss: 1.4733350276947021\n",
      "Epoch [21/50], Step [1500/7038], D Loss: 0.47732824087142944, G Loss: 1.4350157976150513\n",
      "Epoch [21/50], Step [1600/7038], D Loss: 0.6664924621582031, G Loss: 0.9640870094299316\n",
      "Epoch [21/50], Step [1700/7038], D Loss: 0.5447008609771729, G Loss: 1.3761893510818481\n",
      "Epoch [21/50], Step [1800/7038], D Loss: 0.7993841171264648, G Loss: 1.1762771606445312\n",
      "Epoch [21/50], Step [1900/7038], D Loss: 0.5479361414909363, G Loss: 0.9661986827850342\n",
      "Epoch [21/50], Step [2000/7038], D Loss: 0.8089582920074463, G Loss: 1.1657503843307495\n",
      "Epoch [21/50], Step [2100/7038], D Loss: 0.4211021065711975, G Loss: 1.315764307975769\n",
      "Epoch [21/50], Step [2200/7038], D Loss: 0.5293954610824585, G Loss: 0.890639066696167\n",
      "Epoch [21/50], Step [2300/7038], D Loss: 0.8447756767272949, G Loss: 1.4893653392791748\n",
      "Epoch [21/50], Step [2400/7038], D Loss: 0.7060617208480835, G Loss: 0.8609296679496765\n",
      "Epoch [21/50], Step [2500/7038], D Loss: 0.48116523027420044, G Loss: 1.5804531574249268\n",
      "Epoch [21/50], Step [2600/7038], D Loss: 0.660534143447876, G Loss: 1.0429272651672363\n",
      "Epoch [21/50], Step [2700/7038], D Loss: 0.6461553573608398, G Loss: 1.4985315799713135\n",
      "Epoch [21/50], Step [2800/7038], D Loss: 0.4888002872467041, G Loss: 1.3282448053359985\n",
      "Epoch [21/50], Step [2900/7038], D Loss: 0.8736988306045532, G Loss: 1.0219206809997559\n",
      "Epoch [21/50], Step [3000/7038], D Loss: 0.3260035514831543, G Loss: 2.1621525287628174\n",
      "Epoch [21/50], Step [3100/7038], D Loss: 0.40899014472961426, G Loss: 1.8305546045303345\n",
      "Epoch [21/50], Step [3200/7038], D Loss: 0.3955007791519165, G Loss: 1.3562192916870117\n",
      "Epoch [21/50], Step [3300/7038], D Loss: 0.49746251106262207, G Loss: 1.2276424169540405\n",
      "Epoch [21/50], Step [3400/7038], D Loss: 0.34280750155448914, G Loss: 1.31180739402771\n",
      "Epoch [21/50], Step [3500/7038], D Loss: 0.31482750177383423, G Loss: 1.8022459745407104\n",
      "Epoch [21/50], Step [3600/7038], D Loss: 0.33846211433410645, G Loss: 1.4593814611434937\n",
      "Epoch [21/50], Step [3700/7038], D Loss: 0.4739481806755066, G Loss: 1.352416753768921\n",
      "Epoch [21/50], Step [3800/7038], D Loss: 0.35168617963790894, G Loss: 1.4818490743637085\n",
      "Epoch [21/50], Step [3900/7038], D Loss: 0.313257098197937, G Loss: 1.40353524684906\n",
      "Epoch [21/50], Step [4000/7038], D Loss: 0.47683873772621155, G Loss: 1.315557599067688\n",
      "Epoch [21/50], Step [4100/7038], D Loss: 0.5779438018798828, G Loss: 1.0951988697052002\n",
      "Epoch [21/50], Step [4200/7038], D Loss: 0.38347554206848145, G Loss: 2.1630148887634277\n",
      "Epoch [21/50], Step [4300/7038], D Loss: 0.5919103622436523, G Loss: 1.2536535263061523\n",
      "Epoch [21/50], Step [4400/7038], D Loss: 0.6591058373451233, G Loss: 1.990900993347168\n",
      "Epoch [21/50], Step [4500/7038], D Loss: 0.43384629487991333, G Loss: 1.2660229206085205\n",
      "Epoch [21/50], Step [4600/7038], D Loss: 0.37143611907958984, G Loss: 1.372827410697937\n",
      "Epoch [21/50], Step [4700/7038], D Loss: 0.5984427332878113, G Loss: 1.1756454706192017\n",
      "Epoch [21/50], Step [4800/7038], D Loss: 0.36126989126205444, G Loss: 1.8662461042404175\n",
      "Epoch [21/50], Step [4900/7038], D Loss: 0.5608401298522949, G Loss: 1.0647958517074585\n",
      "Epoch [21/50], Step [5000/7038], D Loss: 0.5531375408172607, G Loss: 1.5324211120605469\n",
      "Epoch [21/50], Step [5100/7038], D Loss: 0.4950210452079773, G Loss: 1.5074775218963623\n",
      "Epoch [21/50], Step [5200/7038], D Loss: 0.41078269481658936, G Loss: 1.38957941532135\n",
      "Epoch [21/50], Step [5300/7038], D Loss: 0.46565788984298706, G Loss: 1.3345272541046143\n",
      "Epoch [21/50], Step [5400/7038], D Loss: 0.5003796815872192, G Loss: 1.4683529138565063\n",
      "Epoch [21/50], Step [5500/7038], D Loss: 0.4721486270427704, G Loss: 1.29886794090271\n",
      "Epoch [21/50], Step [5600/7038], D Loss: 0.5313772559165955, G Loss: 1.357479214668274\n",
      "Epoch [21/50], Step [5700/7038], D Loss: 0.5884642004966736, G Loss: 1.6257776021957397\n",
      "Epoch [21/50], Step [5800/7038], D Loss: 0.7010970115661621, G Loss: 1.2936382293701172\n",
      "Epoch [21/50], Step [5900/7038], D Loss: 0.4698375463485718, G Loss: 1.2108761072158813\n",
      "Epoch [21/50], Step [6000/7038], D Loss: 0.49005991220474243, G Loss: 1.276153802871704\n",
      "Epoch [21/50], Step [6100/7038], D Loss: 0.5330547094345093, G Loss: 1.0404249429702759\n",
      "Epoch [21/50], Step [6200/7038], D Loss: 0.4688856601715088, G Loss: 1.3560407161712646\n",
      "Epoch [21/50], Step [6300/7038], D Loss: 0.5220268964767456, G Loss: 1.2441134452819824\n",
      "Epoch [21/50], Step [6400/7038], D Loss: 0.49400120973587036, G Loss: 1.259363055229187\n",
      "Epoch [21/50], Step [6500/7038], D Loss: 0.6407102346420288, G Loss: 1.0443456172943115\n",
      "Epoch [21/50], Step [6600/7038], D Loss: 0.4847230315208435, G Loss: 1.2446539402008057\n",
      "Epoch [21/50], Step [6700/7038], D Loss: 0.42725470662117004, G Loss: 1.5077534914016724\n",
      "Epoch [21/50], Step [6800/7038], D Loss: 0.7647767066955566, G Loss: 1.134305477142334\n",
      "Epoch [21/50], Step [6900/7038], D Loss: 0.3361600637435913, G Loss: 1.5362704992294312\n",
      "Epoch [21/50], Step [7000/7038], D Loss: 0.47461646795272827, G Loss: 1.3717000484466553\n",
      "Epoch [22/50], Step [0/7038], D Loss: 0.53074049949646, G Loss: 1.4230048656463623\n",
      "Epoch [22/50], Step [100/7038], D Loss: 0.3063797354698181, G Loss: 1.8811941146850586\n",
      "Epoch [22/50], Step [200/7038], D Loss: 0.7646704316139221, G Loss: 1.232881784439087\n",
      "Epoch [22/50], Step [300/7038], D Loss: 0.547866940498352, G Loss: 1.1812230348587036\n",
      "Epoch [22/50], Step [400/7038], D Loss: 0.5143746137619019, G Loss: 1.2826623916625977\n",
      "Epoch [22/50], Step [500/7038], D Loss: 0.6520363688468933, G Loss: 1.3412842750549316\n",
      "Epoch [22/50], Step [600/7038], D Loss: 0.583325982093811, G Loss: 1.2942924499511719\n",
      "Epoch [22/50], Step [700/7038], D Loss: 0.26558366417884827, G Loss: 1.7362031936645508\n",
      "Epoch [22/50], Step [800/7038], D Loss: 0.5975500345230103, G Loss: 1.225473403930664\n",
      "Epoch [22/50], Step [900/7038], D Loss: 0.6482527256011963, G Loss: 1.3222366571426392\n",
      "Epoch [22/50], Step [1000/7038], D Loss: 0.6419491171836853, G Loss: 1.2751835584640503\n",
      "Epoch [22/50], Step [1100/7038], D Loss: 0.5123316049575806, G Loss: 1.5671592950820923\n",
      "Epoch [22/50], Step [1200/7038], D Loss: 0.6257486343383789, G Loss: 1.260392189025879\n",
      "Epoch [22/50], Step [1300/7038], D Loss: 0.5216513872146606, G Loss: 1.6224637031555176\n",
      "Epoch [22/50], Step [1400/7038], D Loss: 0.514133095741272, G Loss: 0.9511354565620422\n",
      "Epoch [22/50], Step [1500/7038], D Loss: 0.5377638936042786, G Loss: 1.0609980821609497\n",
      "Epoch [22/50], Step [1600/7038], D Loss: 0.49874117970466614, G Loss: 1.381711721420288\n",
      "Epoch [22/50], Step [1700/7038], D Loss: 0.521467387676239, G Loss: 1.0723494291305542\n",
      "Epoch [22/50], Step [1800/7038], D Loss: 0.529158890247345, G Loss: 1.3415673971176147\n",
      "Epoch [22/50], Step [1900/7038], D Loss: 0.4653528332710266, G Loss: 1.4030667543411255\n",
      "Epoch [22/50], Step [2000/7038], D Loss: 0.5310242176055908, G Loss: 1.1752498149871826\n",
      "Epoch [22/50], Step [2100/7038], D Loss: 0.47311103343963623, G Loss: 1.5209391117095947\n",
      "Epoch [22/50], Step [2200/7038], D Loss: 0.36696237325668335, G Loss: 1.687892198562622\n",
      "Epoch [22/50], Step [2300/7038], D Loss: 0.373694509267807, G Loss: 1.5808247327804565\n",
      "Epoch [22/50], Step [2400/7038], D Loss: 0.6455249786376953, G Loss: 1.3692188262939453\n",
      "Epoch [22/50], Step [2500/7038], D Loss: 0.7437265515327454, G Loss: 0.9245736598968506\n",
      "Epoch [22/50], Step [2600/7038], D Loss: 0.4356076121330261, G Loss: 1.0262837409973145\n",
      "Epoch [22/50], Step [2700/7038], D Loss: 0.5770367980003357, G Loss: 1.4338696002960205\n",
      "Epoch [22/50], Step [2800/7038], D Loss: 0.5881425738334656, G Loss: 1.3835607767105103\n",
      "Epoch [22/50], Step [2900/7038], D Loss: 0.5052221417427063, G Loss: 1.0688278675079346\n",
      "Epoch [22/50], Step [3000/7038], D Loss: 0.464791476726532, G Loss: 1.1463146209716797\n",
      "Epoch [22/50], Step [3100/7038], D Loss: 0.5158519744873047, G Loss: 1.2878758907318115\n",
      "Epoch [22/50], Step [3200/7038], D Loss: 0.4720640778541565, G Loss: 1.5226088762283325\n",
      "Epoch [22/50], Step [3300/7038], D Loss: 0.5066403150558472, G Loss: 1.3499963283538818\n",
      "Epoch [22/50], Step [3400/7038], D Loss: 0.28110751509666443, G Loss: 1.4047306776046753\n",
      "Epoch [22/50], Step [3500/7038], D Loss: 0.5809584856033325, G Loss: 1.0846843719482422\n",
      "Epoch [22/50], Step [3600/7038], D Loss: 0.4894375801086426, G Loss: 1.255219578742981\n",
      "Epoch [22/50], Step [3700/7038], D Loss: 0.304934561252594, G Loss: 1.4990252256393433\n",
      "Epoch [22/50], Step [3800/7038], D Loss: 0.39642512798309326, G Loss: 1.2862484455108643\n",
      "Epoch [22/50], Step [3900/7038], D Loss: 0.31698349118232727, G Loss: 1.610290288925171\n",
      "Epoch [22/50], Step [4000/7038], D Loss: 0.323059618473053, G Loss: 1.9250779151916504\n",
      "Epoch [22/50], Step [4100/7038], D Loss: 0.7004923224449158, G Loss: 1.227006196975708\n",
      "Epoch [22/50], Step [4200/7038], D Loss: 0.2952830195426941, G Loss: 2.098626136779785\n",
      "Epoch [22/50], Step [4300/7038], D Loss: 0.4831092953681946, G Loss: 1.3202039003372192\n",
      "Epoch [22/50], Step [4400/7038], D Loss: 0.6065140962600708, G Loss: 1.1952452659606934\n",
      "Epoch [22/50], Step [4500/7038], D Loss: 0.5782906413078308, G Loss: 1.127244472503662\n",
      "Epoch [22/50], Step [4600/7038], D Loss: 0.4282907247543335, G Loss: 1.2094066143035889\n",
      "Epoch [22/50], Step [4700/7038], D Loss: 0.4592994451522827, G Loss: 1.2606866359710693\n",
      "Epoch [22/50], Step [4800/7038], D Loss: 0.8460807204246521, G Loss: 1.7487127780914307\n",
      "Epoch [22/50], Step [4900/7038], D Loss: 0.5207582116127014, G Loss: 1.8338184356689453\n",
      "Epoch [22/50], Step [5000/7038], D Loss: 0.6623980402946472, G Loss: 1.046769618988037\n",
      "Epoch [22/50], Step [5100/7038], D Loss: 0.46067014336586, G Loss: 1.3704338073730469\n",
      "Epoch [22/50], Step [5200/7038], D Loss: 0.4525013864040375, G Loss: 1.3758385181427002\n",
      "Epoch [22/50], Step [5300/7038], D Loss: 0.6020504236221313, G Loss: 1.0759536027908325\n",
      "Epoch [22/50], Step [5400/7038], D Loss: 0.4547051787376404, G Loss: 1.3897122144699097\n",
      "Epoch [22/50], Step [5500/7038], D Loss: 0.541522741317749, G Loss: 1.1665054559707642\n",
      "Epoch [22/50], Step [5600/7038], D Loss: 0.5051639676094055, G Loss: 1.095270037651062\n",
      "Epoch [22/50], Step [5700/7038], D Loss: 0.3942594826221466, G Loss: 1.2114397287368774\n",
      "Epoch [22/50], Step [5800/7038], D Loss: 0.5586367249488831, G Loss: 1.3815035820007324\n",
      "Epoch [22/50], Step [5900/7038], D Loss: 0.4294169545173645, G Loss: 1.0779520273208618\n",
      "Epoch [22/50], Step [6000/7038], D Loss: 0.4466190040111542, G Loss: 1.4386634826660156\n",
      "Epoch [22/50], Step [6100/7038], D Loss: 0.684918999671936, G Loss: 1.5635353326797485\n",
      "Epoch [22/50], Step [6200/7038], D Loss: 0.632440447807312, G Loss: 1.131677269935608\n",
      "Epoch [22/50], Step [6300/7038], D Loss: 0.3867635130882263, G Loss: 1.521683692932129\n",
      "Epoch [22/50], Step [6400/7038], D Loss: 0.6487033367156982, G Loss: 1.0258103609085083\n",
      "Epoch [22/50], Step [6500/7038], D Loss: 0.5119526982307434, G Loss: 1.4188828468322754\n",
      "Epoch [22/50], Step [6600/7038], D Loss: 0.45163294672966003, G Loss: 1.441746473312378\n",
      "Epoch [22/50], Step [6700/7038], D Loss: 0.5094785094261169, G Loss: 1.24346923828125\n",
      "Epoch [22/50], Step [6800/7038], D Loss: 0.6485844850540161, G Loss: 1.0088598728179932\n",
      "Epoch [22/50], Step [6900/7038], D Loss: 0.32535937428474426, G Loss: 1.815430760383606\n",
      "Epoch [22/50], Step [7000/7038], D Loss: 0.529063880443573, G Loss: 1.923148274421692\n",
      "Epoch [23/50], Step [0/7038], D Loss: 0.5581357479095459, G Loss: 1.4472335577011108\n",
      "Epoch [23/50], Step [100/7038], D Loss: 0.6039434671401978, G Loss: 1.1138497591018677\n",
      "Epoch [23/50], Step [200/7038], D Loss: 0.4668922424316406, G Loss: 1.1155751943588257\n",
      "Epoch [23/50], Step [300/7038], D Loss: 0.612767219543457, G Loss: 1.3030489683151245\n",
      "Epoch [23/50], Step [400/7038], D Loss: 0.351574182510376, G Loss: 1.4532238245010376\n",
      "Epoch [23/50], Step [500/7038], D Loss: 0.375150591135025, G Loss: 1.4404984712600708\n",
      "Epoch [23/50], Step [600/7038], D Loss: 0.4526371955871582, G Loss: 1.2093228101730347\n",
      "Epoch [23/50], Step [700/7038], D Loss: 0.4484224319458008, G Loss: 1.2532293796539307\n",
      "Epoch [23/50], Step [800/7038], D Loss: 0.42858511209487915, G Loss: 1.279274344444275\n",
      "Epoch [23/50], Step [900/7038], D Loss: 0.5420586466789246, G Loss: 1.4450210332870483\n",
      "Epoch [23/50], Step [1000/7038], D Loss: 0.6362918019294739, G Loss: 1.2073935270309448\n",
      "Epoch [23/50], Step [1100/7038], D Loss: 0.43980902433395386, G Loss: 1.6564171314239502\n",
      "Epoch [23/50], Step [1200/7038], D Loss: 0.5356090664863586, G Loss: 1.589668869972229\n",
      "Epoch [23/50], Step [1300/7038], D Loss: 0.3630865514278412, G Loss: 1.2889580726623535\n",
      "Epoch [23/50], Step [1400/7038], D Loss: 0.49079152941703796, G Loss: 1.571895718574524\n",
      "Epoch [23/50], Step [1500/7038], D Loss: 0.8334976434707642, G Loss: 1.255679965019226\n",
      "Epoch [23/50], Step [1600/7038], D Loss: 0.444988489151001, G Loss: 1.2278393507003784\n",
      "Epoch [23/50], Step [1700/7038], D Loss: 0.6412249207496643, G Loss: 1.4185248613357544\n",
      "Epoch [23/50], Step [1800/7038], D Loss: 0.5669203996658325, G Loss: 1.1318997144699097\n",
      "Epoch [23/50], Step [1900/7038], D Loss: 0.7351251244544983, G Loss: 1.3162381649017334\n",
      "Epoch [23/50], Step [2000/7038], D Loss: 0.7357798218727112, G Loss: 1.050419807434082\n",
      "Epoch [23/50], Step [2100/7038], D Loss: 0.5243690013885498, G Loss: 1.2105668783187866\n",
      "Epoch [23/50], Step [2200/7038], D Loss: 0.40007880330085754, G Loss: 1.2799468040466309\n",
      "Epoch [23/50], Step [2300/7038], D Loss: 0.4790157973766327, G Loss: 1.2447497844696045\n",
      "Epoch [23/50], Step [2400/7038], D Loss: 0.5538516044616699, G Loss: 1.055916428565979\n",
      "Epoch [23/50], Step [2500/7038], D Loss: 0.560942530632019, G Loss: 1.162453293800354\n",
      "Epoch [23/50], Step [2600/7038], D Loss: 0.4788733720779419, G Loss: 1.704730749130249\n",
      "Epoch [23/50], Step [2700/7038], D Loss: 0.5073817372322083, G Loss: 1.3498871326446533\n",
      "Epoch [23/50], Step [2800/7038], D Loss: 0.33176136016845703, G Loss: 1.5050809383392334\n",
      "Epoch [23/50], Step [2900/7038], D Loss: 0.4374983608722687, G Loss: 1.4821213483810425\n",
      "Epoch [23/50], Step [3000/7038], D Loss: 0.5459319353103638, G Loss: 2.0811853408813477\n",
      "Epoch [23/50], Step [3100/7038], D Loss: 0.3207487463951111, G Loss: 1.6044690608978271\n",
      "Epoch [23/50], Step [3200/7038], D Loss: 0.3197309076786041, G Loss: 1.6035239696502686\n",
      "Epoch [23/50], Step [3300/7038], D Loss: 0.567853569984436, G Loss: 1.3881396055221558\n",
      "Epoch [23/50], Step [3400/7038], D Loss: 0.40099674463272095, G Loss: 1.174976110458374\n",
      "Epoch [23/50], Step [3500/7038], D Loss: 0.3332674503326416, G Loss: 1.2277140617370605\n",
      "Epoch [23/50], Step [3600/7038], D Loss: 0.4553028345108032, G Loss: 1.4064956903457642\n",
      "Epoch [23/50], Step [3700/7038], D Loss: 0.3957366943359375, G Loss: 1.3026798963546753\n",
      "Epoch [23/50], Step [3800/7038], D Loss: 0.7059503197669983, G Loss: 1.0540356636047363\n",
      "Epoch [23/50], Step [3900/7038], D Loss: 0.42040908336639404, G Loss: 1.4759782552719116\n",
      "Epoch [23/50], Step [4000/7038], D Loss: 0.46450167894363403, G Loss: 1.2392691373825073\n",
      "Epoch [23/50], Step [4100/7038], D Loss: 0.3510337471961975, G Loss: 1.4946167469024658\n",
      "Epoch [23/50], Step [4200/7038], D Loss: 0.6065447330474854, G Loss: 1.1400243043899536\n",
      "Epoch [23/50], Step [4300/7038], D Loss: 0.39019274711608887, G Loss: 1.3047598600387573\n",
      "Epoch [23/50], Step [4400/7038], D Loss: 0.44076305627822876, G Loss: 1.2382615804672241\n",
      "Epoch [23/50], Step [4500/7038], D Loss: 0.6049444675445557, G Loss: 1.307144045829773\n",
      "Epoch [23/50], Step [4600/7038], D Loss: 0.46635332703590393, G Loss: 2.10347318649292\n",
      "Epoch [23/50], Step [4700/7038], D Loss: 0.44643929600715637, G Loss: 1.5799062252044678\n",
      "Epoch [23/50], Step [4800/7038], D Loss: 0.44047290086746216, G Loss: 1.3196537494659424\n",
      "Epoch [23/50], Step [4900/7038], D Loss: 0.43492045998573303, G Loss: 1.2304272651672363\n",
      "Epoch [23/50], Step [5000/7038], D Loss: 0.4943749010562897, G Loss: 1.5959123373031616\n",
      "Epoch [23/50], Step [5100/7038], D Loss: 0.5570612549781799, G Loss: 1.7160338163375854\n",
      "Epoch [23/50], Step [5200/7038], D Loss: 0.7005459070205688, G Loss: 1.6686103343963623\n",
      "Epoch [23/50], Step [5300/7038], D Loss: 0.7008591890335083, G Loss: 1.0937849283218384\n",
      "Epoch [23/50], Step [5400/7038], D Loss: 0.6786981225013733, G Loss: 1.3483883142471313\n",
      "Epoch [23/50], Step [5500/7038], D Loss: 0.6972814798355103, G Loss: 1.4711836576461792\n",
      "Epoch [23/50], Step [5600/7038], D Loss: 0.6400150656700134, G Loss: 0.8786014318466187\n",
      "Epoch [23/50], Step [5700/7038], D Loss: 0.36203742027282715, G Loss: 2.011080265045166\n",
      "Epoch [23/50], Step [5800/7038], D Loss: 0.6735295057296753, G Loss: 0.9456725120544434\n",
      "Epoch [23/50], Step [5900/7038], D Loss: 0.44099873304367065, G Loss: 1.382949709892273\n",
      "Epoch [23/50], Step [6000/7038], D Loss: 0.432265967130661, G Loss: 1.2174159288406372\n",
      "Epoch [23/50], Step [6100/7038], D Loss: 0.5261448621749878, G Loss: 1.4879122972488403\n",
      "Epoch [23/50], Step [6200/7038], D Loss: 0.42381352186203003, G Loss: 1.1818145513534546\n",
      "Epoch [23/50], Step [6300/7038], D Loss: 0.3497219681739807, G Loss: 1.6436772346496582\n",
      "Epoch [23/50], Step [6400/7038], D Loss: 0.5516085028648376, G Loss: 1.6335161924362183\n",
      "Epoch [23/50], Step [6500/7038], D Loss: 0.5304441452026367, G Loss: 1.773073673248291\n",
      "Epoch [23/50], Step [6600/7038], D Loss: 0.6008759140968323, G Loss: 1.2900538444519043\n",
      "Epoch [23/50], Step [6700/7038], D Loss: 0.2967398762702942, G Loss: 1.5470985174179077\n",
      "Epoch [23/50], Step [6800/7038], D Loss: 0.5286046266555786, G Loss: 1.8414644002914429\n",
      "Epoch [23/50], Step [6900/7038], D Loss: 0.3459870219230652, G Loss: 1.7283477783203125\n",
      "Epoch [23/50], Step [7000/7038], D Loss: 0.6047379970550537, G Loss: 1.2875890731811523\n",
      "Epoch [24/50], Step [0/7038], D Loss: 0.43507903814315796, G Loss: 1.6352568864822388\n",
      "Epoch [24/50], Step [100/7038], D Loss: 0.4449215829372406, G Loss: 1.3065799474716187\n",
      "Epoch [24/50], Step [200/7038], D Loss: 0.7198638916015625, G Loss: 0.824219822883606\n",
      "Epoch [24/50], Step [300/7038], D Loss: 0.528449535369873, G Loss: 1.4474650621414185\n",
      "Epoch [24/50], Step [400/7038], D Loss: 0.4690968990325928, G Loss: 1.3234132528305054\n",
      "Epoch [24/50], Step [500/7038], D Loss: 0.37393105030059814, G Loss: 1.361097812652588\n",
      "Epoch [24/50], Step [600/7038], D Loss: 0.653469979763031, G Loss: 1.1601046323776245\n",
      "Epoch [24/50], Step [700/7038], D Loss: 0.3787667751312256, G Loss: 1.4049018621444702\n",
      "Epoch [24/50], Step [800/7038], D Loss: 0.49829351902008057, G Loss: 1.395385503768921\n",
      "Epoch [24/50], Step [900/7038], D Loss: 0.377467542886734, G Loss: 1.7103986740112305\n",
      "Epoch [24/50], Step [1000/7038], D Loss: 0.4019867777824402, G Loss: 1.4813923835754395\n",
      "Epoch [24/50], Step [1100/7038], D Loss: 0.35611942410469055, G Loss: 1.2583768367767334\n",
      "Epoch [24/50], Step [1200/7038], D Loss: 0.4243403673171997, G Loss: 1.5375536680221558\n",
      "Epoch [24/50], Step [1300/7038], D Loss: 0.4622108042240143, G Loss: 1.3597633838653564\n",
      "Epoch [24/50], Step [1400/7038], D Loss: 0.44970205426216125, G Loss: 1.1656301021575928\n",
      "Epoch [24/50], Step [1500/7038], D Loss: 0.4182397723197937, G Loss: 1.753411054611206\n",
      "Epoch [24/50], Step [1600/7038], D Loss: 0.39730745553970337, G Loss: 1.400484561920166\n",
      "Epoch [24/50], Step [1700/7038], D Loss: 0.46843892335891724, G Loss: 1.2072325944900513\n",
      "Epoch [24/50], Step [1800/7038], D Loss: 0.6083418130874634, G Loss: 0.8703112006187439\n",
      "Epoch [24/50], Step [1900/7038], D Loss: 0.5608788132667542, G Loss: 1.1748154163360596\n",
      "Epoch [24/50], Step [2000/7038], D Loss: 0.42630571126937866, G Loss: 1.5975010395050049\n",
      "Epoch [24/50], Step [2100/7038], D Loss: 0.41800275444984436, G Loss: 1.8935621976852417\n",
      "Epoch [24/50], Step [2200/7038], D Loss: 0.809790313243866, G Loss: 1.3380062580108643\n",
      "Epoch [24/50], Step [2300/7038], D Loss: 0.5143065452575684, G Loss: 1.385420560836792\n",
      "Epoch [24/50], Step [2400/7038], D Loss: 0.6690186262130737, G Loss: 1.7442474365234375\n",
      "Epoch [24/50], Step [2500/7038], D Loss: 0.5744547843933105, G Loss: 1.3619067668914795\n",
      "Epoch [24/50], Step [2600/7038], D Loss: 0.7258325815200806, G Loss: 1.2571111917495728\n",
      "Epoch [24/50], Step [2700/7038], D Loss: 0.5568147301673889, G Loss: 1.291572093963623\n",
      "Epoch [24/50], Step [2800/7038], D Loss: 0.6115124225616455, G Loss: 0.9111764430999756\n",
      "Epoch [24/50], Step [2900/7038], D Loss: 0.5472282767295837, G Loss: 1.4158579111099243\n",
      "Epoch [24/50], Step [3000/7038], D Loss: 0.32257896661758423, G Loss: 1.4436538219451904\n",
      "Epoch [24/50], Step [3100/7038], D Loss: 0.7293604612350464, G Loss: 1.2412222623825073\n",
      "Epoch [24/50], Step [3200/7038], D Loss: 0.5208835601806641, G Loss: 1.47907292842865\n",
      "Epoch [24/50], Step [3300/7038], D Loss: 0.6228657364845276, G Loss: 1.241586446762085\n",
      "Epoch [24/50], Step [3400/7038], D Loss: 0.7087686061859131, G Loss: 1.6617752313613892\n",
      "Epoch [24/50], Step [3500/7038], D Loss: 0.5207346677780151, G Loss: 1.1721760034561157\n",
      "Epoch [24/50], Step [3600/7038], D Loss: 0.5945225954055786, G Loss: 1.468026876449585\n",
      "Epoch [24/50], Step [3700/7038], D Loss: 0.376655250787735, G Loss: 1.6385784149169922\n",
      "Epoch [24/50], Step [3800/7038], D Loss: 0.5261536836624146, G Loss: 1.4092490673065186\n",
      "Epoch [24/50], Step [3900/7038], D Loss: 0.6595840454101562, G Loss: 1.221096158027649\n",
      "Epoch [24/50], Step [4000/7038], D Loss: 0.5457456111907959, G Loss: 1.2549470663070679\n",
      "Epoch [24/50], Step [4100/7038], D Loss: 0.4794589877128601, G Loss: 1.5240557193756104\n",
      "Epoch [24/50], Step [4200/7038], D Loss: 0.6592721343040466, G Loss: 1.073898434638977\n",
      "Epoch [24/50], Step [4300/7038], D Loss: 0.5268003940582275, G Loss: 1.622509241104126\n",
      "Epoch [24/50], Step [4400/7038], D Loss: 0.5294307470321655, G Loss: 1.2265757322311401\n",
      "Epoch [24/50], Step [4500/7038], D Loss: 0.6100285053253174, G Loss: 1.2439141273498535\n",
      "Epoch [24/50], Step [4600/7038], D Loss: 0.6031755208969116, G Loss: 1.0876195430755615\n",
      "Epoch [24/50], Step [4700/7038], D Loss: 0.577049732208252, G Loss: 1.1839340925216675\n",
      "Epoch [24/50], Step [4800/7038], D Loss: 0.6202505230903625, G Loss: 1.2389090061187744\n",
      "Epoch [24/50], Step [4900/7038], D Loss: 0.5166269540786743, G Loss: 1.1230906248092651\n",
      "Epoch [24/50], Step [5000/7038], D Loss: 0.49288421869277954, G Loss: 1.4085701704025269\n",
      "Epoch [24/50], Step [5100/7038], D Loss: 0.5521210432052612, G Loss: 1.3551526069641113\n",
      "Epoch [24/50], Step [5200/7038], D Loss: 0.7441134452819824, G Loss: 1.3051929473876953\n",
      "Epoch [24/50], Step [5300/7038], D Loss: 0.2999383807182312, G Loss: 1.6447473764419556\n",
      "Epoch [24/50], Step [5400/7038], D Loss: 0.29017603397369385, G Loss: 1.6456286907196045\n",
      "Epoch [24/50], Step [5500/7038], D Loss: 0.4066230356693268, G Loss: 1.3414961099624634\n",
      "Epoch [24/50], Step [5600/7038], D Loss: 0.4343414306640625, G Loss: 1.5378758907318115\n",
      "Epoch [24/50], Step [5700/7038], D Loss: 0.38677167892456055, G Loss: 1.6232513189315796\n",
      "Epoch [24/50], Step [5800/7038], D Loss: 0.4063846170902252, G Loss: 1.6099261045455933\n",
      "Epoch [24/50], Step [5900/7038], D Loss: 0.4388333559036255, G Loss: 1.501845359802246\n",
      "Epoch [24/50], Step [6000/7038], D Loss: 0.5375874638557434, G Loss: 1.1450833082199097\n",
      "Epoch [24/50], Step [6100/7038], D Loss: 0.3611051142215729, G Loss: 1.4397027492523193\n",
      "Epoch [24/50], Step [6200/7038], D Loss: 0.5892369151115417, G Loss: 2.1685245037078857\n",
      "Epoch [24/50], Step [6300/7038], D Loss: 0.8670811057090759, G Loss: 1.295163869857788\n",
      "Epoch [24/50], Step [6400/7038], D Loss: 0.6955071687698364, G Loss: 0.952100396156311\n",
      "Epoch [24/50], Step [6500/7038], D Loss: 0.5175867080688477, G Loss: 1.3287837505340576\n",
      "Epoch [24/50], Step [6600/7038], D Loss: 0.6126970052719116, G Loss: 1.4085776805877686\n",
      "Epoch [24/50], Step [6700/7038], D Loss: 0.476252943277359, G Loss: 1.3066141605377197\n",
      "Epoch [24/50], Step [6800/7038], D Loss: 0.47965115308761597, G Loss: 2.1463539600372314\n",
      "Epoch [24/50], Step [6900/7038], D Loss: 0.41128191351890564, G Loss: 1.5241471529006958\n",
      "Epoch [24/50], Step [7000/7038], D Loss: 0.4471561312675476, G Loss: 1.4694879055023193\n",
      "Epoch [25/50], Step [0/7038], D Loss: 0.3130640387535095, G Loss: 1.41939377784729\n",
      "Epoch [25/50], Step [100/7038], D Loss: 0.4215604066848755, G Loss: 1.516420602798462\n",
      "Epoch [25/50], Step [200/7038], D Loss: 0.4447914958000183, G Loss: 1.4364240169525146\n",
      "Epoch [25/50], Step [300/7038], D Loss: 0.2994057238101959, G Loss: 2.2885618209838867\n",
      "Epoch [25/50], Step [400/7038], D Loss: 0.8667461276054382, G Loss: 1.6190223693847656\n",
      "Epoch [25/50], Step [500/7038], D Loss: 0.5082957744598389, G Loss: 1.2535096406936646\n",
      "Epoch [25/50], Step [600/7038], D Loss: 0.4628865122795105, G Loss: 1.3773123025894165\n",
      "Epoch [25/50], Step [700/7038], D Loss: 0.4309501051902771, G Loss: 1.6497581005096436\n",
      "Epoch [25/50], Step [800/7038], D Loss: 0.2963363826274872, G Loss: 1.4148930311203003\n",
      "Epoch [25/50], Step [900/7038], D Loss: 0.5193189382553101, G Loss: 1.8667114973068237\n",
      "Epoch [25/50], Step [1000/7038], D Loss: 0.5033208131790161, G Loss: 1.2645049095153809\n",
      "Epoch [25/50], Step [1100/7038], D Loss: 0.3352116346359253, G Loss: 1.6619112491607666\n",
      "Epoch [25/50], Step [1200/7038], D Loss: 0.23832616209983826, G Loss: 1.7611240148544312\n",
      "Epoch [25/50], Step [1300/7038], D Loss: 0.5668823719024658, G Loss: 1.0899471044540405\n",
      "Epoch [25/50], Step [1400/7038], D Loss: 0.6053511500358582, G Loss: 0.9984812140464783\n",
      "Epoch [25/50], Step [1500/7038], D Loss: 0.6076308488845825, G Loss: 1.6574779748916626\n",
      "Epoch [25/50], Step [1600/7038], D Loss: 0.49467337131500244, G Loss: 1.3041437864303589\n",
      "Epoch [25/50], Step [1700/7038], D Loss: 0.5184711217880249, G Loss: 1.260200023651123\n",
      "Epoch [25/50], Step [1800/7038], D Loss: 0.3351415991783142, G Loss: 1.6371935606002808\n",
      "Epoch [25/50], Step [1900/7038], D Loss: 0.39855098724365234, G Loss: 1.3780146837234497\n",
      "Epoch [25/50], Step [2000/7038], D Loss: 0.8685402870178223, G Loss: 1.047093152999878\n",
      "Epoch [25/50], Step [2100/7038], D Loss: 0.3058355450630188, G Loss: 1.551110863685608\n",
      "Epoch [25/50], Step [2200/7038], D Loss: 0.6039770245552063, G Loss: 1.4953950643539429\n",
      "Epoch [25/50], Step [2300/7038], D Loss: 0.3519989252090454, G Loss: 1.5073786973953247\n",
      "Epoch [25/50], Step [2400/7038], D Loss: 0.5464349389076233, G Loss: 1.3936997652053833\n",
      "Epoch [25/50], Step [2500/7038], D Loss: 0.6865172982215881, G Loss: 1.353768229484558\n",
      "Epoch [25/50], Step [2600/7038], D Loss: 0.4942246675491333, G Loss: 1.1738680601119995\n",
      "Epoch [25/50], Step [2700/7038], D Loss: 0.536899209022522, G Loss: 1.5138272047042847\n",
      "Epoch [25/50], Step [2800/7038], D Loss: 0.4349571168422699, G Loss: 1.261913776397705\n",
      "Epoch [25/50], Step [2900/7038], D Loss: 0.4946410655975342, G Loss: 1.1258726119995117\n",
      "Epoch [25/50], Step [3000/7038], D Loss: 0.48572874069213867, G Loss: 1.4662178754806519\n",
      "Epoch [25/50], Step [3100/7038], D Loss: 0.4709088206291199, G Loss: 1.2291619777679443\n",
      "Epoch [25/50], Step [3200/7038], D Loss: 0.3807235658168793, G Loss: 1.3965450525283813\n",
      "Epoch [25/50], Step [3300/7038], D Loss: 0.34696730971336365, G Loss: 1.8759738206863403\n",
      "Epoch [25/50], Step [3400/7038], D Loss: 0.2775575518608093, G Loss: 1.7165132761001587\n",
      "Epoch [25/50], Step [3500/7038], D Loss: 0.5982353687286377, G Loss: 1.0253605842590332\n",
      "Epoch [25/50], Step [3600/7038], D Loss: 0.5311132669448853, G Loss: 1.5560333728790283\n",
      "Epoch [25/50], Step [3700/7038], D Loss: 0.311212420463562, G Loss: 1.5314019918441772\n",
      "Epoch [25/50], Step [3800/7038], D Loss: 0.45659559965133667, G Loss: 1.3985298871994019\n",
      "Epoch [25/50], Step [3900/7038], D Loss: 0.6311612129211426, G Loss: 1.0992618799209595\n",
      "Epoch [25/50], Step [4000/7038], D Loss: 0.565476655960083, G Loss: 1.7128045558929443\n",
      "Epoch [25/50], Step [4100/7038], D Loss: 0.5301002264022827, G Loss: 1.1568560600280762\n",
      "Epoch [25/50], Step [4200/7038], D Loss: 0.3236859440803528, G Loss: 1.6848150491714478\n",
      "Epoch [25/50], Step [4300/7038], D Loss: 0.558487057685852, G Loss: 1.2327229976654053\n",
      "Epoch [25/50], Step [4400/7038], D Loss: 0.5473722219467163, G Loss: 1.4930139780044556\n",
      "Epoch [25/50], Step [4500/7038], D Loss: 0.5151656270027161, G Loss: 1.6173380613327026\n",
      "Epoch [25/50], Step [4600/7038], D Loss: 0.41496509313583374, G Loss: 1.5420314073562622\n",
      "Epoch [25/50], Step [4700/7038], D Loss: 0.5716699361801147, G Loss: 1.669162392616272\n",
      "Epoch [25/50], Step [4800/7038], D Loss: 0.5051623582839966, G Loss: 1.2062578201293945\n",
      "Epoch [25/50], Step [4900/7038], D Loss: 0.35588693618774414, G Loss: 1.6568721532821655\n",
      "Epoch [25/50], Step [5000/7038], D Loss: 0.48867231607437134, G Loss: 2.6540400981903076\n",
      "Epoch [25/50], Step [5100/7038], D Loss: 0.43349188566207886, G Loss: 1.3989431858062744\n",
      "Epoch [25/50], Step [5200/7038], D Loss: 0.47819995880126953, G Loss: 1.1414415836334229\n",
      "Epoch [25/50], Step [5300/7038], D Loss: 0.5032892227172852, G Loss: 1.3758800029754639\n",
      "Epoch [25/50], Step [5400/7038], D Loss: 0.28208622336387634, G Loss: 1.6865966320037842\n",
      "Epoch [25/50], Step [5500/7038], D Loss: 0.38234949111938477, G Loss: 1.7605056762695312\n",
      "Epoch [25/50], Step [5600/7038], D Loss: 0.4817480444908142, G Loss: 1.2126373052597046\n",
      "Epoch [25/50], Step [5700/7038], D Loss: 0.4128815531730652, G Loss: 1.359178066253662\n",
      "Epoch [25/50], Step [5800/7038], D Loss: 0.529221773147583, G Loss: 1.075465202331543\n",
      "Epoch [25/50], Step [5900/7038], D Loss: 0.3763960897922516, G Loss: 1.4028584957122803\n",
      "Epoch [25/50], Step [6000/7038], D Loss: 0.1985635757446289, G Loss: 2.233306646347046\n",
      "Epoch [25/50], Step [6100/7038], D Loss: 0.8491275310516357, G Loss: 1.2495417594909668\n",
      "Epoch [25/50], Step [6200/7038], D Loss: 0.29521918296813965, G Loss: 1.771768569946289\n",
      "Epoch [25/50], Step [6300/7038], D Loss: 0.5265165567398071, G Loss: 1.3490322828292847\n",
      "Epoch [25/50], Step [6400/7038], D Loss: 0.3396512269973755, G Loss: 1.9014836549758911\n",
      "Epoch [25/50], Step [6500/7038], D Loss: 0.39689284563064575, G Loss: 1.6721478700637817\n",
      "Epoch [25/50], Step [6600/7038], D Loss: 0.4323204755783081, G Loss: 1.2319295406341553\n",
      "Epoch [25/50], Step [6700/7038], D Loss: 0.433086633682251, G Loss: 1.410735845565796\n",
      "Epoch [25/50], Step [6800/7038], D Loss: 0.5620359778404236, G Loss: 1.324469804763794\n",
      "Epoch [25/50], Step [6900/7038], D Loss: 0.8161826729774475, G Loss: 1.3415714502334595\n",
      "Epoch [25/50], Step [7000/7038], D Loss: 0.7588052153587341, G Loss: 1.3259018659591675\n",
      "Epoch [26/50], Step [0/7038], D Loss: 0.4644044041633606, G Loss: 1.298477292060852\n",
      "Epoch [26/50], Step [100/7038], D Loss: 0.4184393882751465, G Loss: 1.378237009048462\n",
      "Epoch [26/50], Step [200/7038], D Loss: 0.42391806840896606, G Loss: 1.490919589996338\n",
      "Epoch [26/50], Step [300/7038], D Loss: 0.603524923324585, G Loss: 1.3119940757751465\n",
      "Epoch [26/50], Step [400/7038], D Loss: 0.28790390491485596, G Loss: 2.0807905197143555\n",
      "Epoch [26/50], Step [500/7038], D Loss: 0.7269653081893921, G Loss: 1.1125191450119019\n",
      "Epoch [26/50], Step [600/7038], D Loss: 0.3731909692287445, G Loss: 1.4639105796813965\n",
      "Epoch [26/50], Step [700/7038], D Loss: 0.606072187423706, G Loss: 1.2209805250167847\n",
      "Epoch [26/50], Step [800/7038], D Loss: 0.6494187116622925, G Loss: 1.309259295463562\n",
      "Epoch [26/50], Step [900/7038], D Loss: 0.41936448216438293, G Loss: 1.7098416090011597\n",
      "Epoch [26/50], Step [1000/7038], D Loss: 0.4664353132247925, G Loss: 1.4360415935516357\n",
      "Epoch [26/50], Step [1100/7038], D Loss: 0.2762734293937683, G Loss: 1.7164382934570312\n",
      "Epoch [26/50], Step [1200/7038], D Loss: 0.4971218705177307, G Loss: 1.3134838342666626\n",
      "Epoch [26/50], Step [1300/7038], D Loss: 0.35255295038223267, G Loss: 1.9959129095077515\n",
      "Epoch [26/50], Step [1400/7038], D Loss: 0.6566490530967712, G Loss: 1.150862216949463\n",
      "Epoch [26/50], Step [1500/7038], D Loss: 0.6837819814682007, G Loss: 0.9806510806083679\n",
      "Epoch [26/50], Step [1600/7038], D Loss: 0.4825601577758789, G Loss: 1.1185170412063599\n",
      "Epoch [26/50], Step [1700/7038], D Loss: 0.2734091579914093, G Loss: 1.7922515869140625\n",
      "Epoch [26/50], Step [1800/7038], D Loss: 0.51508629322052, G Loss: 1.1833688020706177\n",
      "Epoch [26/50], Step [1900/7038], D Loss: 0.47111791372299194, G Loss: 1.2777371406555176\n",
      "Epoch [26/50], Step [2000/7038], D Loss: 0.5647401809692383, G Loss: 1.0876818895339966\n",
      "Epoch [26/50], Step [2100/7038], D Loss: 0.48404550552368164, G Loss: 1.211973786354065\n",
      "Epoch [26/50], Step [2200/7038], D Loss: 0.5917103290557861, G Loss: 1.4788495302200317\n",
      "Epoch [26/50], Step [2300/7038], D Loss: 0.49761825799942017, G Loss: 1.2927998304367065\n",
      "Epoch [26/50], Step [2400/7038], D Loss: 0.423866331577301, G Loss: 1.3270838260650635\n",
      "Epoch [26/50], Step [2500/7038], D Loss: 0.4488310217857361, G Loss: 1.3889245986938477\n",
      "Epoch [26/50], Step [2600/7038], D Loss: 0.6015718579292297, G Loss: 1.072326898574829\n",
      "Epoch [26/50], Step [2700/7038], D Loss: 0.49113374948501587, G Loss: 1.2392079830169678\n",
      "Epoch [26/50], Step [2800/7038], D Loss: 0.4502338767051697, G Loss: 1.3051488399505615\n",
      "Epoch [26/50], Step [2900/7038], D Loss: 0.9489994645118713, G Loss: 1.6389421224594116\n",
      "Epoch [26/50], Step [3000/7038], D Loss: 0.3323787450790405, G Loss: 1.6015491485595703\n",
      "Epoch [26/50], Step [3100/7038], D Loss: 0.6886448860168457, G Loss: 0.9492830634117126\n",
      "Epoch [26/50], Step [3200/7038], D Loss: 0.5795727372169495, G Loss: 1.6245454549789429\n",
      "Epoch [26/50], Step [3300/7038], D Loss: 0.48533695936203003, G Loss: 1.3763461112976074\n",
      "Epoch [26/50], Step [3400/7038], D Loss: 0.4669994115829468, G Loss: 1.3539150953292847\n",
      "Epoch [26/50], Step [3500/7038], D Loss: 0.6983525156974792, G Loss: 1.2709077596664429\n",
      "Epoch [26/50], Step [3600/7038], D Loss: 0.37699106335639954, G Loss: 1.4386509656906128\n",
      "Epoch [26/50], Step [3700/7038], D Loss: 0.37939202785491943, G Loss: 1.2714520692825317\n",
      "Epoch [26/50], Step [3800/7038], D Loss: 0.3736572861671448, G Loss: 1.4090838432312012\n",
      "Epoch [26/50], Step [3900/7038], D Loss: 0.31202006340026855, G Loss: 1.5707181692123413\n",
      "Epoch [26/50], Step [4000/7038], D Loss: 0.4387836456298828, G Loss: 1.3437772989273071\n",
      "Epoch [26/50], Step [4100/7038], D Loss: 0.48206859827041626, G Loss: 1.056296944618225\n",
      "Epoch [26/50], Step [4200/7038], D Loss: 0.46903887391090393, G Loss: 1.186570644378662\n",
      "Epoch [26/50], Step [4300/7038], D Loss: 0.6323121190071106, G Loss: 2.4412105083465576\n",
      "Epoch [26/50], Step [4400/7038], D Loss: 0.4254649877548218, G Loss: 1.1890051364898682\n",
      "Epoch [26/50], Step [4500/7038], D Loss: 0.5341921448707581, G Loss: 1.0716369152069092\n",
      "Epoch [26/50], Step [4600/7038], D Loss: 0.36361563205718994, G Loss: 1.355263113975525\n",
      "Epoch [26/50], Step [4700/7038], D Loss: 0.49580496549606323, G Loss: 1.3227088451385498\n",
      "Epoch [26/50], Step [4800/7038], D Loss: 0.3822517395019531, G Loss: 1.3363921642303467\n",
      "Epoch [26/50], Step [4900/7038], D Loss: 0.3852149248123169, G Loss: 1.5207103490829468\n",
      "Epoch [26/50], Step [5000/7038], D Loss: 0.34793683886528015, G Loss: 2.3006844520568848\n",
      "Epoch [26/50], Step [5100/7038], D Loss: 0.3048127293586731, G Loss: 1.868154764175415\n",
      "Epoch [26/50], Step [5200/7038], D Loss: 0.7074558734893799, G Loss: 1.1977847814559937\n",
      "Epoch [26/50], Step [5300/7038], D Loss: 0.6167672276496887, G Loss: 1.381210446357727\n",
      "Epoch [26/50], Step [5400/7038], D Loss: 0.6056143045425415, G Loss: 1.1958800554275513\n",
      "Epoch [26/50], Step [5500/7038], D Loss: 0.6964848637580872, G Loss: 1.0744796991348267\n",
      "Epoch [26/50], Step [5600/7038], D Loss: 0.45161205530166626, G Loss: 1.4856444597244263\n",
      "Epoch [26/50], Step [5700/7038], D Loss: 0.5474193096160889, G Loss: 1.1875799894332886\n",
      "Epoch [26/50], Step [5800/7038], D Loss: 0.3740497827529907, G Loss: 1.4992417097091675\n",
      "Epoch [26/50], Step [5900/7038], D Loss: 0.43864375352859497, G Loss: 1.4936267137527466\n",
      "Epoch [26/50], Step [6000/7038], D Loss: 0.5466992259025574, G Loss: 1.2342710494995117\n",
      "Epoch [26/50], Step [6100/7038], D Loss: 0.40796151757240295, G Loss: 1.4010248184204102\n",
      "Epoch [26/50], Step [6200/7038], D Loss: 0.34207484126091003, G Loss: 1.4289416074752808\n",
      "Epoch [26/50], Step [6300/7038], D Loss: 0.5923187732696533, G Loss: 1.183635950088501\n",
      "Epoch [26/50], Step [6400/7038], D Loss: 0.7505386471748352, G Loss: 1.3156969547271729\n",
      "Epoch [26/50], Step [6500/7038], D Loss: 0.3451206088066101, G Loss: 1.7285292148590088\n",
      "Epoch [26/50], Step [6600/7038], D Loss: 0.6902351379394531, G Loss: 1.2058727741241455\n",
      "Epoch [26/50], Step [6700/7038], D Loss: 0.3968466520309448, G Loss: 1.4017854928970337\n",
      "Epoch [26/50], Step [6800/7038], D Loss: 0.6091591119766235, G Loss: 1.1247254610061646\n",
      "Epoch [26/50], Step [6900/7038], D Loss: 0.2952476739883423, G Loss: 1.56078040599823\n",
      "Epoch [26/50], Step [7000/7038], D Loss: 0.4373362064361572, G Loss: 1.5465036630630493\n",
      "Epoch [27/50], Step [0/7038], D Loss: 0.6372485160827637, G Loss: 1.6721919775009155\n",
      "Epoch [27/50], Step [100/7038], D Loss: 0.5506452322006226, G Loss: 1.4005768299102783\n",
      "Epoch [27/50], Step [200/7038], D Loss: 0.33706748485565186, G Loss: 1.429020643234253\n",
      "Epoch [27/50], Step [300/7038], D Loss: 0.48912662267684937, G Loss: 1.3862284421920776\n",
      "Epoch [27/50], Step [400/7038], D Loss: 0.3433164954185486, G Loss: 1.4253634214401245\n",
      "Epoch [27/50], Step [500/7038], D Loss: 0.4662489593029022, G Loss: 1.1477925777435303\n",
      "Epoch [27/50], Step [600/7038], D Loss: 0.47428882122039795, G Loss: 1.1499813795089722\n",
      "Epoch [27/50], Step [700/7038], D Loss: 0.40026164054870605, G Loss: 1.124015212059021\n",
      "Epoch [27/50], Step [800/7038], D Loss: 0.46761298179626465, G Loss: 1.3358148336410522\n",
      "Epoch [27/50], Step [900/7038], D Loss: 0.5808206796646118, G Loss: 1.5234284400939941\n",
      "Epoch [27/50], Step [1000/7038], D Loss: 0.6739764213562012, G Loss: 1.266644835472107\n",
      "Epoch [27/50], Step [1100/7038], D Loss: 0.3241637945175171, G Loss: 1.3075016736984253\n",
      "Epoch [27/50], Step [1200/7038], D Loss: 0.6388654708862305, G Loss: 1.2635002136230469\n",
      "Epoch [27/50], Step [1300/7038], D Loss: 0.5340061187744141, G Loss: 1.1819664239883423\n",
      "Epoch [27/50], Step [1400/7038], D Loss: 0.4273887276649475, G Loss: 1.371407151222229\n",
      "Epoch [27/50], Step [1500/7038], D Loss: 0.5790221691131592, G Loss: 1.431620717048645\n",
      "Epoch [27/50], Step [1600/7038], D Loss: 0.3403928577899933, G Loss: 1.3649271726608276\n",
      "Epoch [27/50], Step [1700/7038], D Loss: 0.3760465979576111, G Loss: 1.2591331005096436\n",
      "Epoch [27/50], Step [1800/7038], D Loss: 0.735937237739563, G Loss: 0.8496402502059937\n",
      "Epoch [27/50], Step [1900/7038], D Loss: 0.3762636184692383, G Loss: 1.3557837009429932\n",
      "Epoch [27/50], Step [2000/7038], D Loss: 0.3416481614112854, G Loss: 1.2792357206344604\n",
      "Epoch [27/50], Step [2100/7038], D Loss: 0.42801612615585327, G Loss: 1.499694585800171\n",
      "Epoch [27/50], Step [2200/7038], D Loss: 0.5819406509399414, G Loss: 1.1402192115783691\n",
      "Epoch [27/50], Step [2300/7038], D Loss: 0.526612401008606, G Loss: 1.3584145307540894\n",
      "Epoch [27/50], Step [2400/7038], D Loss: 0.508661687374115, G Loss: 1.2841053009033203\n",
      "Epoch [27/50], Step [2500/7038], D Loss: 0.5247538089752197, G Loss: 1.0296934843063354\n",
      "Epoch [27/50], Step [2600/7038], D Loss: 0.4669229984283447, G Loss: 1.4687461853027344\n",
      "Epoch [27/50], Step [2700/7038], D Loss: 0.24222427606582642, G Loss: 1.610994815826416\n",
      "Epoch [27/50], Step [2800/7038], D Loss: 0.5978996753692627, G Loss: 1.3083239793777466\n",
      "Epoch [27/50], Step [2900/7038], D Loss: 0.40664243698120117, G Loss: 1.3631500005722046\n",
      "Epoch [27/50], Step [3000/7038], D Loss: 0.6943422555923462, G Loss: 1.4523284435272217\n",
      "Epoch [27/50], Step [3100/7038], D Loss: 0.596723198890686, G Loss: 1.0829517841339111\n",
      "Epoch [27/50], Step [3200/7038], D Loss: 0.4967397451400757, G Loss: 1.0106409788131714\n",
      "Epoch [27/50], Step [3300/7038], D Loss: 0.45674580335617065, G Loss: 1.4966970682144165\n",
      "Epoch [27/50], Step [3400/7038], D Loss: 0.4550451636314392, G Loss: 1.6677697896957397\n",
      "Epoch [27/50], Step [3500/7038], D Loss: 0.6059523820877075, G Loss: 1.2944996356964111\n",
      "Epoch [27/50], Step [3600/7038], D Loss: 0.4346906244754791, G Loss: 1.7187339067459106\n",
      "Epoch [27/50], Step [3700/7038], D Loss: 0.4516187608242035, G Loss: 1.2493970394134521\n",
      "Epoch [27/50], Step [3800/7038], D Loss: 0.4252069294452667, G Loss: 1.5374689102172852\n",
      "Epoch [27/50], Step [3900/7038], D Loss: 0.4136713147163391, G Loss: 1.4538681507110596\n",
      "Epoch [27/50], Step [4000/7038], D Loss: 0.42222505807876587, G Loss: 1.2851905822753906\n",
      "Epoch [27/50], Step [4100/7038], D Loss: 0.5166988372802734, G Loss: 1.3347750902175903\n",
      "Epoch [27/50], Step [4200/7038], D Loss: 0.49788230657577515, G Loss: 1.64900541305542\n",
      "Epoch [27/50], Step [4300/7038], D Loss: 0.5774127244949341, G Loss: 1.6042238473892212\n",
      "Epoch [27/50], Step [4400/7038], D Loss: 0.6267868876457214, G Loss: 1.1959632635116577\n",
      "Epoch [27/50], Step [4500/7038], D Loss: 0.5772860646247864, G Loss: 1.5390253067016602\n",
      "Epoch [27/50], Step [4600/7038], D Loss: 0.3933456540107727, G Loss: 1.5636824369430542\n",
      "Epoch [27/50], Step [4700/7038], D Loss: 0.38693928718566895, G Loss: 1.3955022096633911\n",
      "Epoch [27/50], Step [4800/7038], D Loss: 0.39567407965660095, G Loss: 1.4933415651321411\n",
      "Epoch [27/50], Step [4900/7038], D Loss: 0.5148884057998657, G Loss: 1.2633442878723145\n",
      "Epoch [27/50], Step [5000/7038], D Loss: 0.5743265151977539, G Loss: 1.18254554271698\n",
      "Epoch [27/50], Step [5100/7038], D Loss: 0.5259672403335571, G Loss: 1.048228144645691\n",
      "Epoch [27/50], Step [5200/7038], D Loss: 0.659443199634552, G Loss: 1.174088478088379\n",
      "Epoch [27/50], Step [5300/7038], D Loss: 0.43574607372283936, G Loss: 1.4938251972198486\n",
      "Epoch [27/50], Step [5400/7038], D Loss: 0.660961389541626, G Loss: 1.2959741353988647\n",
      "Epoch [27/50], Step [5500/7038], D Loss: 0.48199665546417236, G Loss: 1.2754487991333008\n",
      "Epoch [27/50], Step [5600/7038], D Loss: 0.49409592151641846, G Loss: 1.260178565979004\n",
      "Epoch [27/50], Step [5700/7038], D Loss: 0.5170285701751709, G Loss: 1.6584248542785645\n",
      "Epoch [27/50], Step [5800/7038], D Loss: 0.506965160369873, G Loss: 1.35205078125\n",
      "Epoch [27/50], Step [5900/7038], D Loss: 0.46311068534851074, G Loss: 1.4030791521072388\n",
      "Epoch [27/50], Step [6000/7038], D Loss: 0.34165120124816895, G Loss: 1.6705513000488281\n",
      "Epoch [27/50], Step [6100/7038], D Loss: 0.5835102796554565, G Loss: 1.3107455968856812\n",
      "Epoch [27/50], Step [6200/7038], D Loss: 0.46249473094940186, G Loss: 1.710615873336792\n",
      "Epoch [27/50], Step [6300/7038], D Loss: 0.6293070912361145, G Loss: 0.9674028754234314\n",
      "Epoch [27/50], Step [6400/7038], D Loss: 0.6388794183731079, G Loss: 1.7864934206008911\n",
      "Epoch [27/50], Step [6500/7038], D Loss: 0.4672764241695404, G Loss: 1.2758119106292725\n",
      "Epoch [27/50], Step [6600/7038], D Loss: 0.7368106245994568, G Loss: 1.3813936710357666\n",
      "Epoch [27/50], Step [6700/7038], D Loss: 0.6457728147506714, G Loss: 1.272576093673706\n",
      "Epoch [27/50], Step [6800/7038], D Loss: 0.44724833965301514, G Loss: 1.3636267185211182\n",
      "Epoch [27/50], Step [6900/7038], D Loss: 0.39114779233932495, G Loss: 1.3489705324172974\n",
      "Epoch [27/50], Step [7000/7038], D Loss: 0.43521904945373535, G Loss: 1.5748276710510254\n",
      "Epoch [28/50], Step [0/7038], D Loss: 0.5008915662765503, G Loss: 1.5245996713638306\n",
      "Epoch [28/50], Step [100/7038], D Loss: 0.7064812183380127, G Loss: 1.2675193548202515\n",
      "Epoch [28/50], Step [200/7038], D Loss: 0.5608351230621338, G Loss: 1.8497523069381714\n",
      "Epoch [28/50], Step [300/7038], D Loss: 0.5036202073097229, G Loss: 1.312003493309021\n",
      "Epoch [28/50], Step [400/7038], D Loss: 0.37862586975097656, G Loss: 1.3543591499328613\n",
      "Epoch [28/50], Step [500/7038], D Loss: 0.3224268853664398, G Loss: 1.445475697517395\n",
      "Epoch [28/50], Step [600/7038], D Loss: 0.28472083806991577, G Loss: 1.521416425704956\n",
      "Epoch [28/50], Step [700/7038], D Loss: 0.4982373118400574, G Loss: 0.9996452927589417\n",
      "Epoch [28/50], Step [800/7038], D Loss: 0.29850339889526367, G Loss: 1.5962697267532349\n",
      "Epoch [28/50], Step [900/7038], D Loss: 0.41526728868484497, G Loss: 1.3273024559020996\n",
      "Epoch [28/50], Step [1000/7038], D Loss: 0.4960867762565613, G Loss: 0.9979179501533508\n",
      "Epoch [28/50], Step [1100/7038], D Loss: 0.4520335793495178, G Loss: 1.551653504371643\n",
      "Epoch [28/50], Step [1200/7038], D Loss: 0.3941623568534851, G Loss: 1.5365616083145142\n",
      "Epoch [28/50], Step [1300/7038], D Loss: 0.6209889650344849, G Loss: 1.3599894046783447\n",
      "Epoch [28/50], Step [1400/7038], D Loss: 0.4470553398132324, G Loss: 1.3193494081497192\n",
      "Epoch [28/50], Step [1500/7038], D Loss: 0.6093411445617676, G Loss: 1.3054293394088745\n",
      "Epoch [28/50], Step [1600/7038], D Loss: 0.3283315598964691, G Loss: 1.709458589553833\n",
      "Epoch [28/50], Step [1700/7038], D Loss: 0.3660573959350586, G Loss: 1.5323432683944702\n",
      "Epoch [28/50], Step [1800/7038], D Loss: 0.2907613515853882, G Loss: 1.8498080968856812\n",
      "Epoch [28/50], Step [1900/7038], D Loss: 0.6291756629943848, G Loss: 1.2212482690811157\n",
      "Epoch [28/50], Step [2000/7038], D Loss: 0.5140828490257263, G Loss: 1.7172751426696777\n",
      "Epoch [28/50], Step [2100/7038], D Loss: 0.5924230813980103, G Loss: 1.1015541553497314\n",
      "Epoch [28/50], Step [2200/7038], D Loss: 0.5054896473884583, G Loss: 1.288655400276184\n",
      "Epoch [28/50], Step [2300/7038], D Loss: 0.4728047549724579, G Loss: 1.468358039855957\n",
      "Epoch [28/50], Step [2400/7038], D Loss: 0.3589082956314087, G Loss: 1.3821971416473389\n",
      "Epoch [28/50], Step [2500/7038], D Loss: 0.49274924397468567, G Loss: 1.4347559213638306\n",
      "Epoch [28/50], Step [2600/7038], D Loss: 0.5215852856636047, G Loss: 1.1609671115875244\n",
      "Epoch [28/50], Step [2700/7038], D Loss: 0.6751502156257629, G Loss: 1.2947603464126587\n",
      "Epoch [28/50], Step [2800/7038], D Loss: 0.3392997086048126, G Loss: 1.6916353702545166\n",
      "Epoch [28/50], Step [2900/7038], D Loss: 0.36119183897972107, G Loss: 1.3258159160614014\n",
      "Epoch [28/50], Step [3000/7038], D Loss: 0.5090506076812744, G Loss: 1.0614230632781982\n",
      "Epoch [28/50], Step [3100/7038], D Loss: 0.4728161096572876, G Loss: 1.3840725421905518\n",
      "Epoch [28/50], Step [3200/7038], D Loss: 0.4131426215171814, G Loss: 1.8421968221664429\n",
      "Epoch [28/50], Step [3300/7038], D Loss: 0.658397376537323, G Loss: 0.8751252889633179\n",
      "Epoch [28/50], Step [3400/7038], D Loss: 0.7779609560966492, G Loss: 1.0728895664215088\n",
      "Epoch [28/50], Step [3500/7038], D Loss: 0.2956000566482544, G Loss: 1.7151737213134766\n",
      "Epoch [28/50], Step [3600/7038], D Loss: 0.5159263014793396, G Loss: 1.0631245374679565\n",
      "Epoch [28/50], Step [3700/7038], D Loss: 0.5106115341186523, G Loss: 1.2612085342407227\n",
      "Epoch [28/50], Step [3800/7038], D Loss: 0.3770301938056946, G Loss: 1.3424057960510254\n",
      "Epoch [28/50], Step [3900/7038], D Loss: 0.3730139136314392, G Loss: 1.4385364055633545\n",
      "Epoch [28/50], Step [4000/7038], D Loss: 0.41788432002067566, G Loss: 1.6040598154067993\n",
      "Epoch [28/50], Step [4100/7038], D Loss: 0.462510883808136, G Loss: 1.485934853553772\n",
      "Epoch [28/50], Step [4200/7038], D Loss: 0.4237847626209259, G Loss: 1.5800669193267822\n",
      "Epoch [28/50], Step [4300/7038], D Loss: 0.5431597232818604, G Loss: 0.9764367341995239\n",
      "Epoch [28/50], Step [4400/7038], D Loss: 0.478835791349411, G Loss: 1.286636233329773\n",
      "Epoch [28/50], Step [4500/7038], D Loss: 0.38270053267478943, G Loss: 1.7196201086044312\n",
      "Epoch [28/50], Step [4600/7038], D Loss: 0.6763179898262024, G Loss: 1.0595729351043701\n",
      "Epoch [28/50], Step [4700/7038], D Loss: 0.44808921217918396, G Loss: 1.4872030019760132\n",
      "Epoch [28/50], Step [4800/7038], D Loss: 0.5444248914718628, G Loss: 1.2920325994491577\n",
      "Epoch [28/50], Step [4900/7038], D Loss: 0.379743754863739, G Loss: 1.8917474746704102\n",
      "Epoch [28/50], Step [5000/7038], D Loss: 0.27814722061157227, G Loss: 1.5373094081878662\n",
      "Epoch [28/50], Step [5100/7038], D Loss: 0.6452812552452087, G Loss: 1.3632128238677979\n",
      "Epoch [28/50], Step [5200/7038], D Loss: 0.3007161617279053, G Loss: 1.8155567646026611\n",
      "Epoch [28/50], Step [5300/7038], D Loss: 0.7286954522132874, G Loss: 1.0749189853668213\n",
      "Epoch [28/50], Step [5400/7038], D Loss: 0.41060805320739746, G Loss: 1.3277257680892944\n",
      "Epoch [28/50], Step [5500/7038], D Loss: 0.5308414697647095, G Loss: 1.4523366689682007\n",
      "Epoch [28/50], Step [5600/7038], D Loss: 0.4063023030757904, G Loss: 1.3336247205734253\n",
      "Epoch [28/50], Step [5700/7038], D Loss: 0.4299786686897278, G Loss: 1.3936138153076172\n",
      "Epoch [28/50], Step [5800/7038], D Loss: 0.374847948551178, G Loss: 1.5908046960830688\n",
      "Epoch [28/50], Step [5900/7038], D Loss: 0.6385019421577454, G Loss: 1.580622673034668\n",
      "Epoch [28/50], Step [6000/7038], D Loss: 0.3650156557559967, G Loss: 1.950015664100647\n",
      "Epoch [28/50], Step [6100/7038], D Loss: 0.4810357689857483, G Loss: 1.5389865636825562\n",
      "Epoch [28/50], Step [6200/7038], D Loss: 0.5863533020019531, G Loss: 1.0392789840698242\n",
      "Epoch [28/50], Step [6300/7038], D Loss: 0.281213641166687, G Loss: 1.6496719121932983\n",
      "Epoch [28/50], Step [6400/7038], D Loss: 0.5647122263908386, G Loss: 1.3944165706634521\n",
      "Epoch [28/50], Step [6500/7038], D Loss: 0.43724220991134644, G Loss: 1.1663869619369507\n",
      "Epoch [28/50], Step [6600/7038], D Loss: 0.41973257064819336, G Loss: 1.2229220867156982\n",
      "Epoch [28/50], Step [6700/7038], D Loss: 0.5392522811889648, G Loss: 1.6979663372039795\n",
      "Epoch [28/50], Step [6800/7038], D Loss: 0.4016457200050354, G Loss: 1.6314488649368286\n",
      "Epoch [28/50], Step [6900/7038], D Loss: 0.3347698152065277, G Loss: 1.4635425806045532\n",
      "Epoch [28/50], Step [7000/7038], D Loss: 0.5414599180221558, G Loss: 1.3959466218948364\n",
      "Epoch [29/50], Step [0/7038], D Loss: 0.32822126150131226, G Loss: 1.4873337745666504\n",
      "Epoch [29/50], Step [100/7038], D Loss: 0.6850239038467407, G Loss: 1.3125427961349487\n",
      "Epoch [29/50], Step [200/7038], D Loss: 0.7576954364776611, G Loss: 1.3139960765838623\n",
      "Epoch [29/50], Step [300/7038], D Loss: 0.3238946199417114, G Loss: 1.5704739093780518\n",
      "Epoch [29/50], Step [400/7038], D Loss: 0.4494304656982422, G Loss: 1.175704836845398\n",
      "Epoch [29/50], Step [500/7038], D Loss: 0.4629809260368347, G Loss: 1.2732619047164917\n",
      "Epoch [29/50], Step [600/7038], D Loss: 0.36867374181747437, G Loss: 1.354877233505249\n",
      "Epoch [29/50], Step [700/7038], D Loss: 0.5088979005813599, G Loss: 1.1009299755096436\n",
      "Epoch [29/50], Step [800/7038], D Loss: 0.5918045043945312, G Loss: 1.1804351806640625\n",
      "Epoch [29/50], Step [900/7038], D Loss: 0.31698188185691833, G Loss: 2.1565799713134766\n",
      "Epoch [29/50], Step [1000/7038], D Loss: 0.5752789378166199, G Loss: 1.4387942552566528\n",
      "Epoch [29/50], Step [1100/7038], D Loss: 0.45720797777175903, G Loss: 1.3457605838775635\n",
      "Epoch [29/50], Step [1200/7038], D Loss: 0.8953195214271545, G Loss: 1.6918197870254517\n",
      "Epoch [29/50], Step [1300/7038], D Loss: 0.6715424060821533, G Loss: 1.5160614252090454\n",
      "Epoch [29/50], Step [1400/7038], D Loss: 0.4768402576446533, G Loss: 1.2558282613754272\n",
      "Epoch [29/50], Step [1500/7038], D Loss: 0.32530277967453003, G Loss: 1.5270565748214722\n",
      "Epoch [29/50], Step [1600/7038], D Loss: 0.4564071297645569, G Loss: 1.3496938943862915\n",
      "Epoch [29/50], Step [1700/7038], D Loss: 0.5672321915626526, G Loss: 2.147618055343628\n",
      "Epoch [29/50], Step [1800/7038], D Loss: 0.6422874331474304, G Loss: 1.4737669229507446\n",
      "Epoch [29/50], Step [1900/7038], D Loss: 0.5554639101028442, G Loss: 1.1563376188278198\n",
      "Epoch [29/50], Step [2000/7038], D Loss: 0.507257878780365, G Loss: 1.166277527809143\n",
      "Epoch [29/50], Step [2100/7038], D Loss: 0.19948506355285645, G Loss: 1.862226128578186\n",
      "Epoch [29/50], Step [2200/7038], D Loss: 0.39975690841674805, G Loss: 1.9463549852371216\n",
      "Epoch [29/50], Step [2300/7038], D Loss: 0.35348376631736755, G Loss: 1.6726365089416504\n",
      "Epoch [29/50], Step [2400/7038], D Loss: 0.47906386852264404, G Loss: 1.8396762609481812\n",
      "Epoch [29/50], Step [2500/7038], D Loss: 0.92819744348526, G Loss: 0.8194413781166077\n",
      "Epoch [29/50], Step [2600/7038], D Loss: 0.4957706332206726, G Loss: 1.18465256690979\n",
      "Epoch [29/50], Step [2700/7038], D Loss: 0.485526978969574, G Loss: 1.528388500213623\n",
      "Epoch [29/50], Step [2800/7038], D Loss: 0.41590142250061035, G Loss: 1.5554347038269043\n",
      "Epoch [29/50], Step [2900/7038], D Loss: 0.3110824227333069, G Loss: 2.0346434116363525\n",
      "Epoch [29/50], Step [3000/7038], D Loss: 0.6960656642913818, G Loss: 1.2094385623931885\n",
      "Epoch [29/50], Step [3100/7038], D Loss: 0.44102388620376587, G Loss: 1.8877991437911987\n",
      "Epoch [29/50], Step [3200/7038], D Loss: 0.3011091947555542, G Loss: 1.7616655826568604\n",
      "Epoch [29/50], Step [3300/7038], D Loss: 0.43883416056632996, G Loss: 1.309984803199768\n",
      "Epoch [29/50], Step [3400/7038], D Loss: 0.3035743832588196, G Loss: 1.5283504724502563\n",
      "Epoch [29/50], Step [3500/7038], D Loss: 0.2802408039569855, G Loss: 1.9754003286361694\n",
      "Epoch [29/50], Step [3600/7038], D Loss: 0.30591702461242676, G Loss: 1.5469098091125488\n",
      "Epoch [29/50], Step [3700/7038], D Loss: 0.4231441020965576, G Loss: 1.7422846555709839\n",
      "Epoch [29/50], Step [3800/7038], D Loss: 0.5808955430984497, G Loss: 1.1868970394134521\n",
      "Epoch [29/50], Step [3900/7038], D Loss: 0.5985308289527893, G Loss: 1.535688877105713\n",
      "Epoch [29/50], Step [4000/7038], D Loss: 0.5460646152496338, G Loss: 1.2336406707763672\n",
      "Epoch [29/50], Step [4100/7038], D Loss: 0.5351206064224243, G Loss: 2.604736566543579\n",
      "Epoch [29/50], Step [4200/7038], D Loss: 0.5016184449195862, G Loss: 1.1335620880126953\n",
      "Epoch [29/50], Step [4300/7038], D Loss: 0.37415429949760437, G Loss: 1.5823943614959717\n",
      "Epoch [29/50], Step [4400/7038], D Loss: 0.7571184039115906, G Loss: 1.1720064878463745\n",
      "Epoch [29/50], Step [4500/7038], D Loss: 0.26400184631347656, G Loss: 1.8273859024047852\n",
      "Epoch [29/50], Step [4600/7038], D Loss: 0.5332962274551392, G Loss: 1.375724196434021\n",
      "Epoch [29/50], Step [4700/7038], D Loss: 0.6370006203651428, G Loss: 1.9162721633911133\n",
      "Epoch [29/50], Step [4800/7038], D Loss: 0.6903963088989258, G Loss: 1.1879054307937622\n",
      "Epoch [29/50], Step [4900/7038], D Loss: 0.28720587491989136, G Loss: 1.7802811861038208\n",
      "Epoch [29/50], Step [5000/7038], D Loss: 0.44512832164764404, G Loss: 1.1389834880828857\n",
      "Epoch [29/50], Step [5100/7038], D Loss: 0.3950169086456299, G Loss: 1.2401518821716309\n",
      "Epoch [29/50], Step [5200/7038], D Loss: 0.2988308072090149, G Loss: 1.5249288082122803\n",
      "Epoch [29/50], Step [5300/7038], D Loss: 0.5358560085296631, G Loss: 1.400186538696289\n",
      "Epoch [29/50], Step [5400/7038], D Loss: 0.3057788908481598, G Loss: 1.6736905574798584\n",
      "Epoch [29/50], Step [5500/7038], D Loss: 0.7000440359115601, G Loss: 1.2873449325561523\n",
      "Epoch [29/50], Step [5600/7038], D Loss: 0.5412192344665527, G Loss: 1.1951559782028198\n",
      "Epoch [29/50], Step [5700/7038], D Loss: 0.6829108595848083, G Loss: 1.1309728622436523\n",
      "Epoch [29/50], Step [5800/7038], D Loss: 0.4454664885997772, G Loss: 1.4924646615982056\n",
      "Epoch [29/50], Step [5900/7038], D Loss: 0.4271426796913147, G Loss: 1.7367632389068604\n",
      "Epoch [29/50], Step [6000/7038], D Loss: 0.2750457227230072, G Loss: 1.8946762084960938\n",
      "Epoch [29/50], Step [6100/7038], D Loss: 0.5223785042762756, G Loss: 1.5131741762161255\n",
      "Epoch [29/50], Step [6200/7038], D Loss: 0.5039288997650146, G Loss: 1.0411348342895508\n",
      "Epoch [29/50], Step [6300/7038], D Loss: 0.46105170249938965, G Loss: 1.4385943412780762\n",
      "Epoch [29/50], Step [6400/7038], D Loss: 0.6568053364753723, G Loss: 1.2024405002593994\n",
      "Epoch [29/50], Step [6500/7038], D Loss: 0.7081199288368225, G Loss: 1.3181116580963135\n",
      "Epoch [29/50], Step [6600/7038], D Loss: 0.4555337131023407, G Loss: 1.3954664468765259\n",
      "Epoch [29/50], Step [6700/7038], D Loss: 0.32225972414016724, G Loss: 1.4613444805145264\n",
      "Epoch [29/50], Step [6800/7038], D Loss: 0.5710064172744751, G Loss: 1.1316567659378052\n",
      "Epoch [29/50], Step [6900/7038], D Loss: 0.3910086750984192, G Loss: 1.5933021306991577\n",
      "Epoch [29/50], Step [7000/7038], D Loss: 0.3680878281593323, G Loss: 1.3305182456970215\n",
      "Epoch [30/50], Step [0/7038], D Loss: 0.3325169086456299, G Loss: 1.6605243682861328\n",
      "Epoch [30/50], Step [100/7038], D Loss: 0.33075493574142456, G Loss: 1.6483343839645386\n",
      "Epoch [30/50], Step [200/7038], D Loss: 0.3865123987197876, G Loss: 1.5301135778427124\n",
      "Epoch [30/50], Step [300/7038], D Loss: 0.40608322620391846, G Loss: 1.609897494316101\n",
      "Epoch [30/50], Step [400/7038], D Loss: 0.4328867495059967, G Loss: 1.3427557945251465\n",
      "Epoch [30/50], Step [500/7038], D Loss: 0.43400874733924866, G Loss: 1.3531588315963745\n",
      "Epoch [30/50], Step [600/7038], D Loss: 0.5221841931343079, G Loss: 1.2712138891220093\n",
      "Epoch [30/50], Step [700/7038], D Loss: 0.7854383587837219, G Loss: 1.1052995920181274\n",
      "Epoch [30/50], Step [800/7038], D Loss: 0.4355616569519043, G Loss: 1.1480002403259277\n",
      "Epoch [30/50], Step [900/7038], D Loss: 0.4244004487991333, G Loss: 1.111443042755127\n",
      "Epoch [30/50], Step [1000/7038], D Loss: 0.36865508556365967, G Loss: 1.447890281677246\n",
      "Epoch [30/50], Step [1100/7038], D Loss: 0.5510643124580383, G Loss: 1.5208476781845093\n",
      "Epoch [30/50], Step [1200/7038], D Loss: 0.2848229706287384, G Loss: 1.6071964502334595\n",
      "Epoch [30/50], Step [1300/7038], D Loss: 0.4434329867362976, G Loss: 1.1276381015777588\n",
      "Epoch [30/50], Step [1400/7038], D Loss: 0.34090685844421387, G Loss: 1.849787950515747\n",
      "Epoch [30/50], Step [1500/7038], D Loss: 0.609624981880188, G Loss: 1.1629754304885864\n",
      "Epoch [30/50], Step [1600/7038], D Loss: 0.3968655467033386, G Loss: 1.758882761001587\n",
      "Epoch [30/50], Step [1700/7038], D Loss: 0.4204319715499878, G Loss: 1.724360704421997\n",
      "Epoch [30/50], Step [1800/7038], D Loss: 0.48205238580703735, G Loss: 1.1800740957260132\n",
      "Epoch [30/50], Step [1900/7038], D Loss: 0.5307846069335938, G Loss: 1.1063308715820312\n",
      "Epoch [30/50], Step [2000/7038], D Loss: 0.3578484058380127, G Loss: 1.763766884803772\n",
      "Epoch [30/50], Step [2100/7038], D Loss: 0.2401561588048935, G Loss: 1.8273662328720093\n",
      "Epoch [30/50], Step [2200/7038], D Loss: 0.6021947264671326, G Loss: 1.2556695938110352\n",
      "Epoch [30/50], Step [2300/7038], D Loss: 0.35338643193244934, G Loss: 1.4904969930648804\n",
      "Epoch [30/50], Step [2400/7038], D Loss: 0.5962069630622864, G Loss: 0.9827547669410706\n",
      "Epoch [30/50], Step [2500/7038], D Loss: 0.4525224566459656, G Loss: 1.4765732288360596\n",
      "Epoch [30/50], Step [2600/7038], D Loss: 0.6851415634155273, G Loss: 1.1682443618774414\n",
      "Epoch [30/50], Step [2700/7038], D Loss: 0.4192519783973694, G Loss: 1.4260034561157227\n",
      "Epoch [30/50], Step [2800/7038], D Loss: 0.3879640996456146, G Loss: 1.1861765384674072\n",
      "Epoch [30/50], Step [2900/7038], D Loss: 0.5285272002220154, G Loss: 1.3058476448059082\n",
      "Epoch [30/50], Step [3000/7038], D Loss: 0.44669926166534424, G Loss: 1.3706010580062866\n",
      "Epoch [30/50], Step [3100/7038], D Loss: 0.3998699486255646, G Loss: 2.21610164642334\n",
      "Epoch [30/50], Step [3200/7038], D Loss: 0.33655232191085815, G Loss: 1.67437744140625\n",
      "Epoch [30/50], Step [3300/7038], D Loss: 0.7563867568969727, G Loss: 1.260345220565796\n",
      "Epoch [30/50], Step [3400/7038], D Loss: 0.4668162763118744, G Loss: 1.2045600414276123\n",
      "Epoch [30/50], Step [3500/7038], D Loss: 0.7288542985916138, G Loss: 1.086927890777588\n",
      "Epoch [30/50], Step [3600/7038], D Loss: 0.5699180364608765, G Loss: 1.130027174949646\n",
      "Epoch [30/50], Step [3700/7038], D Loss: 0.4124441146850586, G Loss: 1.4436317682266235\n",
      "Epoch [30/50], Step [3800/7038], D Loss: 0.4148753881454468, G Loss: 1.2512694597244263\n",
      "Epoch [30/50], Step [3900/7038], D Loss: 0.3581361770629883, G Loss: 1.6844594478607178\n",
      "Epoch [30/50], Step [4000/7038], D Loss: 0.4048442840576172, G Loss: 1.4604334831237793\n",
      "Epoch [30/50], Step [4100/7038], D Loss: 0.47495946288108826, G Loss: 1.8450732231140137\n",
      "Epoch [30/50], Step [4200/7038], D Loss: 0.5912459492683411, G Loss: 1.5772284269332886\n",
      "Epoch [30/50], Step [4300/7038], D Loss: 0.4358210563659668, G Loss: 1.4161750078201294\n",
      "Epoch [30/50], Step [4400/7038], D Loss: 0.7623516917228699, G Loss: 1.3258000612258911\n",
      "Epoch [30/50], Step [4500/7038], D Loss: 0.7212371230125427, G Loss: 1.3316435813903809\n",
      "Epoch [30/50], Step [4600/7038], D Loss: 0.38712555170059204, G Loss: 1.8631844520568848\n",
      "Epoch [30/50], Step [4700/7038], D Loss: 0.5207678079605103, G Loss: 1.1704868078231812\n",
      "Epoch [30/50], Step [4800/7038], D Loss: 0.4002390503883362, G Loss: 1.8157472610473633\n",
      "Epoch [30/50], Step [4900/7038], D Loss: 0.5056164860725403, G Loss: 1.8464645147323608\n",
      "Epoch [30/50], Step [5000/7038], D Loss: 0.41965699195861816, G Loss: 1.3338630199432373\n",
      "Epoch [30/50], Step [5100/7038], D Loss: 0.5624011754989624, G Loss: 1.1665654182434082\n",
      "Epoch [30/50], Step [5200/7038], D Loss: 0.5526109337806702, G Loss: 1.293097972869873\n",
      "Epoch [30/50], Step [5300/7038], D Loss: 0.4975750148296356, G Loss: 1.2450919151306152\n",
      "Epoch [30/50], Step [5400/7038], D Loss: 0.4365840256214142, G Loss: 1.3146125078201294\n",
      "Epoch [30/50], Step [5500/7038], D Loss: 0.3814643621444702, G Loss: 1.3519668579101562\n",
      "Epoch [30/50], Step [5600/7038], D Loss: 0.5957379341125488, G Loss: 1.514939308166504\n",
      "Epoch [30/50], Step [5700/7038], D Loss: 0.47568419575691223, G Loss: 1.2432278394699097\n",
      "Epoch [30/50], Step [5800/7038], D Loss: 0.3585875928401947, G Loss: 1.6181132793426514\n",
      "Epoch [30/50], Step [5900/7038], D Loss: 0.5334753394126892, G Loss: 1.3708984851837158\n",
      "Epoch [30/50], Step [6000/7038], D Loss: 0.5460549592971802, G Loss: 1.8751890659332275\n",
      "Epoch [30/50], Step [6100/7038], D Loss: 0.2574034333229065, G Loss: 2.3640284538269043\n",
      "Epoch [30/50], Step [6200/7038], D Loss: 0.36047449707984924, G Loss: 1.467225193977356\n",
      "Epoch [30/50], Step [6300/7038], D Loss: 0.5247236490249634, G Loss: 1.5077316761016846\n",
      "Epoch [30/50], Step [6400/7038], D Loss: 0.4394131898880005, G Loss: 1.4863780736923218\n",
      "Epoch [30/50], Step [6500/7038], D Loss: 0.4562250077724457, G Loss: 1.2677706480026245\n",
      "Epoch [30/50], Step [6600/7038], D Loss: 0.2548971474170685, G Loss: 1.9941860437393188\n",
      "Epoch [30/50], Step [6700/7038], D Loss: 0.33948904275894165, G Loss: 2.106410503387451\n",
      "Epoch [30/50], Step [6800/7038], D Loss: 0.3593093752861023, G Loss: 1.8630366325378418\n",
      "Epoch [30/50], Step [6900/7038], D Loss: 0.69816654920578, G Loss: 1.727954387664795\n",
      "Epoch [30/50], Step [7000/7038], D Loss: 0.3939706087112427, G Loss: 1.5171278715133667\n",
      "Epoch [31/50], Step [0/7038], D Loss: 0.7050541639328003, G Loss: 0.9278977513313293\n",
      "Epoch [31/50], Step [100/7038], D Loss: 0.429673433303833, G Loss: 1.2382218837738037\n",
      "Epoch [31/50], Step [200/7038], D Loss: 0.5194411277770996, G Loss: 1.2941999435424805\n",
      "Epoch [31/50], Step [300/7038], D Loss: 0.5605543851852417, G Loss: 1.1671332120895386\n",
      "Epoch [31/50], Step [400/7038], D Loss: 0.18585972487926483, G Loss: 2.120558261871338\n",
      "Epoch [31/50], Step [500/7038], D Loss: 0.37867891788482666, G Loss: 1.355372428894043\n",
      "Epoch [31/50], Step [600/7038], D Loss: 0.4802972078323364, G Loss: 1.1087678670883179\n",
      "Epoch [31/50], Step [700/7038], D Loss: 0.47035807371139526, G Loss: 1.3579050302505493\n",
      "Epoch [31/50], Step [800/7038], D Loss: 0.31056198477745056, G Loss: 1.5169832706451416\n",
      "Epoch [31/50], Step [900/7038], D Loss: 0.44143474102020264, G Loss: 1.4565714597702026\n",
      "Epoch [31/50], Step [1000/7038], D Loss: 0.6632204651832581, G Loss: 1.147837519645691\n",
      "Epoch [31/50], Step [1100/7038], D Loss: 0.5169603824615479, G Loss: 1.1185979843139648\n",
      "Epoch [31/50], Step [1200/7038], D Loss: 0.4146535098552704, G Loss: 1.3110859394073486\n",
      "Epoch [31/50], Step [1300/7038], D Loss: 0.6004515886306763, G Loss: 0.9651343822479248\n",
      "Epoch [31/50], Step [1400/7038], D Loss: 0.39096885919570923, G Loss: 1.2276283502578735\n",
      "Epoch [31/50], Step [1500/7038], D Loss: 0.37670469284057617, G Loss: 1.758261799812317\n",
      "Epoch [31/50], Step [1600/7038], D Loss: 0.3554956018924713, G Loss: 1.61060631275177\n",
      "Epoch [31/50], Step [1700/7038], D Loss: 0.5672425627708435, G Loss: 1.4262986183166504\n",
      "Epoch [31/50], Step [1800/7038], D Loss: 0.301585853099823, G Loss: 1.5016144514083862\n",
      "Epoch [31/50], Step [1900/7038], D Loss: 0.5175222754478455, G Loss: 1.3026942014694214\n",
      "Epoch [31/50], Step [2000/7038], D Loss: 0.5330373048782349, G Loss: 1.1060919761657715\n",
      "Epoch [31/50], Step [2100/7038], D Loss: 0.5861639976501465, G Loss: 1.6043994426727295\n",
      "Epoch [31/50], Step [2200/7038], D Loss: 0.5574519038200378, G Loss: 1.6796499490737915\n",
      "Epoch [31/50], Step [2300/7038], D Loss: 0.8228105306625366, G Loss: 0.9853695631027222\n",
      "Epoch [31/50], Step [2400/7038], D Loss: 0.5643366575241089, G Loss: 1.1779417991638184\n",
      "Epoch [31/50], Step [2500/7038], D Loss: 0.41665416955947876, G Loss: 1.2660417556762695\n",
      "Epoch [31/50], Step [2600/7038], D Loss: 0.6136100888252258, G Loss: 1.3463830947875977\n",
      "Epoch [31/50], Step [2700/7038], D Loss: 0.45171406865119934, G Loss: 1.404963731765747\n",
      "Epoch [31/50], Step [2800/7038], D Loss: 0.34860658645629883, G Loss: 1.460195779800415\n",
      "Epoch [31/50], Step [2900/7038], D Loss: 0.406249463558197, G Loss: 1.9037957191467285\n",
      "Epoch [31/50], Step [3000/7038], D Loss: 0.43783408403396606, G Loss: 1.8270220756530762\n",
      "Epoch [31/50], Step [3100/7038], D Loss: 0.5648409724235535, G Loss: 1.4355400800704956\n",
      "Epoch [31/50], Step [3200/7038], D Loss: 0.3896365463733673, G Loss: 1.5418707132339478\n",
      "Epoch [31/50], Step [3300/7038], D Loss: 0.369265615940094, G Loss: 1.4460848569869995\n",
      "Epoch [31/50], Step [3400/7038], D Loss: 0.4835914969444275, G Loss: 1.444411277770996\n",
      "Epoch [31/50], Step [3500/7038], D Loss: 0.6861183047294617, G Loss: 1.4311543703079224\n",
      "Epoch [31/50], Step [3600/7038], D Loss: 0.4926936626434326, G Loss: 1.3700623512268066\n",
      "Epoch [31/50], Step [3700/7038], D Loss: 0.5577080845832825, G Loss: 1.1239112615585327\n",
      "Epoch [31/50], Step [3800/7038], D Loss: 0.4110420346260071, G Loss: 1.3971915245056152\n",
      "Epoch [31/50], Step [3900/7038], D Loss: 0.5757632255554199, G Loss: 1.081848382949829\n",
      "Epoch [31/50], Step [4000/7038], D Loss: 0.5060505867004395, G Loss: 1.3853206634521484\n",
      "Epoch [31/50], Step [4100/7038], D Loss: 0.37601736187934875, G Loss: 1.7669053077697754\n",
      "Epoch [31/50], Step [4200/7038], D Loss: 0.5049785375595093, G Loss: 1.4586055278778076\n",
      "Epoch [31/50], Step [4300/7038], D Loss: 0.6965785622596741, G Loss: 1.7370809316635132\n",
      "Epoch [31/50], Step [4400/7038], D Loss: 0.34280118346214294, G Loss: 1.3612349033355713\n",
      "Epoch [31/50], Step [4500/7038], D Loss: 0.6272474527359009, G Loss: 1.6272956132888794\n",
      "Epoch [31/50], Step [4600/7038], D Loss: 0.42520561814308167, G Loss: 1.2562967538833618\n",
      "Epoch [31/50], Step [4700/7038], D Loss: 0.30863797664642334, G Loss: 1.8256728649139404\n",
      "Epoch [31/50], Step [4800/7038], D Loss: 0.5860167741775513, G Loss: 1.1809450387954712\n",
      "Epoch [31/50], Step [4900/7038], D Loss: 0.5351940393447876, G Loss: 1.5751917362213135\n",
      "Epoch [31/50], Step [5000/7038], D Loss: 0.5795454978942871, G Loss: 1.1215922832489014\n",
      "Epoch [31/50], Step [5100/7038], D Loss: 0.4231973886489868, G Loss: 1.6777689456939697\n",
      "Epoch [31/50], Step [5200/7038], D Loss: 0.5853628516197205, G Loss: 1.307672142982483\n",
      "Epoch [31/50], Step [5300/7038], D Loss: 0.39605027437210083, G Loss: 1.2942736148834229\n",
      "Epoch [31/50], Step [5400/7038], D Loss: 0.5118459463119507, G Loss: 1.0771267414093018\n",
      "Epoch [31/50], Step [5500/7038], D Loss: 0.3794015049934387, G Loss: 1.3327841758728027\n",
      "Epoch [31/50], Step [5600/7038], D Loss: 0.49118104577064514, G Loss: 1.3522170782089233\n",
      "Epoch [31/50], Step [5700/7038], D Loss: 0.30655449628829956, G Loss: 1.65640127658844\n",
      "Epoch [31/50], Step [5800/7038], D Loss: 0.5948569774627686, G Loss: 1.4061657190322876\n",
      "Epoch [31/50], Step [5900/7038], D Loss: 0.6564018726348877, G Loss: 1.4464722871780396\n",
      "Epoch [31/50], Step [6000/7038], D Loss: 0.5743914842605591, G Loss: 1.5330548286437988\n",
      "Epoch [31/50], Step [6100/7038], D Loss: 0.4522603750228882, G Loss: 2.0723166465759277\n",
      "Epoch [31/50], Step [6200/7038], D Loss: 0.5696026682853699, G Loss: 1.2642470598220825\n",
      "Epoch [31/50], Step [6300/7038], D Loss: 0.42478886246681213, G Loss: 1.641170620918274\n",
      "Epoch [31/50], Step [6400/7038], D Loss: 0.7810495495796204, G Loss: 1.6734875440597534\n",
      "Epoch [31/50], Step [6500/7038], D Loss: 0.5222060680389404, G Loss: 1.2439006567001343\n",
      "Epoch [31/50], Step [6600/7038], D Loss: 0.3482862710952759, G Loss: 1.8525468111038208\n",
      "Epoch [31/50], Step [6700/7038], D Loss: 0.5358250141143799, G Loss: 1.2796339988708496\n",
      "Epoch [31/50], Step [6800/7038], D Loss: 0.6341053247451782, G Loss: 1.0147225856781006\n",
      "Epoch [31/50], Step [6900/7038], D Loss: 0.29314568638801575, G Loss: 2.022655487060547\n",
      "Epoch [31/50], Step [7000/7038], D Loss: 0.5072060227394104, G Loss: 1.24546217918396\n",
      "Epoch [32/50], Step [0/7038], D Loss: 0.3518561124801636, G Loss: 1.5419764518737793\n",
      "Epoch [32/50], Step [100/7038], D Loss: 0.43311214447021484, G Loss: 1.4180477857589722\n",
      "Epoch [32/50], Step [200/7038], D Loss: 0.6954197883605957, G Loss: 1.8172569274902344\n",
      "Epoch [32/50], Step [300/7038], D Loss: 0.7274112105369568, G Loss: 0.9075955748558044\n",
      "Epoch [32/50], Step [400/7038], D Loss: 0.293661892414093, G Loss: 1.5275942087173462\n",
      "Epoch [32/50], Step [500/7038], D Loss: 0.5161448121070862, G Loss: 1.4638298749923706\n",
      "Epoch [32/50], Step [600/7038], D Loss: 0.6866676807403564, G Loss: 1.250989317893982\n",
      "Epoch [32/50], Step [700/7038], D Loss: 0.5798314809799194, G Loss: 1.584762454032898\n",
      "Epoch [32/50], Step [800/7038], D Loss: 0.30360275506973267, G Loss: 1.8133996725082397\n",
      "Epoch [32/50], Step [900/7038], D Loss: 0.37742894887924194, G Loss: 1.913545846939087\n",
      "Epoch [32/50], Step [1000/7038], D Loss: 0.35995984077453613, G Loss: 2.2383382320404053\n",
      "Epoch [32/50], Step [1100/7038], D Loss: 0.5434310436248779, G Loss: 1.6715099811553955\n",
      "Epoch [32/50], Step [1200/7038], D Loss: 0.6333940625190735, G Loss: 0.9819532632827759\n",
      "Epoch [32/50], Step [1300/7038], D Loss: 0.4369892179965973, G Loss: 1.505462408065796\n",
      "Epoch [32/50], Step [1400/7038], D Loss: 0.42608463764190674, G Loss: 1.3303245306015015\n",
      "Epoch [32/50], Step [1500/7038], D Loss: 0.27421292662620544, G Loss: 1.714516520500183\n",
      "Epoch [32/50], Step [1600/7038], D Loss: 0.542186439037323, G Loss: 1.2008603811264038\n",
      "Epoch [32/50], Step [1700/7038], D Loss: 0.5134100317955017, G Loss: 1.3913627862930298\n",
      "Epoch [32/50], Step [1800/7038], D Loss: 0.4693121016025543, G Loss: 1.2106430530548096\n",
      "Epoch [32/50], Step [1900/7038], D Loss: 0.4932485818862915, G Loss: 1.2044010162353516\n",
      "Epoch [32/50], Step [2000/7038], D Loss: 0.2821551561355591, G Loss: 2.0557587146759033\n",
      "Epoch [32/50], Step [2100/7038], D Loss: 0.5458602905273438, G Loss: 2.2982966899871826\n",
      "Epoch [32/50], Step [2200/7038], D Loss: 0.5612155199050903, G Loss: 1.2795830965042114\n",
      "Epoch [32/50], Step [2300/7038], D Loss: 0.5260965824127197, G Loss: 1.079256296157837\n",
      "Epoch [32/50], Step [2400/7038], D Loss: 0.4580388367176056, G Loss: 1.4669822454452515\n",
      "Epoch [32/50], Step [2500/7038], D Loss: 0.5654297471046448, G Loss: 1.3556714057922363\n",
      "Epoch [32/50], Step [2600/7038], D Loss: 0.28735804557800293, G Loss: 1.7819982767105103\n",
      "Epoch [32/50], Step [2700/7038], D Loss: 0.4564662575721741, G Loss: 1.5445510149002075\n",
      "Epoch [32/50], Step [2800/7038], D Loss: 0.1040930300951004, G Loss: 2.467005729675293\n",
      "Epoch [32/50], Step [2900/7038], D Loss: 0.669538140296936, G Loss: 1.0942262411117554\n",
      "Epoch [32/50], Step [3000/7038], D Loss: 0.31166577339172363, G Loss: 1.575034737586975\n",
      "Epoch [32/50], Step [3100/7038], D Loss: 0.7680920958518982, G Loss: 1.5637321472167969\n",
      "Epoch [32/50], Step [3200/7038], D Loss: 0.5030258297920227, G Loss: 1.3447355031967163\n",
      "Epoch [32/50], Step [3300/7038], D Loss: 0.5786857604980469, G Loss: 1.2824840545654297\n",
      "Epoch [32/50], Step [3400/7038], D Loss: 0.519069492816925, G Loss: 1.0679728984832764\n",
      "Epoch [32/50], Step [3500/7038], D Loss: 0.4003444314002991, G Loss: 1.7207989692687988\n",
      "Epoch [32/50], Step [3600/7038], D Loss: 0.46024560928344727, G Loss: 1.2002222537994385\n",
      "Epoch [32/50], Step [3700/7038], D Loss: 0.21520018577575684, G Loss: 2.127335548400879\n",
      "Epoch [32/50], Step [3800/7038], D Loss: 0.4854033589363098, G Loss: 1.2969515323638916\n",
      "Epoch [32/50], Step [3900/7038], D Loss: 0.6336883902549744, G Loss: 1.2361664772033691\n",
      "Epoch [32/50], Step [4000/7038], D Loss: 0.5175905227661133, G Loss: 1.2396306991577148\n",
      "Epoch [32/50], Step [4100/7038], D Loss: 0.3566012978553772, G Loss: 1.5196486711502075\n",
      "Epoch [32/50], Step [4200/7038], D Loss: 0.5379256010055542, G Loss: 1.1882250308990479\n",
      "Epoch [32/50], Step [4300/7038], D Loss: 0.2722153067588806, G Loss: 1.9010233879089355\n",
      "Epoch [32/50], Step [4400/7038], D Loss: 0.39385002851486206, G Loss: 1.383670687675476\n",
      "Epoch [32/50], Step [4500/7038], D Loss: 0.5313141942024231, G Loss: 1.293624758720398\n",
      "Epoch [32/50], Step [4600/7038], D Loss: 0.6266813278198242, G Loss: 1.7960655689239502\n",
      "Epoch [32/50], Step [4700/7038], D Loss: 1.0491528511047363, G Loss: 1.4107012748718262\n",
      "Epoch [32/50], Step [4800/7038], D Loss: 0.4112215042114258, G Loss: 1.8032079935073853\n",
      "Epoch [32/50], Step [4900/7038], D Loss: 0.36728978157043457, G Loss: 1.5564683675765991\n",
      "Epoch [32/50], Step [5000/7038], D Loss: 0.5817055702209473, G Loss: 1.3678234815597534\n",
      "Epoch [32/50], Step [5100/7038], D Loss: 0.5021637678146362, G Loss: 1.7431182861328125\n",
      "Epoch [32/50], Step [5200/7038], D Loss: 0.6091063618659973, G Loss: 2.020185947418213\n",
      "Epoch [32/50], Step [5300/7038], D Loss: 0.38678818941116333, G Loss: 1.7665668725967407\n",
      "Epoch [32/50], Step [5400/7038], D Loss: 0.5690011382102966, G Loss: 1.5538934469223022\n",
      "Epoch [32/50], Step [5500/7038], D Loss: 0.41233062744140625, G Loss: 1.943275809288025\n",
      "Epoch [32/50], Step [5600/7038], D Loss: 0.5454180836677551, G Loss: 1.4568430185317993\n",
      "Epoch [32/50], Step [5700/7038], D Loss: 0.26833784580230713, G Loss: 1.6134977340698242\n",
      "Epoch [32/50], Step [5800/7038], D Loss: 0.5607157945632935, G Loss: 1.2382231950759888\n",
      "Epoch [32/50], Step [5900/7038], D Loss: 0.4280674457550049, G Loss: 1.355650782585144\n",
      "Epoch [32/50], Step [6000/7038], D Loss: 0.732846736907959, G Loss: 1.3950858116149902\n",
      "Epoch [32/50], Step [6100/7038], D Loss: 0.5279074907302856, G Loss: 1.4790515899658203\n",
      "Epoch [32/50], Step [6200/7038], D Loss: 0.47093814611434937, G Loss: 1.7405805587768555\n",
      "Epoch [32/50], Step [6300/7038], D Loss: 0.4533084034919739, G Loss: 1.2718837261199951\n",
      "Epoch [32/50], Step [6400/7038], D Loss: 0.421190470457077, G Loss: 1.476601004600525\n",
      "Epoch [32/50], Step [6500/7038], D Loss: 0.8688058853149414, G Loss: 1.6784783601760864\n",
      "Epoch [32/50], Step [6600/7038], D Loss: 0.2852258086204529, G Loss: 1.767382264137268\n",
      "Epoch [32/50], Step [6700/7038], D Loss: 0.6102911233901978, G Loss: 1.2513662576675415\n",
      "Epoch [32/50], Step [6800/7038], D Loss: 0.38251036405563354, G Loss: 1.5417885780334473\n",
      "Epoch [32/50], Step [6900/7038], D Loss: 0.46901798248291016, G Loss: 1.610788106918335\n",
      "Epoch [32/50], Step [7000/7038], D Loss: 0.5154725909233093, G Loss: 1.5231413841247559\n",
      "Epoch [33/50], Step [0/7038], D Loss: 0.2090006321668625, G Loss: 1.7276147603988647\n",
      "Epoch [33/50], Step [100/7038], D Loss: 0.32220983505249023, G Loss: 1.6266535520553589\n",
      "Epoch [33/50], Step [200/7038], D Loss: 0.4968201518058777, G Loss: 1.376809000968933\n",
      "Epoch [33/50], Step [300/7038], D Loss: 0.5472983121871948, G Loss: 1.3972256183624268\n",
      "Epoch [33/50], Step [400/7038], D Loss: 0.3784918785095215, G Loss: 1.5054397583007812\n",
      "Epoch [33/50], Step [500/7038], D Loss: 0.533173680305481, G Loss: 1.1332790851593018\n",
      "Epoch [33/50], Step [600/7038], D Loss: 0.7942178249359131, G Loss: 1.4731202125549316\n",
      "Epoch [33/50], Step [700/7038], D Loss: 0.40876317024230957, G Loss: 1.2169231176376343\n",
      "Epoch [33/50], Step [800/7038], D Loss: 0.3862974941730499, G Loss: 1.704140305519104\n",
      "Epoch [33/50], Step [900/7038], D Loss: 0.5493365526199341, G Loss: 1.8640382289886475\n",
      "Epoch [33/50], Step [1000/7038], D Loss: 0.546747088432312, G Loss: 1.0426788330078125\n",
      "Epoch [33/50], Step [1100/7038], D Loss: 0.6866620779037476, G Loss: 1.2799897193908691\n",
      "Epoch [33/50], Step [1200/7038], D Loss: 0.4422954320907593, G Loss: 1.5211875438690186\n",
      "Epoch [33/50], Step [1300/7038], D Loss: 0.27565351128578186, G Loss: 1.7132303714752197\n",
      "Epoch [33/50], Step [1400/7038], D Loss: 0.6586915850639343, G Loss: 1.2536498308181763\n",
      "Epoch [33/50], Step [1500/7038], D Loss: 0.4421728849411011, G Loss: 1.201140284538269\n",
      "Epoch [33/50], Step [1600/7038], D Loss: 0.48356854915618896, G Loss: 1.3071337938308716\n",
      "Epoch [33/50], Step [1700/7038], D Loss: 0.4453011155128479, G Loss: 1.5042704343795776\n",
      "Epoch [33/50], Step [1800/7038], D Loss: 0.6883102655410767, G Loss: 1.750592589378357\n",
      "Epoch [33/50], Step [1900/7038], D Loss: 0.5037035942077637, G Loss: 1.433480143547058\n",
      "Epoch [33/50], Step [2000/7038], D Loss: 0.39637452363967896, G Loss: 1.3427355289459229\n",
      "Epoch [33/50], Step [2100/7038], D Loss: 0.40739578008651733, G Loss: 1.5061213970184326\n",
      "Epoch [33/50], Step [2200/7038], D Loss: 0.4227650761604309, G Loss: 1.7523082494735718\n",
      "Epoch [33/50], Step [2300/7038], D Loss: 0.32259491086006165, G Loss: 1.681581974029541\n",
      "Epoch [33/50], Step [2400/7038], D Loss: 0.3469725251197815, G Loss: 1.4311268329620361\n",
      "Epoch [33/50], Step [2500/7038], D Loss: 0.6948696374893188, G Loss: 1.097719430923462\n",
      "Epoch [33/50], Step [2600/7038], D Loss: 0.4098375141620636, G Loss: 1.6428519487380981\n",
      "Epoch [33/50], Step [2700/7038], D Loss: 0.45278605818748474, G Loss: 1.782362937927246\n",
      "Epoch [33/50], Step [2800/7038], D Loss: 0.8647459745407104, G Loss: 1.9586470127105713\n",
      "Epoch [33/50], Step [2900/7038], D Loss: 0.5695412755012512, G Loss: 0.6917510628700256\n",
      "Epoch [33/50], Step [3000/7038], D Loss: 0.4221421778202057, G Loss: 1.7257716655731201\n",
      "Epoch [33/50], Step [3100/7038], D Loss: 0.27357667684555054, G Loss: 1.5625622272491455\n",
      "Epoch [33/50], Step [3200/7038], D Loss: 0.4048048257827759, G Loss: 1.2173333168029785\n",
      "Epoch [33/50], Step [3300/7038], D Loss: 0.28811153769493103, G Loss: 1.9587708711624146\n",
      "Epoch [33/50], Step [3400/7038], D Loss: 0.6162262558937073, G Loss: 1.2442643642425537\n",
      "Epoch [33/50], Step [3500/7038], D Loss: 0.49178236722946167, G Loss: 1.465512990951538\n",
      "Epoch [33/50], Step [3600/7038], D Loss: 0.5614081621170044, G Loss: 1.5114651918411255\n",
      "Epoch [33/50], Step [3700/7038], D Loss: 0.45507556200027466, G Loss: 1.2356593608856201\n",
      "Epoch [33/50], Step [3800/7038], D Loss: 0.92320716381073, G Loss: 1.1103020906448364\n",
      "Epoch [33/50], Step [3900/7038], D Loss: 0.4564695954322815, G Loss: 1.709248661994934\n",
      "Epoch [33/50], Step [4000/7038], D Loss: 0.33956900238990784, G Loss: 1.7082018852233887\n",
      "Epoch [33/50], Step [4100/7038], D Loss: 0.36042043566703796, G Loss: 1.411450982093811\n",
      "Epoch [33/50], Step [4200/7038], D Loss: 0.3732096552848816, G Loss: 1.5145552158355713\n",
      "Epoch [33/50], Step [4300/7038], D Loss: 0.535014271736145, G Loss: 1.3266808986663818\n",
      "Epoch [33/50], Step [4400/7038], D Loss: 0.47506874799728394, G Loss: 1.7372254133224487\n",
      "Epoch [33/50], Step [4500/7038], D Loss: 0.37414342164993286, G Loss: 1.384305715560913\n",
      "Epoch [33/50], Step [4600/7038], D Loss: 0.36116328835487366, G Loss: 1.6618406772613525\n",
      "Epoch [33/50], Step [4700/7038], D Loss: 0.70524001121521, G Loss: 1.2082616090774536\n",
      "Epoch [33/50], Step [4800/7038], D Loss: 0.22149424254894257, G Loss: 1.8841090202331543\n",
      "Epoch [33/50], Step [4900/7038], D Loss: 0.5253217220306396, G Loss: 1.2292091846466064\n",
      "Epoch [33/50], Step [5000/7038], D Loss: 0.5093870162963867, G Loss: 1.0772724151611328\n",
      "Epoch [33/50], Step [5100/7038], D Loss: 0.6534907817840576, G Loss: 1.532782793045044\n",
      "Epoch [33/50], Step [5200/7038], D Loss: 0.7733759880065918, G Loss: 1.7756229639053345\n",
      "Epoch [33/50], Step [5300/7038], D Loss: 0.4865031838417053, G Loss: 1.3748376369476318\n",
      "Epoch [33/50], Step [5400/7038], D Loss: 0.5373008251190186, G Loss: 1.0265816450119019\n",
      "Epoch [33/50], Step [5500/7038], D Loss: 0.5893228054046631, G Loss: 1.0987175703048706\n",
      "Epoch [33/50], Step [5600/7038], D Loss: 0.28520894050598145, G Loss: 1.5820889472961426\n",
      "Epoch [33/50], Step [5700/7038], D Loss: 0.4174099266529083, G Loss: 1.587187647819519\n",
      "Epoch [33/50], Step [5800/7038], D Loss: 0.5005897879600525, G Loss: 1.519514799118042\n",
      "Epoch [33/50], Step [5900/7038], D Loss: 0.4712081551551819, G Loss: 1.4082576036453247\n",
      "Epoch [33/50], Step [6000/7038], D Loss: 0.31254908442497253, G Loss: 1.3373851776123047\n",
      "Epoch [33/50], Step [6100/7038], D Loss: 0.6199216246604919, G Loss: 1.2879118919372559\n",
      "Epoch [33/50], Step [6200/7038], D Loss: 0.45699018239974976, G Loss: 1.2284942865371704\n",
      "Epoch [33/50], Step [6300/7038], D Loss: 0.7181075811386108, G Loss: 1.3687485456466675\n",
      "Epoch [33/50], Step [6400/7038], D Loss: 0.26867154240608215, G Loss: 1.7203031778335571\n",
      "Epoch [33/50], Step [6500/7038], D Loss: 0.28394293785095215, G Loss: 1.6861966848373413\n",
      "Epoch [33/50], Step [6600/7038], D Loss: 0.310062438249588, G Loss: 1.6205127239227295\n",
      "Epoch [33/50], Step [6700/7038], D Loss: 0.4085555672645569, G Loss: 1.5303386449813843\n",
      "Epoch [33/50], Step [6800/7038], D Loss: 0.35318267345428467, G Loss: 1.384566068649292\n",
      "Epoch [33/50], Step [6900/7038], D Loss: 0.5340527296066284, G Loss: 1.2599942684173584\n",
      "Epoch [33/50], Step [7000/7038], D Loss: 0.6891651153564453, G Loss: 0.7337305545806885\n",
      "Epoch [34/50], Step [0/7038], D Loss: 0.44933584332466125, G Loss: 1.630881905555725\n",
      "Epoch [34/50], Step [100/7038], D Loss: 0.45427751541137695, G Loss: 1.3878759145736694\n",
      "Epoch [34/50], Step [200/7038], D Loss: 0.5082119703292847, G Loss: 1.3958752155303955\n",
      "Epoch [34/50], Step [300/7038], D Loss: 0.4999508261680603, G Loss: 1.1534026861190796\n",
      "Epoch [34/50], Step [400/7038], D Loss: 0.3967914581298828, G Loss: 1.2962043285369873\n",
      "Epoch [34/50], Step [500/7038], D Loss: 0.5592575073242188, G Loss: 1.6585193872451782\n",
      "Epoch [34/50], Step [600/7038], D Loss: 0.3173350393772125, G Loss: 2.2650229930877686\n",
      "Epoch [34/50], Step [700/7038], D Loss: 0.18953430652618408, G Loss: 2.4235775470733643\n",
      "Epoch [34/50], Step [800/7038], D Loss: 0.3894782066345215, G Loss: 1.53437340259552\n",
      "Epoch [34/50], Step [900/7038], D Loss: 0.5615454912185669, G Loss: 1.2383087873458862\n",
      "Epoch [34/50], Step [1000/7038], D Loss: 0.4912130534648895, G Loss: 1.5547429323196411\n",
      "Epoch [34/50], Step [1100/7038], D Loss: 0.32525330781936646, G Loss: 1.5868090391159058\n",
      "Epoch [34/50], Step [1200/7038], D Loss: 0.4477264881134033, G Loss: 1.3559778928756714\n",
      "Epoch [34/50], Step [1300/7038], D Loss: 0.29050344228744507, G Loss: 1.468972086906433\n",
      "Epoch [34/50], Step [1400/7038], D Loss: 0.3957696557044983, G Loss: 1.3581002950668335\n",
      "Epoch [34/50], Step [1500/7038], D Loss: 0.766879677772522, G Loss: 2.045713186264038\n",
      "Epoch [34/50], Step [1600/7038], D Loss: 0.6914554834365845, G Loss: 1.6245523691177368\n",
      "Epoch [34/50], Step [1700/7038], D Loss: 0.4418086111545563, G Loss: 1.5882560014724731\n",
      "Epoch [34/50], Step [1800/7038], D Loss: 0.32884615659713745, G Loss: 2.146639823913574\n",
      "Epoch [34/50], Step [1900/7038], D Loss: 0.5184568762779236, G Loss: 1.0632184743881226\n",
      "Epoch [34/50], Step [2000/7038], D Loss: 0.3882240951061249, G Loss: 1.5909165143966675\n",
      "Epoch [34/50], Step [2100/7038], D Loss: 0.37113672494888306, G Loss: 1.2554140090942383\n",
      "Epoch [34/50], Step [2200/7038], D Loss: 0.5307915210723877, G Loss: 0.9094847440719604\n",
      "Epoch [34/50], Step [2300/7038], D Loss: 0.5615121722221375, G Loss: 1.5668267011642456\n",
      "Epoch [34/50], Step [2400/7038], D Loss: 0.4639626145362854, G Loss: 2.09470534324646\n",
      "Epoch [34/50], Step [2500/7038], D Loss: 0.30986636877059937, G Loss: 1.6191550493240356\n",
      "Epoch [34/50], Step [2600/7038], D Loss: 0.440288245677948, G Loss: 1.5097938776016235\n",
      "Epoch [34/50], Step [2700/7038], D Loss: 0.2861526310443878, G Loss: 1.6371726989746094\n",
      "Epoch [34/50], Step [2800/7038], D Loss: 0.2996729910373688, G Loss: 1.5394662618637085\n",
      "Epoch [34/50], Step [2900/7038], D Loss: 0.8423850536346436, G Loss: 1.168688416481018\n",
      "Epoch [34/50], Step [3000/7038], D Loss: 0.2993260324001312, G Loss: 1.6994112730026245\n",
      "Epoch [34/50], Step [3100/7038], D Loss: 0.3353002965450287, G Loss: 1.5642118453979492\n",
      "Epoch [34/50], Step [3200/7038], D Loss: 0.4376835227012634, G Loss: 1.3691648244857788\n",
      "Epoch [34/50], Step [3300/7038], D Loss: 0.7327522039413452, G Loss: 0.971682071685791\n",
      "Epoch [34/50], Step [3400/7038], D Loss: 0.4411812126636505, G Loss: 1.3269490003585815\n",
      "Epoch [34/50], Step [3500/7038], D Loss: 0.3075200021266937, G Loss: 1.532341718673706\n",
      "Epoch [34/50], Step [3600/7038], D Loss: 0.35330379009246826, G Loss: 1.2709307670593262\n",
      "Epoch [34/50], Step [3700/7038], D Loss: 0.5068650245666504, G Loss: 1.4907562732696533\n",
      "Epoch [34/50], Step [3800/7038], D Loss: 0.4503464102745056, G Loss: 1.790864109992981\n",
      "Epoch [34/50], Step [3900/7038], D Loss: 0.44079694151878357, G Loss: 1.4046860933303833\n",
      "Epoch [34/50], Step [4000/7038], D Loss: 0.5750536322593689, G Loss: 1.345571517944336\n",
      "Epoch [34/50], Step [4100/7038], D Loss: 0.24508407711982727, G Loss: 1.7438979148864746\n",
      "Epoch [34/50], Step [4200/7038], D Loss: 0.7901970148086548, G Loss: 1.0457196235656738\n",
      "Epoch [34/50], Step [4300/7038], D Loss: 0.5442777872085571, G Loss: 1.1341047286987305\n",
      "Epoch [34/50], Step [4400/7038], D Loss: 0.2613426744937897, G Loss: 2.493899345397949\n",
      "Epoch [34/50], Step [4500/7038], D Loss: 0.5017262697219849, G Loss: 1.1470481157302856\n",
      "Epoch [34/50], Step [4600/7038], D Loss: 0.4982925057411194, G Loss: 1.3863641023635864\n",
      "Epoch [34/50], Step [4700/7038], D Loss: 0.7681829929351807, G Loss: 1.6833672523498535\n",
      "Epoch [34/50], Step [4800/7038], D Loss: 0.3731994032859802, G Loss: 1.4015002250671387\n",
      "Epoch [34/50], Step [4900/7038], D Loss: 0.3319092392921448, G Loss: 1.8890732526779175\n",
      "Epoch [34/50], Step [5000/7038], D Loss: 0.4462178349494934, G Loss: 1.2479828596115112\n",
      "Epoch [34/50], Step [5100/7038], D Loss: 0.32116779685020447, G Loss: 1.441835641860962\n",
      "Epoch [34/50], Step [5200/7038], D Loss: 0.3781428337097168, G Loss: 1.6847560405731201\n",
      "Epoch [34/50], Step [5300/7038], D Loss: 0.3479578495025635, G Loss: 1.5549644231796265\n",
      "Epoch [34/50], Step [5400/7038], D Loss: 0.7296990156173706, G Loss: 1.21503746509552\n",
      "Epoch [34/50], Step [5500/7038], D Loss: 0.4943283796310425, G Loss: 1.1434650421142578\n",
      "Epoch [34/50], Step [5600/7038], D Loss: 0.38666245341300964, G Loss: 1.6668211221694946\n",
      "Epoch [34/50], Step [5700/7038], D Loss: 0.3833165466785431, G Loss: 1.4570415019989014\n",
      "Epoch [34/50], Step [5800/7038], D Loss: 0.3052389919757843, G Loss: 1.7762175798416138\n",
      "Epoch [34/50], Step [5900/7038], D Loss: 0.4219798743724823, G Loss: 1.2432860136032104\n",
      "Epoch [34/50], Step [6000/7038], D Loss: 0.5511770248413086, G Loss: 1.2667416334152222\n",
      "Epoch [34/50], Step [6100/7038], D Loss: 0.41848820447921753, G Loss: 1.3018107414245605\n",
      "Epoch [34/50], Step [6200/7038], D Loss: 0.3357429802417755, G Loss: 1.5642095804214478\n",
      "Epoch [34/50], Step [6300/7038], D Loss: 0.5603508949279785, G Loss: 1.3557875156402588\n",
      "Epoch [34/50], Step [6400/7038], D Loss: 0.40115052461624146, G Loss: 1.4110954999923706\n",
      "Epoch [34/50], Step [6500/7038], D Loss: 0.3005129396915436, G Loss: 2.1135668754577637\n",
      "Epoch [34/50], Step [6600/7038], D Loss: 0.5225306749343872, G Loss: 1.6070215702056885\n",
      "Epoch [34/50], Step [6700/7038], D Loss: 0.5980759263038635, G Loss: 1.45173180103302\n",
      "Epoch [34/50], Step [6800/7038], D Loss: 0.9136509895324707, G Loss: 1.2371206283569336\n",
      "Epoch [34/50], Step [6900/7038], D Loss: 0.8390562534332275, G Loss: 1.45405113697052\n",
      "Epoch [34/50], Step [7000/7038], D Loss: 0.45972949266433716, G Loss: 1.4645233154296875\n",
      "Epoch [35/50], Step [0/7038], D Loss: 0.3108266592025757, G Loss: 1.5665137767791748\n",
      "Epoch [35/50], Step [100/7038], D Loss: 0.5816417336463928, G Loss: 1.4155067205429077\n",
      "Epoch [35/50], Step [200/7038], D Loss: 0.4325152039527893, G Loss: 1.4170926809310913\n",
      "Epoch [35/50], Step [300/7038], D Loss: 0.4095378518104553, G Loss: 1.440203309059143\n",
      "Epoch [35/50], Step [400/7038], D Loss: 0.6347845792770386, G Loss: 1.6332625150680542\n",
      "Epoch [35/50], Step [500/7038], D Loss: 0.4768630862236023, G Loss: 1.3909568786621094\n",
      "Epoch [35/50], Step [600/7038], D Loss: 0.4159138798713684, G Loss: 1.3093714714050293\n",
      "Epoch [35/50], Step [700/7038], D Loss: 0.339480996131897, G Loss: 1.544628381729126\n",
      "Epoch [35/50], Step [800/7038], D Loss: 0.582657516002655, G Loss: 1.3971861600875854\n",
      "Epoch [35/50], Step [900/7038], D Loss: 0.48965737223625183, G Loss: 1.2409372329711914\n",
      "Epoch [35/50], Step [1000/7038], D Loss: 0.3557142913341522, G Loss: 1.582809329032898\n",
      "Epoch [35/50], Step [1100/7038], D Loss: 0.4937264025211334, G Loss: 1.8006623983383179\n",
      "Epoch [35/50], Step [1200/7038], D Loss: 0.5909414887428284, G Loss: 1.2937748432159424\n",
      "Epoch [35/50], Step [1300/7038], D Loss: 0.4006519019603729, G Loss: 1.4619312286376953\n",
      "Epoch [35/50], Step [1400/7038], D Loss: 0.40467357635498047, G Loss: 1.4519526958465576\n",
      "Epoch [35/50], Step [1500/7038], D Loss: 0.41823428869247437, G Loss: 1.5951277017593384\n",
      "Epoch [35/50], Step [1600/7038], D Loss: 0.44076547026634216, G Loss: 1.364801287651062\n",
      "Epoch [35/50], Step [1700/7038], D Loss: 0.5920007228851318, G Loss: 1.1847126483917236\n",
      "Epoch [35/50], Step [1800/7038], D Loss: 0.3933510184288025, G Loss: 1.7129794359207153\n",
      "Epoch [35/50], Step [1900/7038], D Loss: 0.3943479061126709, G Loss: 1.5508006811141968\n",
      "Epoch [35/50], Step [2000/7038], D Loss: 0.38830137252807617, G Loss: 1.6318784952163696\n",
      "Epoch [35/50], Step [2100/7038], D Loss: 0.5238426327705383, G Loss: 1.4119293689727783\n",
      "Epoch [35/50], Step [2200/7038], D Loss: 0.7373433113098145, G Loss: 1.2683476209640503\n",
      "Epoch [35/50], Step [2300/7038], D Loss: 0.5686331987380981, G Loss: 1.8716832399368286\n",
      "Epoch [35/50], Step [2400/7038], D Loss: 0.2680317759513855, G Loss: 1.6041104793548584\n",
      "Epoch [35/50], Step [2500/7038], D Loss: 0.5362255573272705, G Loss: 1.1973336935043335\n",
      "Epoch [35/50], Step [2600/7038], D Loss: 0.4839651882648468, G Loss: 1.3938629627227783\n",
      "Epoch [35/50], Step [2700/7038], D Loss: 0.5848718285560608, G Loss: 1.1857445240020752\n",
      "Epoch [35/50], Step [2800/7038], D Loss: 0.7782308459281921, G Loss: 1.0576303005218506\n",
      "Epoch [35/50], Step [2900/7038], D Loss: 0.5364335179328918, G Loss: 1.4553076028823853\n",
      "Epoch [35/50], Step [3000/7038], D Loss: 0.5876377820968628, G Loss: 1.9342249631881714\n",
      "Epoch [35/50], Step [3100/7038], D Loss: 0.49309074878692627, G Loss: 1.3014146089553833\n",
      "Epoch [35/50], Step [3200/7038], D Loss: 0.5558823347091675, G Loss: 0.703769326210022\n",
      "Epoch [35/50], Step [3300/7038], D Loss: 0.4039938151836395, G Loss: 2.1035361289978027\n",
      "Epoch [35/50], Step [3400/7038], D Loss: 0.4193398952484131, G Loss: 1.7390626668930054\n",
      "Epoch [35/50], Step [3500/7038], D Loss: 0.3049255609512329, G Loss: 1.6097865104675293\n",
      "Epoch [35/50], Step [3600/7038], D Loss: 0.2263161838054657, G Loss: 2.1330487728118896\n",
      "Epoch [35/50], Step [3700/7038], D Loss: 0.375306099653244, G Loss: 1.7606369256973267\n",
      "Epoch [35/50], Step [3800/7038], D Loss: 0.4946849048137665, G Loss: 1.3264610767364502\n",
      "Epoch [35/50], Step [3900/7038], D Loss: 0.49644243717193604, G Loss: 1.137728214263916\n",
      "Epoch [35/50], Step [4000/7038], D Loss: 0.40151241421699524, G Loss: 1.4799268245697021\n",
      "Epoch [35/50], Step [4100/7038], D Loss: 0.436630517244339, G Loss: 1.3340187072753906\n",
      "Epoch [35/50], Step [4200/7038], D Loss: 0.4753038287162781, G Loss: 1.1760903596878052\n",
      "Epoch [35/50], Step [4300/7038], D Loss: 0.32398074865341187, G Loss: 1.7137387990951538\n",
      "Epoch [35/50], Step [4400/7038], D Loss: 0.44023042917251587, G Loss: 1.2366538047790527\n",
      "Epoch [35/50], Step [4500/7038], D Loss: 0.48248744010925293, G Loss: 1.4604312181472778\n",
      "Epoch [35/50], Step [4600/7038], D Loss: 0.48845604062080383, G Loss: 1.0959914922714233\n",
      "Epoch [35/50], Step [4700/7038], D Loss: 0.3026527166366577, G Loss: 1.594893217086792\n",
      "Epoch [35/50], Step [4800/7038], D Loss: 0.34045350551605225, G Loss: 1.2287859916687012\n",
      "Epoch [35/50], Step [4900/7038], D Loss: 0.4691880941390991, G Loss: 1.3949002027511597\n",
      "Epoch [35/50], Step [5000/7038], D Loss: 0.35420167446136475, G Loss: 1.692692756652832\n",
      "Epoch [35/50], Step [5100/7038], D Loss: 0.5100512504577637, G Loss: 1.4951051473617554\n",
      "Epoch [35/50], Step [5200/7038], D Loss: 0.4685678780078888, G Loss: 2.7164227962493896\n",
      "Epoch [35/50], Step [5300/7038], D Loss: 0.42946839332580566, G Loss: 1.5551350116729736\n",
      "Epoch [35/50], Step [5400/7038], D Loss: 0.42219334840774536, G Loss: 1.7818619012832642\n",
      "Epoch [35/50], Step [5500/7038], D Loss: 0.4709717631340027, G Loss: 1.1049240827560425\n",
      "Epoch [35/50], Step [5600/7038], D Loss: 0.3430054187774658, G Loss: 1.8401015996932983\n",
      "Epoch [35/50], Step [5700/7038], D Loss: 0.33357977867126465, G Loss: 1.717429757118225\n",
      "Epoch [35/50], Step [5800/7038], D Loss: 0.45035213232040405, G Loss: 1.3822526931762695\n",
      "Epoch [35/50], Step [5900/7038], D Loss: 0.4035334885120392, G Loss: 1.5230119228363037\n",
      "Epoch [35/50], Step [6000/7038], D Loss: 0.5208685994148254, G Loss: 1.3066433668136597\n",
      "Epoch [35/50], Step [6100/7038], D Loss: 0.6287290453910828, G Loss: 1.3001368045806885\n",
      "Epoch [35/50], Step [6200/7038], D Loss: 0.5356590747833252, G Loss: 1.5689512491226196\n",
      "Epoch [35/50], Step [6300/7038], D Loss: 0.45298752188682556, G Loss: 1.0782591104507446\n",
      "Epoch [35/50], Step [6400/7038], D Loss: 0.43407630920410156, G Loss: 1.5440342426300049\n",
      "Epoch [35/50], Step [6500/7038], D Loss: 0.4477313160896301, G Loss: 1.4466053247451782\n",
      "Epoch [35/50], Step [6600/7038], D Loss: 0.39379921555519104, G Loss: 1.4935331344604492\n",
      "Epoch [35/50], Step [6700/7038], D Loss: 0.5978255867958069, G Loss: 1.2117745876312256\n",
      "Epoch [35/50], Step [6800/7038], D Loss: 0.4338274598121643, G Loss: 1.4952585697174072\n",
      "Epoch [35/50], Step [6900/7038], D Loss: 0.4055916666984558, G Loss: 1.5142822265625\n",
      "Epoch [35/50], Step [7000/7038], D Loss: 0.29147395491600037, G Loss: 2.064962387084961\n",
      "Epoch [36/50], Step [0/7038], D Loss: 0.5780680179595947, G Loss: 1.372757077217102\n",
      "Epoch [36/50], Step [100/7038], D Loss: 0.43672946095466614, G Loss: 1.2240115404129028\n",
      "Epoch [36/50], Step [200/7038], D Loss: 0.4486067295074463, G Loss: 1.4357044696807861\n",
      "Epoch [36/50], Step [300/7038], D Loss: 0.4758603274822235, G Loss: 1.7616010904312134\n",
      "Epoch [36/50], Step [400/7038], D Loss: 0.4984990954399109, G Loss: 1.3712365627288818\n",
      "Epoch [36/50], Step [500/7038], D Loss: 0.7219276428222656, G Loss: 1.1735773086547852\n",
      "Epoch [36/50], Step [600/7038], D Loss: 0.3597143888473511, G Loss: 1.7809864282608032\n",
      "Epoch [36/50], Step [700/7038], D Loss: 0.39297550916671753, G Loss: 1.8069789409637451\n",
      "Epoch [36/50], Step [800/7038], D Loss: 0.3967311680316925, G Loss: 1.4355924129486084\n",
      "Epoch [36/50], Step [900/7038], D Loss: 0.44171178340911865, G Loss: 1.3414121866226196\n",
      "Epoch [36/50], Step [1000/7038], D Loss: 0.38996320962905884, G Loss: 1.3793973922729492\n",
      "Epoch [36/50], Step [1100/7038], D Loss: 0.3828114867210388, G Loss: 1.4641860723495483\n",
      "Epoch [36/50], Step [1200/7038], D Loss: 0.31232285499572754, G Loss: 1.5417612791061401\n",
      "Epoch [36/50], Step [1300/7038], D Loss: 0.48566263914108276, G Loss: 1.2815041542053223\n",
      "Epoch [36/50], Step [1400/7038], D Loss: 0.7866065502166748, G Loss: 1.0805385112762451\n",
      "Epoch [36/50], Step [1500/7038], D Loss: 0.43628960847854614, G Loss: 1.6918327808380127\n",
      "Epoch [36/50], Step [1600/7038], D Loss: 0.554949164390564, G Loss: 1.815949559211731\n",
      "Epoch [36/50], Step [1700/7038], D Loss: 0.29939204454421997, G Loss: 1.8514435291290283\n",
      "Epoch [36/50], Step [1800/7038], D Loss: 0.5557152628898621, G Loss: 1.4205522537231445\n",
      "Epoch [36/50], Step [1900/7038], D Loss: 0.8084945678710938, G Loss: 1.067191243171692\n",
      "Epoch [36/50], Step [2000/7038], D Loss: 0.21870213747024536, G Loss: 2.031282424926758\n",
      "Epoch [36/50], Step [2100/7038], D Loss: 0.6787248849868774, G Loss: 0.7910144925117493\n",
      "Epoch [36/50], Step [2200/7038], D Loss: 0.38006681203842163, G Loss: 1.8248589038848877\n",
      "Epoch [36/50], Step [2300/7038], D Loss: 0.2679322063922882, G Loss: 1.6960140466690063\n",
      "Epoch [36/50], Step [2400/7038], D Loss: 0.35793280601501465, G Loss: 1.902151346206665\n",
      "Epoch [36/50], Step [2500/7038], D Loss: 0.38446369767189026, G Loss: 1.3742094039916992\n",
      "Epoch [36/50], Step [2600/7038], D Loss: 0.6600444316864014, G Loss: 1.0995779037475586\n",
      "Epoch [36/50], Step [2700/7038], D Loss: 0.5783701539039612, G Loss: 1.2407394647598267\n",
      "Epoch [36/50], Step [2800/7038], D Loss: 0.38262224197387695, G Loss: 1.525190830230713\n",
      "Epoch [36/50], Step [2900/7038], D Loss: 0.5252013206481934, G Loss: 1.7438634634017944\n",
      "Epoch [36/50], Step [3000/7038], D Loss: 0.42053359746932983, G Loss: 1.5423921346664429\n",
      "Epoch [36/50], Step [3100/7038], D Loss: 0.43592315912246704, G Loss: 1.2613537311553955\n",
      "Epoch [36/50], Step [3200/7038], D Loss: 0.4934699535369873, G Loss: 1.3504106998443604\n",
      "Epoch [36/50], Step [3300/7038], D Loss: 0.31233060359954834, G Loss: 1.863752841949463\n",
      "Epoch [36/50], Step [3400/7038], D Loss: 0.35728397965431213, G Loss: 1.8323452472686768\n",
      "Epoch [36/50], Step [3500/7038], D Loss: 0.707626223564148, G Loss: 1.54356849193573\n",
      "Epoch [36/50], Step [3600/7038], D Loss: 0.3259087800979614, G Loss: 1.6734857559204102\n",
      "Epoch [36/50], Step [3700/7038], D Loss: 0.4971618056297302, G Loss: 1.6854544878005981\n",
      "Epoch [36/50], Step [3800/7038], D Loss: 0.44122883677482605, G Loss: 1.4003130197525024\n",
      "Epoch [36/50], Step [3900/7038], D Loss: 0.3162359893321991, G Loss: 1.6434528827667236\n",
      "Epoch [36/50], Step [4000/7038], D Loss: 0.49391329288482666, G Loss: 1.23579740524292\n",
      "Epoch [36/50], Step [4100/7038], D Loss: 0.6282633543014526, G Loss: 1.5167453289031982\n",
      "Epoch [36/50], Step [4200/7038], D Loss: 0.38367533683776855, G Loss: 1.5029191970825195\n",
      "Epoch [36/50], Step [4300/7038], D Loss: 0.6158028841018677, G Loss: 1.6171101331710815\n",
      "Epoch [36/50], Step [4400/7038], D Loss: 0.5221293568611145, G Loss: 1.0145901441574097\n",
      "Epoch [36/50], Step [4500/7038], D Loss: 0.34473511576652527, G Loss: 1.9267973899841309\n",
      "Epoch [36/50], Step [4600/7038], D Loss: 0.4730353355407715, G Loss: 1.7280850410461426\n",
      "Epoch [36/50], Step [4700/7038], D Loss: 0.4992225468158722, G Loss: 1.7920018434524536\n",
      "Epoch [36/50], Step [4800/7038], D Loss: 0.3776469826698303, G Loss: 1.6274021863937378\n",
      "Epoch [36/50], Step [4900/7038], D Loss: 0.5945433378219604, G Loss: 1.489783763885498\n",
      "Epoch [36/50], Step [5000/7038], D Loss: 0.30734801292419434, G Loss: 1.8979300260543823\n",
      "Epoch [36/50], Step [5100/7038], D Loss: 0.4829198718070984, G Loss: 1.6305007934570312\n",
      "Epoch [36/50], Step [5200/7038], D Loss: 1.057349681854248, G Loss: 1.026029109954834\n",
      "Epoch [36/50], Step [5300/7038], D Loss: 0.656058132648468, G Loss: 1.4056973457336426\n",
      "Epoch [36/50], Step [5400/7038], D Loss: 0.4628477096557617, G Loss: 1.5794881582260132\n",
      "Epoch [36/50], Step [5500/7038], D Loss: 0.6063263416290283, G Loss: 1.3024966716766357\n",
      "Epoch [36/50], Step [5600/7038], D Loss: 0.3991697132587433, G Loss: 1.6417039632797241\n",
      "Epoch [36/50], Step [5700/7038], D Loss: 0.41636961698532104, G Loss: 1.3039790391921997\n",
      "Epoch [36/50], Step [5800/7038], D Loss: 0.45033788681030273, G Loss: 1.2867248058319092\n",
      "Epoch [36/50], Step [5900/7038], D Loss: 0.43185436725616455, G Loss: 1.572869896888733\n",
      "Epoch [36/50], Step [6000/7038], D Loss: 0.46195629239082336, G Loss: 1.4846540689468384\n",
      "Epoch [36/50], Step [6100/7038], D Loss: 0.40635550022125244, G Loss: 1.5608675479888916\n",
      "Epoch [36/50], Step [6200/7038], D Loss: 0.6343175172805786, G Loss: 1.3237510919570923\n",
      "Epoch [36/50], Step [6300/7038], D Loss: 0.8945116996765137, G Loss: 1.3525776863098145\n",
      "Epoch [36/50], Step [6400/7038], D Loss: 0.381281316280365, G Loss: 1.411336064338684\n",
      "Epoch [36/50], Step [6500/7038], D Loss: 0.36962616443634033, G Loss: 1.7225369215011597\n",
      "Epoch [36/50], Step [6600/7038], D Loss: 0.48586902022361755, G Loss: 1.2442508935928345\n",
      "Epoch [36/50], Step [6700/7038], D Loss: 0.6029316186904907, G Loss: 1.1971324682235718\n",
      "Epoch [36/50], Step [6800/7038], D Loss: 0.3924746513366699, G Loss: 1.8378355503082275\n",
      "Epoch [36/50], Step [6900/7038], D Loss: 0.660030722618103, G Loss: 1.0891749858856201\n",
      "Epoch [36/50], Step [7000/7038], D Loss: 0.4756055772304535, G Loss: 1.2642053365707397\n",
      "Epoch [37/50], Step [0/7038], D Loss: 0.46325260400772095, G Loss: 1.4282536506652832\n",
      "Epoch [37/50], Step [100/7038], D Loss: 0.4813089072704315, G Loss: 1.4093760251998901\n",
      "Epoch [37/50], Step [200/7038], D Loss: 0.6516908407211304, G Loss: 1.5719988346099854\n",
      "Epoch [37/50], Step [300/7038], D Loss: 0.5199524760246277, G Loss: 1.3977172374725342\n",
      "Epoch [37/50], Step [400/7038], D Loss: 0.3561474680900574, G Loss: 1.7493624687194824\n",
      "Epoch [37/50], Step [500/7038], D Loss: 0.3767060339450836, G Loss: 1.6906660795211792\n",
      "Epoch [37/50], Step [600/7038], D Loss: 0.3365517258644104, G Loss: 1.4671661853790283\n",
      "Epoch [37/50], Step [700/7038], D Loss: 0.6488308310508728, G Loss: 1.1783568859100342\n",
      "Epoch [37/50], Step [800/7038], D Loss: 0.17134562134742737, G Loss: 2.520327568054199\n",
      "Epoch [37/50], Step [900/7038], D Loss: 0.32391631603240967, G Loss: 1.7773317098617554\n",
      "Epoch [37/50], Step [1000/7038], D Loss: 0.2658742666244507, G Loss: 2.0788769721984863\n",
      "Epoch [37/50], Step [1100/7038], D Loss: 0.38100194931030273, G Loss: 1.6939067840576172\n",
      "Epoch [37/50], Step [1200/7038], D Loss: 0.43756604194641113, G Loss: 1.4602464437484741\n",
      "Epoch [37/50], Step [1300/7038], D Loss: 0.4052731990814209, G Loss: 1.522952914237976\n",
      "Epoch [37/50], Step [1400/7038], D Loss: 0.50651615858078, G Loss: 1.8936617374420166\n",
      "Epoch [37/50], Step [1500/7038], D Loss: 0.3693860173225403, G Loss: 1.3929792642593384\n",
      "Epoch [37/50], Step [1600/7038], D Loss: 0.3109206259250641, G Loss: 1.4904148578643799\n",
      "Epoch [37/50], Step [1700/7038], D Loss: 0.3726092576980591, G Loss: 1.6833572387695312\n",
      "Epoch [37/50], Step [1800/7038], D Loss: 0.5716543197631836, G Loss: 1.6257379055023193\n",
      "Epoch [37/50], Step [1900/7038], D Loss: 0.3129514455795288, G Loss: 1.608942985534668\n",
      "Epoch [37/50], Step [2000/7038], D Loss: 0.29420146346092224, G Loss: 1.5860623121261597\n",
      "Epoch [37/50], Step [2100/7038], D Loss: 0.4010659158229828, G Loss: 2.143040180206299\n",
      "Epoch [37/50], Step [2200/7038], D Loss: 0.4461679458618164, G Loss: 1.37081778049469\n",
      "Epoch [37/50], Step [2300/7038], D Loss: 0.340592622756958, G Loss: 1.381859302520752\n",
      "Epoch [37/50], Step [2400/7038], D Loss: 0.5535651445388794, G Loss: 1.2407609224319458\n",
      "Epoch [37/50], Step [2500/7038], D Loss: 0.40965092182159424, G Loss: 1.6159521341323853\n",
      "Epoch [37/50], Step [2600/7038], D Loss: 0.789729118347168, G Loss: 1.1306571960449219\n",
      "Epoch [37/50], Step [2700/7038], D Loss: 0.5179703235626221, G Loss: 1.562942385673523\n",
      "Epoch [37/50], Step [2800/7038], D Loss: 0.5180063843727112, G Loss: 1.2576197385787964\n",
      "Epoch [37/50], Step [2900/7038], D Loss: 0.43725335597991943, G Loss: 1.2325387001037598\n",
      "Epoch [37/50], Step [3000/7038], D Loss: 0.216079443693161, G Loss: 2.3982319831848145\n",
      "Epoch [37/50], Step [3100/7038], D Loss: 0.5401679277420044, G Loss: 1.350356936454773\n",
      "Epoch [37/50], Step [3200/7038], D Loss: 0.5127143263816833, G Loss: 1.2443983554840088\n",
      "Epoch [37/50], Step [3300/7038], D Loss: 0.5870357751846313, G Loss: 1.5369309186935425\n",
      "Epoch [37/50], Step [3400/7038], D Loss: 0.2886652946472168, G Loss: 1.7651796340942383\n",
      "Epoch [37/50], Step [3500/7038], D Loss: 0.4489503502845764, G Loss: 1.7024911642074585\n",
      "Epoch [37/50], Step [3600/7038], D Loss: 0.4998502731323242, G Loss: 2.6053359508514404\n",
      "Epoch [37/50], Step [3700/7038], D Loss: 0.4615517258644104, G Loss: 1.4567234516143799\n",
      "Epoch [37/50], Step [3800/7038], D Loss: 0.4544755220413208, G Loss: 1.5417886972427368\n",
      "Epoch [37/50], Step [3900/7038], D Loss: 0.49823641777038574, G Loss: 1.288702130317688\n",
      "Epoch [37/50], Step [4000/7038], D Loss: 0.5080759525299072, G Loss: 2.1183953285217285\n",
      "Epoch [37/50], Step [4100/7038], D Loss: 0.4330971837043762, G Loss: 1.285333514213562\n",
      "Epoch [37/50], Step [4200/7038], D Loss: 0.48835453391075134, G Loss: 1.3677072525024414\n",
      "Epoch [37/50], Step [4300/7038], D Loss: 0.34576934576034546, G Loss: 1.8283292055130005\n",
      "Epoch [37/50], Step [4400/7038], D Loss: 0.7092090845108032, G Loss: 1.4068570137023926\n",
      "Epoch [37/50], Step [4500/7038], D Loss: 0.387557715177536, G Loss: 1.7968671321868896\n",
      "Epoch [37/50], Step [4600/7038], D Loss: 0.3956539034843445, G Loss: 1.2432430982589722\n",
      "Epoch [37/50], Step [4700/7038], D Loss: 0.5882350206375122, G Loss: 1.1000274419784546\n",
      "Epoch [37/50], Step [4800/7038], D Loss: 0.28941673040390015, G Loss: 1.9730823040008545\n",
      "Epoch [37/50], Step [4900/7038], D Loss: 0.521658718585968, G Loss: 1.4558192491531372\n",
      "Epoch [37/50], Step [5000/7038], D Loss: 0.44490841031074524, G Loss: 1.448264479637146\n",
      "Epoch [37/50], Step [5100/7038], D Loss: 0.8531462550163269, G Loss: 1.573599934577942\n",
      "Epoch [37/50], Step [5200/7038], D Loss: 0.47921639680862427, G Loss: 1.1380751132965088\n",
      "Epoch [37/50], Step [5300/7038], D Loss: 0.6074978709220886, G Loss: 1.272222876548767\n",
      "Epoch [37/50], Step [5400/7038], D Loss: 0.288472056388855, G Loss: 2.0128841400146484\n",
      "Epoch [37/50], Step [5500/7038], D Loss: 0.4240718185901642, G Loss: 1.3513716459274292\n",
      "Epoch [37/50], Step [5600/7038], D Loss: 0.532890796661377, G Loss: 1.1933777332305908\n",
      "Epoch [37/50], Step [5700/7038], D Loss: 0.2969047427177429, G Loss: 1.874176025390625\n",
      "Epoch [37/50], Step [5800/7038], D Loss: 0.5606822371482849, G Loss: 1.4958957433700562\n",
      "Epoch [37/50], Step [5900/7038], D Loss: 0.6230635643005371, G Loss: 1.0770390033721924\n",
      "Epoch [37/50], Step [6000/7038], D Loss: 0.43094342947006226, G Loss: 1.4221140146255493\n",
      "Epoch [37/50], Step [6100/7038], D Loss: 0.6861100792884827, G Loss: 1.389106273651123\n",
      "Epoch [37/50], Step [6200/7038], D Loss: 0.449654757976532, G Loss: 1.2631255388259888\n",
      "Epoch [37/50], Step [6300/7038], D Loss: 0.4824579358100891, G Loss: 1.233949065208435\n",
      "Epoch [37/50], Step [6400/7038], D Loss: 0.3268435299396515, G Loss: 1.5486741065979004\n",
      "Epoch [37/50], Step [6500/7038], D Loss: 0.30075693130493164, G Loss: 1.7990978956222534\n",
      "Epoch [37/50], Step [6600/7038], D Loss: 0.4988807439804077, G Loss: 1.3508400917053223\n",
      "Epoch [37/50], Step [6700/7038], D Loss: 0.4514176547527313, G Loss: 1.331873893737793\n",
      "Epoch [37/50], Step [6800/7038], D Loss: 0.517278254032135, G Loss: 1.8527390956878662\n",
      "Epoch [37/50], Step [6900/7038], D Loss: 0.3197174072265625, G Loss: 1.4743975400924683\n",
      "Epoch [37/50], Step [7000/7038], D Loss: 0.37594544887542725, G Loss: 1.7641996145248413\n",
      "Epoch [38/50], Step [0/7038], D Loss: 0.2980515956878662, G Loss: 1.7431349754333496\n",
      "Epoch [38/50], Step [100/7038], D Loss: 0.4063381850719452, G Loss: 1.6296932697296143\n",
      "Epoch [38/50], Step [200/7038], D Loss: 0.2852210998535156, G Loss: 2.0459485054016113\n",
      "Epoch [38/50], Step [300/7038], D Loss: 0.5415705442428589, G Loss: 1.2964410781860352\n",
      "Epoch [38/50], Step [400/7038], D Loss: 0.5259428024291992, G Loss: 1.1412137746810913\n",
      "Epoch [38/50], Step [500/7038], D Loss: 0.643372118473053, G Loss: 1.2468262910842896\n",
      "Epoch [38/50], Step [600/7038], D Loss: 0.5181677937507629, G Loss: 1.2642440795898438\n",
      "Epoch [38/50], Step [700/7038], D Loss: 0.31039756536483765, G Loss: 1.6207607984542847\n",
      "Epoch [38/50], Step [800/7038], D Loss: 0.39907896518707275, G Loss: 1.538348913192749\n",
      "Epoch [38/50], Step [900/7038], D Loss: 0.6800386905670166, G Loss: 1.1889582872390747\n",
      "Epoch [38/50], Step [1000/7038], D Loss: 0.5414361953735352, G Loss: 1.7718905210494995\n",
      "Epoch [38/50], Step [1100/7038], D Loss: 0.7380419969558716, G Loss: 1.3157966136932373\n",
      "Epoch [38/50], Step [1200/7038], D Loss: 0.5576602816581726, G Loss: 1.2014950513839722\n",
      "Epoch [38/50], Step [1300/7038], D Loss: 0.41947847604751587, G Loss: 1.43672513961792\n",
      "Epoch [38/50], Step [1400/7038], D Loss: 0.7477473020553589, G Loss: 1.1303819417953491\n",
      "Epoch [38/50], Step [1500/7038], D Loss: 0.48384085297584534, G Loss: 1.1418143510818481\n",
      "Epoch [38/50], Step [1600/7038], D Loss: 0.667599081993103, G Loss: 2.2376890182495117\n",
      "Epoch [38/50], Step [1700/7038], D Loss: 0.40048688650131226, G Loss: 1.7754608392715454\n",
      "Epoch [38/50], Step [1800/7038], D Loss: 0.5338152050971985, G Loss: 1.2212443351745605\n",
      "Epoch [38/50], Step [1900/7038], D Loss: 0.4216403365135193, G Loss: 1.5339947938919067\n",
      "Epoch [38/50], Step [2000/7038], D Loss: 0.577170193195343, G Loss: 1.1108299493789673\n",
      "Epoch [38/50], Step [2100/7038], D Loss: 0.5580599308013916, G Loss: 1.4574522972106934\n",
      "Epoch [38/50], Step [2200/7038], D Loss: 0.5166200995445251, G Loss: 1.4706130027770996\n",
      "Epoch [38/50], Step [2300/7038], D Loss: 0.7557727098464966, G Loss: 2.5659306049346924\n",
      "Epoch [38/50], Step [2400/7038], D Loss: 0.5054373741149902, G Loss: 1.2414751052856445\n",
      "Epoch [38/50], Step [2500/7038], D Loss: 0.7820618152618408, G Loss: 1.0864462852478027\n",
      "Epoch [38/50], Step [2600/7038], D Loss: 0.3825213611125946, G Loss: 1.4271981716156006\n",
      "Epoch [38/50], Step [2700/7038], D Loss: 0.2080543488264084, G Loss: 1.9456593990325928\n",
      "Epoch [38/50], Step [2800/7038], D Loss: 0.29159390926361084, G Loss: 1.9735643863677979\n",
      "Epoch [38/50], Step [2900/7038], D Loss: 0.5530273914337158, G Loss: 1.2291719913482666\n",
      "Epoch [38/50], Step [3000/7038], D Loss: 0.3142626881599426, G Loss: 1.545902132987976\n",
      "Epoch [38/50], Step [3100/7038], D Loss: 0.5762650966644287, G Loss: 1.6194769144058228\n",
      "Epoch [38/50], Step [3200/7038], D Loss: 0.47313326597213745, G Loss: 1.3759576082229614\n",
      "Epoch [38/50], Step [3300/7038], D Loss: 0.6937016248703003, G Loss: 0.9719366431236267\n",
      "Epoch [38/50], Step [3400/7038], D Loss: 0.3674435317516327, G Loss: 1.3600842952728271\n",
      "Epoch [38/50], Step [3500/7038], D Loss: 0.27930748462677, G Loss: 1.5096088647842407\n",
      "Epoch [38/50], Step [3600/7038], D Loss: 0.4229130744934082, G Loss: 1.3013168573379517\n",
      "Epoch [38/50], Step [3700/7038], D Loss: 0.421258807182312, G Loss: 2.1416280269622803\n",
      "Epoch [38/50], Step [3800/7038], D Loss: 0.5959322452545166, G Loss: 1.2351758480072021\n",
      "Epoch [38/50], Step [3900/7038], D Loss: 0.7605537176132202, G Loss: 1.5937507152557373\n",
      "Epoch [38/50], Step [4000/7038], D Loss: 0.3506166934967041, G Loss: 1.560697078704834\n",
      "Epoch [38/50], Step [4100/7038], D Loss: 0.5378800630569458, G Loss: 1.6874632835388184\n",
      "Epoch [38/50], Step [4200/7038], D Loss: 0.4408244490623474, G Loss: 1.4043519496917725\n",
      "Epoch [38/50], Step [4300/7038], D Loss: 0.4581105411052704, G Loss: 1.1313503980636597\n",
      "Epoch [38/50], Step [4400/7038], D Loss: 0.3593766689300537, G Loss: 1.4592161178588867\n",
      "Epoch [38/50], Step [4500/7038], D Loss: 0.22700831294059753, G Loss: 1.990257978439331\n",
      "Epoch [38/50], Step [4600/7038], D Loss: 0.23326487839221954, G Loss: 1.7325212955474854\n",
      "Epoch [38/50], Step [4700/7038], D Loss: 0.34221702814102173, G Loss: 1.574870228767395\n",
      "Epoch [38/50], Step [4800/7038], D Loss: 0.7002806663513184, G Loss: 1.8785910606384277\n",
      "Epoch [38/50], Step [4900/7038], D Loss: 0.48097479343414307, G Loss: 1.3499083518981934\n",
      "Epoch [38/50], Step [5000/7038], D Loss: 0.41303104162216187, G Loss: 2.198030710220337\n",
      "Epoch [38/50], Step [5100/7038], D Loss: 0.7786753177642822, G Loss: 1.7868739366531372\n",
      "Epoch [38/50], Step [5200/7038], D Loss: 0.5612100958824158, G Loss: 1.192539930343628\n",
      "Epoch [38/50], Step [5300/7038], D Loss: 0.2718067169189453, G Loss: 1.82501220703125\n",
      "Epoch [38/50], Step [5400/7038], D Loss: 0.5763645172119141, G Loss: 1.3175846338272095\n",
      "Epoch [38/50], Step [5500/7038], D Loss: 0.40650615096092224, G Loss: 1.2389227151870728\n",
      "Epoch [38/50], Step [5600/7038], D Loss: 0.5501257181167603, G Loss: 1.0619667768478394\n",
      "Epoch [38/50], Step [5700/7038], D Loss: 0.4881872534751892, G Loss: 1.3534330129623413\n",
      "Epoch [38/50], Step [5800/7038], D Loss: 0.3647605776786804, G Loss: 1.7267378568649292\n",
      "Epoch [38/50], Step [5900/7038], D Loss: 0.9189329743385315, G Loss: 1.6245847940444946\n",
      "Epoch [38/50], Step [6000/7038], D Loss: 0.4759095311164856, G Loss: 1.8248735666275024\n",
      "Epoch [38/50], Step [6100/7038], D Loss: 0.369662880897522, G Loss: 1.872611403465271\n",
      "Epoch [38/50], Step [6200/7038], D Loss: 0.6768609285354614, G Loss: 1.34254789352417\n",
      "Epoch [38/50], Step [6300/7038], D Loss: 0.6021097898483276, G Loss: 1.1616358757019043\n",
      "Epoch [38/50], Step [6400/7038], D Loss: 0.3768838047981262, G Loss: 1.5109403133392334\n",
      "Epoch [38/50], Step [6500/7038], D Loss: 0.45618271827697754, G Loss: 1.0848321914672852\n",
      "Epoch [38/50], Step [6600/7038], D Loss: 0.23191507160663605, G Loss: 1.9747309684753418\n",
      "Epoch [38/50], Step [6700/7038], D Loss: 0.26522061228752136, G Loss: 1.8842328786849976\n",
      "Epoch [38/50], Step [6800/7038], D Loss: 0.46665406227111816, G Loss: 1.2511001825332642\n",
      "Epoch [38/50], Step [6900/7038], D Loss: 0.41435956954956055, G Loss: 1.4425976276397705\n",
      "Epoch [38/50], Step [7000/7038], D Loss: 0.5903260707855225, G Loss: 1.1683732271194458\n",
      "Epoch [39/50], Step [0/7038], D Loss: 0.23714891076087952, G Loss: 1.7964344024658203\n",
      "Epoch [39/50], Step [100/7038], D Loss: 0.4650549292564392, G Loss: 1.4966009855270386\n",
      "Epoch [39/50], Step [200/7038], D Loss: 0.4653308391571045, G Loss: 0.9661423563957214\n",
      "Epoch [39/50], Step [300/7038], D Loss: 0.3448726236820221, G Loss: 1.8533592224121094\n",
      "Epoch [39/50], Step [400/7038], D Loss: 0.3954707086086273, G Loss: 1.8936609029769897\n",
      "Epoch [39/50], Step [500/7038], D Loss: 0.3820860981941223, G Loss: 1.7161433696746826\n",
      "Epoch [39/50], Step [600/7038], D Loss: 0.46144166588783264, G Loss: 1.2398096323013306\n",
      "Epoch [39/50], Step [700/7038], D Loss: 0.6682255864143372, G Loss: 1.394562840461731\n",
      "Epoch [39/50], Step [800/7038], D Loss: 0.3076450228691101, G Loss: 1.4437968730926514\n",
      "Epoch [39/50], Step [900/7038], D Loss: 0.4286256730556488, G Loss: 1.3753578662872314\n",
      "Epoch [39/50], Step [1000/7038], D Loss: 0.4155116677284241, G Loss: 1.488808274269104\n",
      "Epoch [39/50], Step [1100/7038], D Loss: 0.4820410907268524, G Loss: 1.3675835132598877\n",
      "Epoch [39/50], Step [1200/7038], D Loss: 0.4132879972457886, G Loss: 1.5613986253738403\n",
      "Epoch [39/50], Step [1300/7038], D Loss: 0.4309591054916382, G Loss: 1.279364824295044\n",
      "Epoch [39/50], Step [1400/7038], D Loss: 0.4370081424713135, G Loss: 1.7152588367462158\n",
      "Epoch [39/50], Step [1500/7038], D Loss: 0.5749329924583435, G Loss: 1.6785602569580078\n",
      "Epoch [39/50], Step [1600/7038], D Loss: 0.28971076011657715, G Loss: 1.893214464187622\n",
      "Epoch [39/50], Step [1700/7038], D Loss: 0.5299395322799683, G Loss: 1.2722457647323608\n",
      "Epoch [39/50], Step [1800/7038], D Loss: 0.6724554300308228, G Loss: 1.304489016532898\n",
      "Epoch [39/50], Step [1900/7038], D Loss: 0.5788036584854126, G Loss: 1.295348882675171\n",
      "Epoch [39/50], Step [2000/7038], D Loss: 0.47749269008636475, G Loss: 1.284454345703125\n",
      "Epoch [39/50], Step [2100/7038], D Loss: 0.36884650588035583, G Loss: 1.580704689025879\n",
      "Epoch [39/50], Step [2200/7038], D Loss: 0.5773782134056091, G Loss: 0.9396554827690125\n",
      "Epoch [39/50], Step [2300/7038], D Loss: 0.4970444440841675, G Loss: 1.1813304424285889\n",
      "Epoch [39/50], Step [2400/7038], D Loss: 0.6006748676300049, G Loss: 1.1133438348770142\n",
      "Epoch [39/50], Step [2500/7038], D Loss: 0.534466564655304, G Loss: 1.2713656425476074\n",
      "Epoch [39/50], Step [2600/7038], D Loss: 0.7804800271987915, G Loss: 1.4450373649597168\n",
      "Epoch [39/50], Step [2700/7038], D Loss: 0.5324674248695374, G Loss: 1.126711130142212\n",
      "Epoch [39/50], Step [2800/7038], D Loss: 0.4755561053752899, G Loss: 1.8063901662826538\n",
      "Epoch [39/50], Step [2900/7038], D Loss: 0.4265402853488922, G Loss: 1.233712077140808\n",
      "Epoch [39/50], Step [3000/7038], D Loss: 0.6103872656822205, G Loss: 1.3664830923080444\n",
      "Epoch [39/50], Step [3100/7038], D Loss: 0.3559606671333313, G Loss: 1.4608124494552612\n",
      "Epoch [39/50], Step [3200/7038], D Loss: 0.4550049304962158, G Loss: 1.364993691444397\n",
      "Epoch [39/50], Step [3300/7038], D Loss: 0.7771203517913818, G Loss: 1.143600344657898\n",
      "Epoch [39/50], Step [3400/7038], D Loss: 0.3749755024909973, G Loss: 1.8744361400604248\n",
      "Epoch [39/50], Step [3500/7038], D Loss: 0.5813462734222412, G Loss: 1.1041245460510254\n",
      "Epoch [39/50], Step [3600/7038], D Loss: 0.3628993034362793, G Loss: 1.8534858226776123\n",
      "Epoch [39/50], Step [3700/7038], D Loss: 0.44669491052627563, G Loss: 1.7503541707992554\n",
      "Epoch [39/50], Step [3800/7038], D Loss: 0.3585909605026245, G Loss: 1.6689107418060303\n",
      "Epoch [39/50], Step [3900/7038], D Loss: 0.3283180594444275, G Loss: 1.5371897220611572\n",
      "Epoch [39/50], Step [4000/7038], D Loss: 0.3997687101364136, G Loss: 1.5150015354156494\n",
      "Epoch [39/50], Step [4100/7038], D Loss: 0.43050122261047363, G Loss: 1.6240479946136475\n",
      "Epoch [39/50], Step [4200/7038], D Loss: 0.7207095623016357, G Loss: 1.0283536911010742\n",
      "Epoch [39/50], Step [4300/7038], D Loss: 0.6398513913154602, G Loss: 1.1752386093139648\n",
      "Epoch [39/50], Step [4400/7038], D Loss: 0.4975135922431946, G Loss: 1.4021424055099487\n",
      "Epoch [39/50], Step [4500/7038], D Loss: 0.6309831142425537, G Loss: 1.5976155996322632\n",
      "Epoch [39/50], Step [4600/7038], D Loss: 0.2486346960067749, G Loss: 1.9758880138397217\n",
      "Epoch [39/50], Step [4700/7038], D Loss: 0.25130635499954224, G Loss: 2.1158511638641357\n",
      "Epoch [39/50], Step [4800/7038], D Loss: 0.7431217432022095, G Loss: 1.2687827348709106\n",
      "Epoch [39/50], Step [4900/7038], D Loss: 1.0387393236160278, G Loss: 0.8611938953399658\n",
      "Epoch [39/50], Step [5000/7038], D Loss: 0.36410677433013916, G Loss: 1.4867380857467651\n",
      "Epoch [39/50], Step [5100/7038], D Loss: 0.4561292231082916, G Loss: 1.3376456499099731\n",
      "Epoch [39/50], Step [5200/7038], D Loss: 1.1312251091003418, G Loss: 2.3291847705841064\n",
      "Epoch [39/50], Step [5300/7038], D Loss: 0.2980252504348755, G Loss: 2.01877760887146\n",
      "Epoch [39/50], Step [5400/7038], D Loss: 0.22343599796295166, G Loss: 2.0821282863616943\n",
      "Epoch [39/50], Step [5500/7038], D Loss: 0.4959779977798462, G Loss: 1.2685763835906982\n",
      "Epoch [39/50], Step [5600/7038], D Loss: 0.48829513788223267, G Loss: 2.062570810317993\n",
      "Epoch [39/50], Step [5700/7038], D Loss: 0.3449239730834961, G Loss: 1.9740628004074097\n",
      "Epoch [39/50], Step [5800/7038], D Loss: 0.5166494846343994, G Loss: 1.1742533445358276\n",
      "Epoch [39/50], Step [5900/7038], D Loss: 0.490200936794281, G Loss: 2.0097649097442627\n",
      "Epoch [39/50], Step [6000/7038], D Loss: 0.4213184118270874, G Loss: 1.265476107597351\n",
      "Epoch [39/50], Step [6100/7038], D Loss: 0.2865532338619232, G Loss: 1.9473541975021362\n",
      "Epoch [39/50], Step [6200/7038], D Loss: 0.2997765839099884, G Loss: 1.8864179849624634\n",
      "Epoch [39/50], Step [6300/7038], D Loss: 0.4271315932273865, G Loss: 1.3343008756637573\n",
      "Epoch [39/50], Step [6400/7038], D Loss: 0.5914006233215332, G Loss: 1.0937209129333496\n",
      "Epoch [39/50], Step [6500/7038], D Loss: 0.34065496921539307, G Loss: 1.4594773054122925\n",
      "Epoch [39/50], Step [6600/7038], D Loss: 0.48778605461120605, G Loss: 1.1994528770446777\n",
      "Epoch [39/50], Step [6700/7038], D Loss: 0.34908199310302734, G Loss: 1.9592132568359375\n",
      "Epoch [39/50], Step [6800/7038], D Loss: 0.6440997123718262, G Loss: 1.127913475036621\n",
      "Epoch [39/50], Step [6900/7038], D Loss: 0.342337042093277, G Loss: 2.0808427333831787\n",
      "Epoch [39/50], Step [7000/7038], D Loss: 0.31319335103034973, G Loss: 1.761579155921936\n",
      "Epoch [40/50], Step [0/7038], D Loss: 0.760743260383606, G Loss: 0.8194960951805115\n",
      "Epoch [40/50], Step [100/7038], D Loss: 0.5015969276428223, G Loss: 1.8291397094726562\n",
      "Epoch [40/50], Step [200/7038], D Loss: 0.516087532043457, G Loss: 1.3558567762374878\n",
      "Epoch [40/50], Step [300/7038], D Loss: 0.5745623111724854, G Loss: 1.343177080154419\n",
      "Epoch [40/50], Step [400/7038], D Loss: 0.5494632720947266, G Loss: 1.2349644899368286\n",
      "Epoch [40/50], Step [500/7038], D Loss: 0.33772900700569153, G Loss: 1.4786895513534546\n",
      "Epoch [40/50], Step [600/7038], D Loss: 0.41258925199508667, G Loss: 1.7279326915740967\n",
      "Epoch [40/50], Step [700/7038], D Loss: 0.5756814479827881, G Loss: 2.1352732181549072\n",
      "Epoch [40/50], Step [800/7038], D Loss: 0.591399610042572, G Loss: 0.8960971832275391\n",
      "Epoch [40/50], Step [900/7038], D Loss: 0.5216428637504578, G Loss: 1.379841923713684\n",
      "Epoch [40/50], Step [1000/7038], D Loss: 0.41347140073776245, G Loss: 1.3791252374649048\n",
      "Epoch [40/50], Step [1100/7038], D Loss: 0.4554068148136139, G Loss: 1.3579341173171997\n",
      "Epoch [40/50], Step [1200/7038], D Loss: 0.5482305884361267, G Loss: 1.6726350784301758\n",
      "Epoch [40/50], Step [1300/7038], D Loss: 0.6110217571258545, G Loss: 1.177115559577942\n",
      "Epoch [40/50], Step [1400/7038], D Loss: 0.502979040145874, G Loss: 1.9847253561019897\n",
      "Epoch [40/50], Step [1500/7038], D Loss: 0.41077953577041626, G Loss: 1.2966668605804443\n",
      "Epoch [40/50], Step [1600/7038], D Loss: 0.4932074546813965, G Loss: 1.6105027198791504\n",
      "Epoch [40/50], Step [1700/7038], D Loss: 0.33429715037345886, G Loss: 1.598748803138733\n",
      "Epoch [40/50], Step [1800/7038], D Loss: 0.36253154277801514, G Loss: 1.960719108581543\n",
      "Epoch [40/50], Step [1900/7038], D Loss: 0.5009812116622925, G Loss: 2.8645431995391846\n",
      "Epoch [40/50], Step [2000/7038], D Loss: 0.38938412070274353, G Loss: 1.338423728942871\n",
      "Epoch [40/50], Step [2100/7038], D Loss: 0.502629280090332, G Loss: 1.1931613683700562\n",
      "Epoch [40/50], Step [2200/7038], D Loss: 0.4583943486213684, G Loss: 1.3108148574829102\n",
      "Epoch [40/50], Step [2300/7038], D Loss: 0.46959859132766724, G Loss: 1.2659971714019775\n",
      "Epoch [40/50], Step [2400/7038], D Loss: 0.34111589193344116, G Loss: 1.8589524030685425\n",
      "Epoch [40/50], Step [2500/7038], D Loss: 0.553016722202301, G Loss: 1.239950180053711\n",
      "Epoch [40/50], Step [2600/7038], D Loss: 0.3496958613395691, G Loss: 1.4830502271652222\n",
      "Epoch [40/50], Step [2700/7038], D Loss: 0.35328614711761475, G Loss: 1.75081467628479\n",
      "Epoch [40/50], Step [2800/7038], D Loss: 0.40040072798728943, G Loss: 1.7882788181304932\n",
      "Epoch [40/50], Step [2900/7038], D Loss: 0.39277637004852295, G Loss: 1.4634708166122437\n",
      "Epoch [40/50], Step [3000/7038], D Loss: 0.3579334020614624, G Loss: 1.8478286266326904\n",
      "Epoch [40/50], Step [3100/7038], D Loss: 0.2777664065361023, G Loss: 1.5881260633468628\n",
      "Epoch [40/50], Step [3200/7038], D Loss: 0.4034162759780884, G Loss: 1.2419102191925049\n",
      "Epoch [40/50], Step [3300/7038], D Loss: 0.66172194480896, G Loss: 1.1308674812316895\n",
      "Epoch [40/50], Step [3400/7038], D Loss: 0.5087963342666626, G Loss: 1.2940020561218262\n",
      "Epoch [40/50], Step [3500/7038], D Loss: 0.35787445306777954, G Loss: 1.8704180717468262\n",
      "Epoch [40/50], Step [3600/7038], D Loss: 0.4512683153152466, G Loss: 1.4906773567199707\n",
      "Epoch [40/50], Step [3700/7038], D Loss: 0.4306394159793854, G Loss: 1.367194414138794\n",
      "Epoch [40/50], Step [3800/7038], D Loss: 0.5914392471313477, G Loss: 1.1264891624450684\n",
      "Epoch [40/50], Step [3900/7038], D Loss: 0.6280381679534912, G Loss: 2.398601770401001\n",
      "Epoch [40/50], Step [4000/7038], D Loss: 0.556201159954071, G Loss: 1.199158787727356\n",
      "Epoch [40/50], Step [4100/7038], D Loss: 0.35073888301849365, G Loss: 1.6026945114135742\n",
      "Epoch [40/50], Step [4200/7038], D Loss: 0.56256103515625, G Loss: 1.2630800008773804\n",
      "Epoch [40/50], Step [4300/7038], D Loss: 0.2854251265525818, G Loss: 1.7874276638031006\n",
      "Epoch [40/50], Step [4400/7038], D Loss: 0.41769641637802124, G Loss: 1.412777066230774\n",
      "Epoch [40/50], Step [4500/7038], D Loss: 0.27972373366355896, G Loss: 2.097749948501587\n",
      "Epoch [40/50], Step [4600/7038], D Loss: 0.7623381018638611, G Loss: 1.167853832244873\n",
      "Epoch [40/50], Step [4700/7038], D Loss: 0.5896376371383667, G Loss: 1.184952735900879\n",
      "Epoch [40/50], Step [4800/7038], D Loss: 0.4900587797164917, G Loss: 1.3104161024093628\n",
      "Epoch [40/50], Step [4900/7038], D Loss: 0.600631833076477, G Loss: 1.2412214279174805\n",
      "Epoch [40/50], Step [5000/7038], D Loss: 0.4339412450790405, G Loss: 1.440460205078125\n",
      "Epoch [40/50], Step [5100/7038], D Loss: 0.5171078443527222, G Loss: 1.1556285619735718\n",
      "Epoch [40/50], Step [5200/7038], D Loss: 0.5618354082107544, G Loss: 1.215213656425476\n",
      "Epoch [40/50], Step [5300/7038], D Loss: 0.302425354719162, G Loss: 1.7582682371139526\n",
      "Epoch [40/50], Step [5400/7038], D Loss: 0.6471445560455322, G Loss: 1.088737964630127\n",
      "Epoch [40/50], Step [5500/7038], D Loss: 0.46347469091415405, G Loss: 1.5162955522537231\n",
      "Epoch [40/50], Step [5600/7038], D Loss: 0.5759872794151306, G Loss: 1.3153589963912964\n",
      "Epoch [40/50], Step [5700/7038], D Loss: 0.19875723123550415, G Loss: 2.024796724319458\n",
      "Epoch [40/50], Step [5800/7038], D Loss: 0.5291416645050049, G Loss: 1.197404146194458\n",
      "Epoch [40/50], Step [5900/7038], D Loss: 0.3799492120742798, G Loss: 1.4872398376464844\n",
      "Epoch [40/50], Step [6000/7038], D Loss: 0.4409010410308838, G Loss: 1.8012551069259644\n",
      "Epoch [40/50], Step [6100/7038], D Loss: 0.4702422618865967, G Loss: 1.61008882522583\n",
      "Epoch [40/50], Step [6200/7038], D Loss: 0.586502194404602, G Loss: 1.0541516542434692\n",
      "Epoch [40/50], Step [6300/7038], D Loss: 0.6340405941009521, G Loss: 1.6233104467391968\n",
      "Epoch [40/50], Step [6400/7038], D Loss: 0.35226550698280334, G Loss: 2.0416529178619385\n",
      "Epoch [40/50], Step [6500/7038], D Loss: 0.4451003074645996, G Loss: 1.2675174474716187\n",
      "Epoch [40/50], Step [6600/7038], D Loss: 0.5981945991516113, G Loss: 1.8061070442199707\n",
      "Epoch [40/50], Step [6700/7038], D Loss: 0.2764069437980652, G Loss: 1.6208137273788452\n",
      "Epoch [40/50], Step [6800/7038], D Loss: 0.3526526093482971, G Loss: 1.5613394975662231\n",
      "Epoch [40/50], Step [6900/7038], D Loss: 0.2932555079460144, G Loss: 1.7810405492782593\n",
      "Epoch [40/50], Step [7000/7038], D Loss: 0.30751359462738037, G Loss: 1.8719041347503662\n",
      "Epoch [41/50], Step [0/7038], D Loss: 0.34407755732536316, G Loss: 2.1146910190582275\n",
      "Epoch [41/50], Step [100/7038], D Loss: 0.34004366397857666, G Loss: 1.899766206741333\n",
      "Epoch [41/50], Step [200/7038], D Loss: 0.604616641998291, G Loss: 1.336049199104309\n",
      "Epoch [41/50], Step [300/7038], D Loss: 0.25592875480651855, G Loss: 2.144411563873291\n",
      "Epoch [41/50], Step [400/7038], D Loss: 0.6679275631904602, G Loss: 1.3018617630004883\n",
      "Epoch [41/50], Step [500/7038], D Loss: 0.5050135850906372, G Loss: 1.3342360258102417\n",
      "Epoch [41/50], Step [600/7038], D Loss: 0.40146201848983765, G Loss: 1.5363221168518066\n",
      "Epoch [41/50], Step [700/7038], D Loss: 0.39084911346435547, G Loss: 1.366835117340088\n",
      "Epoch [41/50], Step [800/7038], D Loss: 0.36906498670578003, G Loss: 1.4543664455413818\n",
      "Epoch [41/50], Step [900/7038], D Loss: 0.4831334054470062, G Loss: 1.1342759132385254\n",
      "Epoch [41/50], Step [1000/7038], D Loss: 0.5252301692962646, G Loss: 1.3854397535324097\n",
      "Epoch [41/50], Step [1100/7038], D Loss: 0.7398809790611267, G Loss: 1.2883721590042114\n",
      "Epoch [41/50], Step [1200/7038], D Loss: 0.5891051888465881, G Loss: 1.4168740510940552\n",
      "Epoch [41/50], Step [1300/7038], D Loss: 0.4288187325000763, G Loss: 1.538310170173645\n",
      "Epoch [41/50], Step [1400/7038], D Loss: 0.6261694431304932, G Loss: 1.7618234157562256\n",
      "Epoch [41/50], Step [1500/7038], D Loss: 0.4399341940879822, G Loss: 1.2837151288986206\n",
      "Epoch [41/50], Step [1600/7038], D Loss: 0.5845949649810791, G Loss: 1.2142120599746704\n",
      "Epoch [41/50], Step [1700/7038], D Loss: 0.49210983514785767, G Loss: 1.1712602376937866\n",
      "Epoch [41/50], Step [1800/7038], D Loss: 0.5249037146568298, G Loss: 1.4579071998596191\n",
      "Epoch [41/50], Step [1900/7038], D Loss: 0.2983908951282501, G Loss: 2.010768413543701\n",
      "Epoch [41/50], Step [2000/7038], D Loss: 0.4221307635307312, G Loss: 1.3770116567611694\n",
      "Epoch [41/50], Step [2100/7038], D Loss: 0.41958490014076233, G Loss: 1.2230210304260254\n",
      "Epoch [41/50], Step [2200/7038], D Loss: 0.6592776775360107, G Loss: 1.328111171722412\n",
      "Epoch [41/50], Step [2300/7038], D Loss: 0.44364506006240845, G Loss: 1.7005603313446045\n",
      "Epoch [41/50], Step [2400/7038], D Loss: 0.3552245795726776, G Loss: 1.7248077392578125\n",
      "Epoch [41/50], Step [2500/7038], D Loss: 0.5931434631347656, G Loss: 1.2355809211730957\n",
      "Epoch [41/50], Step [2600/7038], D Loss: 0.40193647146224976, G Loss: 1.5103517770767212\n",
      "Epoch [41/50], Step [2700/7038], D Loss: 0.42813336849212646, G Loss: 1.385825753211975\n",
      "Epoch [41/50], Step [2800/7038], D Loss: 0.8035595417022705, G Loss: 1.5226328372955322\n",
      "Epoch [41/50], Step [2900/7038], D Loss: 0.803476095199585, G Loss: 1.5934621095657349\n",
      "Epoch [41/50], Step [3000/7038], D Loss: 0.4273456335067749, G Loss: 1.8497980833053589\n",
      "Epoch [41/50], Step [3100/7038], D Loss: 0.2712870240211487, G Loss: 2.4005889892578125\n",
      "Epoch [41/50], Step [3200/7038], D Loss: 0.43571335077285767, G Loss: 1.321946144104004\n",
      "Epoch [41/50], Step [3300/7038], D Loss: 0.45973747968673706, G Loss: 1.4032319784164429\n",
      "Epoch [41/50], Step [3400/7038], D Loss: 0.40899521112442017, G Loss: 1.549044132232666\n",
      "Epoch [41/50], Step [3500/7038], D Loss: 0.5429913401603699, G Loss: 1.8188551664352417\n",
      "Epoch [41/50], Step [3600/7038], D Loss: 0.4249703884124756, G Loss: 1.8639177083969116\n",
      "Epoch [41/50], Step [3700/7038], D Loss: 0.6230037212371826, G Loss: 1.9389036893844604\n",
      "Epoch [41/50], Step [3800/7038], D Loss: 0.3677403926849365, G Loss: 1.889755368232727\n",
      "Epoch [41/50], Step [3900/7038], D Loss: 0.5837573409080505, G Loss: 1.0339562892913818\n",
      "Epoch [41/50], Step [4000/7038], D Loss: 0.4052487313747406, G Loss: 1.8422960042953491\n",
      "Epoch [41/50], Step [4100/7038], D Loss: 0.43345552682876587, G Loss: 1.8748887777328491\n",
      "Epoch [41/50], Step [4200/7038], D Loss: 0.28397536277770996, G Loss: 2.1372933387756348\n",
      "Epoch [41/50], Step [4300/7038], D Loss: 0.4069317579269409, G Loss: 1.9135210514068604\n",
      "Epoch [41/50], Step [4400/7038], D Loss: 0.5913964509963989, G Loss: 0.9742826223373413\n",
      "Epoch [41/50], Step [4500/7038], D Loss: 0.41116881370544434, G Loss: 1.3336042165756226\n",
      "Epoch [41/50], Step [4600/7038], D Loss: 0.602705717086792, G Loss: 1.5741642713546753\n",
      "Epoch [41/50], Step [4700/7038], D Loss: 0.3000888228416443, G Loss: 1.503544569015503\n",
      "Epoch [41/50], Step [4800/7038], D Loss: 0.6670787930488586, G Loss: 1.5734328031539917\n",
      "Epoch [41/50], Step [4900/7038], D Loss: 0.700272262096405, G Loss: 1.4344114065170288\n",
      "Epoch [41/50], Step [5000/7038], D Loss: 0.24246717989444733, G Loss: 1.8771860599517822\n",
      "Epoch [41/50], Step [5100/7038], D Loss: 0.7023277282714844, G Loss: 1.4059053659439087\n",
      "Epoch [41/50], Step [5200/7038], D Loss: 0.36953556537628174, G Loss: 1.7060654163360596\n",
      "Epoch [41/50], Step [5300/7038], D Loss: 0.3481711149215698, G Loss: 1.6987016201019287\n",
      "Epoch [41/50], Step [5400/7038], D Loss: 0.36001649498939514, G Loss: 1.6055245399475098\n",
      "Epoch [41/50], Step [5500/7038], D Loss: 0.6245889663696289, G Loss: 1.4544554948806763\n",
      "Epoch [41/50], Step [5600/7038], D Loss: 0.42554789781570435, G Loss: 1.4943253993988037\n",
      "Epoch [41/50], Step [5700/7038], D Loss: 0.4058307111263275, G Loss: 1.7958576679229736\n",
      "Epoch [41/50], Step [5800/7038], D Loss: 0.24879789352416992, G Loss: 2.094513416290283\n",
      "Epoch [41/50], Step [5900/7038], D Loss: 0.2789483964443207, G Loss: 1.7833257913589478\n",
      "Epoch [41/50], Step [6000/7038], D Loss: 0.454744815826416, G Loss: 1.284803032875061\n",
      "Epoch [41/50], Step [6100/7038], D Loss: 0.7269906997680664, G Loss: 1.7930463552474976\n",
      "Epoch [41/50], Step [6200/7038], D Loss: 0.34817734360694885, G Loss: 1.7180451154708862\n",
      "Epoch [41/50], Step [6300/7038], D Loss: 0.5875282287597656, G Loss: 1.1595467329025269\n",
      "Epoch [41/50], Step [6400/7038], D Loss: 0.394572377204895, G Loss: 1.5453544855117798\n",
      "Epoch [41/50], Step [6500/7038], D Loss: 0.31659135222435, G Loss: 1.6995973587036133\n",
      "Epoch [41/50], Step [6600/7038], D Loss: 0.6138372421264648, G Loss: 0.9095492362976074\n",
      "Epoch [41/50], Step [6700/7038], D Loss: 0.20339742302894592, G Loss: 2.0635712146759033\n",
      "Epoch [41/50], Step [6800/7038], D Loss: 0.3674277663230896, G Loss: 1.416366696357727\n",
      "Epoch [41/50], Step [6900/7038], D Loss: 0.4653574824333191, G Loss: 2.0732593536376953\n",
      "Epoch [41/50], Step [7000/7038], D Loss: 0.5780420303344727, G Loss: 1.7327882051467896\n",
      "Epoch [42/50], Step [0/7038], D Loss: 0.6618707180023193, G Loss: 1.271878719329834\n",
      "Epoch [42/50], Step [100/7038], D Loss: 0.37823551893234253, G Loss: 1.5567293167114258\n",
      "Epoch [42/50], Step [200/7038], D Loss: 0.33742961287498474, G Loss: 2.03173828125\n",
      "Epoch [42/50], Step [300/7038], D Loss: 0.38541507720947266, G Loss: 1.543160319328308\n",
      "Epoch [42/50], Step [400/7038], D Loss: 0.38031500577926636, G Loss: 1.5878310203552246\n",
      "Epoch [42/50], Step [500/7038], D Loss: 0.7734439373016357, G Loss: 1.4803950786590576\n",
      "Epoch [42/50], Step [600/7038], D Loss: 0.42466408014297485, G Loss: 1.531391978263855\n",
      "Epoch [42/50], Step [700/7038], D Loss: 0.570909857749939, G Loss: 2.180091381072998\n",
      "Epoch [42/50], Step [800/7038], D Loss: 0.5013746619224548, G Loss: 1.1828303337097168\n",
      "Epoch [42/50], Step [900/7038], D Loss: 0.5792154669761658, G Loss: 1.266042709350586\n",
      "Epoch [42/50], Step [1000/7038], D Loss: 0.44789111614227295, G Loss: 1.7153171300888062\n",
      "Epoch [42/50], Step [1100/7038], D Loss: 1.0705749988555908, G Loss: 1.573995590209961\n",
      "Epoch [42/50], Step [1200/7038], D Loss: 0.8926087617874146, G Loss: 1.1315040588378906\n",
      "Epoch [42/50], Step [1300/7038], D Loss: 0.4301883280277252, G Loss: 1.5503323078155518\n",
      "Epoch [42/50], Step [1400/7038], D Loss: 0.3259660601615906, G Loss: 1.7498663663864136\n",
      "Epoch [42/50], Step [1500/7038], D Loss: 0.30771973729133606, G Loss: 1.599460482597351\n",
      "Epoch [42/50], Step [1600/7038], D Loss: 0.4820435047149658, G Loss: 1.415967583656311\n",
      "Epoch [42/50], Step [1700/7038], D Loss: 0.23662301898002625, G Loss: 2.1842973232269287\n",
      "Epoch [42/50], Step [1800/7038], D Loss: 0.5936465263366699, G Loss: 1.102063775062561\n",
      "Epoch [42/50], Step [1900/7038], D Loss: 0.343022882938385, G Loss: 1.8927054405212402\n",
      "Epoch [42/50], Step [2000/7038], D Loss: 0.4548386335372925, G Loss: 1.1709058284759521\n",
      "Epoch [42/50], Step [2100/7038], D Loss: 0.2544069290161133, G Loss: 1.8598086833953857\n",
      "Epoch [42/50], Step [2200/7038], D Loss: 0.5172036290168762, G Loss: 1.817207932472229\n",
      "Epoch [42/50], Step [2300/7038], D Loss: 0.451045423746109, G Loss: 1.5521974563598633\n",
      "Epoch [42/50], Step [2400/7038], D Loss: 0.3273531198501587, G Loss: 1.5986005067825317\n",
      "Epoch [42/50], Step [2500/7038], D Loss: 0.6418660879135132, G Loss: 1.3167694807052612\n",
      "Epoch [42/50], Step [2600/7038], D Loss: 0.4163496196269989, G Loss: 1.3319700956344604\n",
      "Epoch [42/50], Step [2700/7038], D Loss: 0.4982941150665283, G Loss: 1.5256918668746948\n",
      "Epoch [42/50], Step [2800/7038], D Loss: 0.38605719804763794, G Loss: 1.4001339673995972\n",
      "Epoch [42/50], Step [2900/7038], D Loss: 0.6146963834762573, G Loss: 1.6200168132781982\n",
      "Epoch [42/50], Step [3000/7038], D Loss: 0.30147379636764526, G Loss: 1.8186328411102295\n",
      "Epoch [42/50], Step [3100/7038], D Loss: 0.444858193397522, G Loss: 1.6692403554916382\n",
      "Epoch [42/50], Step [3200/7038], D Loss: 0.31215599179267883, G Loss: 1.4607733488082886\n",
      "Epoch [42/50], Step [3300/7038], D Loss: 0.26611194014549255, G Loss: 1.6222282648086548\n",
      "Epoch [42/50], Step [3400/7038], D Loss: 0.7495914697647095, G Loss: 1.49748694896698\n",
      "Epoch [42/50], Step [3500/7038], D Loss: 0.3862922191619873, G Loss: 1.474961280822754\n",
      "Epoch [42/50], Step [3600/7038], D Loss: 0.4105868935585022, G Loss: 1.8404734134674072\n",
      "Epoch [42/50], Step [3700/7038], D Loss: 0.2928093671798706, G Loss: 1.6964913606643677\n",
      "Epoch [42/50], Step [3800/7038], D Loss: 0.3052634000778198, G Loss: 1.9678688049316406\n",
      "Epoch [42/50], Step [3900/7038], D Loss: 0.5964148044586182, G Loss: 1.6367567777633667\n",
      "Epoch [42/50], Step [4000/7038], D Loss: 0.4676022529602051, G Loss: 1.3697988986968994\n",
      "Epoch [42/50], Step [4100/7038], D Loss: 0.6416453719139099, G Loss: 1.5829561948776245\n",
      "Epoch [42/50], Step [4200/7038], D Loss: 0.583918571472168, G Loss: 1.1873177289962769\n",
      "Epoch [42/50], Step [4300/7038], D Loss: 0.39534178376197815, G Loss: 1.3664228916168213\n",
      "Epoch [42/50], Step [4400/7038], D Loss: 0.527805507183075, G Loss: 1.4510174989700317\n",
      "Epoch [42/50], Step [4500/7038], D Loss: 0.43480241298675537, G Loss: 1.4629640579223633\n",
      "Epoch [42/50], Step [4600/7038], D Loss: 0.46809250116348267, G Loss: 1.4708195924758911\n",
      "Epoch [42/50], Step [4700/7038], D Loss: 0.6219857931137085, G Loss: 1.5665172338485718\n",
      "Epoch [42/50], Step [4800/7038], D Loss: 0.3941558003425598, G Loss: 1.2935081720352173\n",
      "Epoch [42/50], Step [4900/7038], D Loss: 0.5290664434432983, G Loss: 1.2680038213729858\n",
      "Epoch [42/50], Step [5000/7038], D Loss: 0.4893202483654022, G Loss: 1.2636572122573853\n",
      "Epoch [42/50], Step [5100/7038], D Loss: 0.5651860237121582, G Loss: 1.2884776592254639\n",
      "Epoch [42/50], Step [5200/7038], D Loss: 0.42729485034942627, G Loss: 1.3996849060058594\n",
      "Epoch [42/50], Step [5300/7038], D Loss: 0.46773409843444824, G Loss: 1.2410246133804321\n",
      "Epoch [42/50], Step [5400/7038], D Loss: 0.48180294036865234, G Loss: 1.6707972288131714\n",
      "Epoch [42/50], Step [5500/7038], D Loss: 0.41668036580085754, G Loss: 1.721734642982483\n",
      "Epoch [42/50], Step [5600/7038], D Loss: 0.37245315313339233, G Loss: 1.6316369771957397\n",
      "Epoch [42/50], Step [5700/7038], D Loss: 0.29499754309654236, G Loss: 1.8803402185440063\n",
      "Epoch [42/50], Step [5800/7038], D Loss: 0.44291451573371887, G Loss: 1.4659854173660278\n",
      "Epoch [42/50], Step [5900/7038], D Loss: 0.40751421451568604, G Loss: 1.3609975576400757\n",
      "Epoch [42/50], Step [6000/7038], D Loss: 0.48676609992980957, G Loss: 1.5720747709274292\n",
      "Epoch [42/50], Step [6100/7038], D Loss: 0.6856822967529297, G Loss: 0.8735288381576538\n",
      "Epoch [42/50], Step [6200/7038], D Loss: 0.43117403984069824, G Loss: 1.9279894828796387\n",
      "Epoch [42/50], Step [6300/7038], D Loss: 0.2464788556098938, G Loss: 1.6641415357589722\n",
      "Epoch [42/50], Step [6400/7038], D Loss: 0.43725624680519104, G Loss: 1.6418894529342651\n",
      "Epoch [42/50], Step [6500/7038], D Loss: 0.5728031396865845, G Loss: 1.4993342161178589\n",
      "Epoch [42/50], Step [6600/7038], D Loss: 0.3750075101852417, G Loss: 1.7621383666992188\n",
      "Epoch [42/50], Step [6700/7038], D Loss: 0.40866920351982117, G Loss: 1.5126465559005737\n",
      "Epoch [42/50], Step [6800/7038], D Loss: 0.21251198649406433, G Loss: 1.7957351207733154\n",
      "Epoch [42/50], Step [6900/7038], D Loss: 0.6438785195350647, G Loss: 1.3967254161834717\n",
      "Epoch [42/50], Step [7000/7038], D Loss: 0.4598844051361084, G Loss: 1.6425378322601318\n",
      "Epoch [43/50], Step [0/7038], D Loss: 0.6908261179924011, G Loss: 1.9106018543243408\n",
      "Epoch [43/50], Step [100/7038], D Loss: 0.6256161332130432, G Loss: 0.9251091480255127\n",
      "Epoch [43/50], Step [200/7038], D Loss: 0.783626139163971, G Loss: 1.3167892694473267\n",
      "Epoch [43/50], Step [300/7038], D Loss: 0.7873901128768921, G Loss: 1.4645342826843262\n",
      "Epoch [43/50], Step [400/7038], D Loss: 0.2353101372718811, G Loss: 2.044510841369629\n",
      "Epoch [43/50], Step [500/7038], D Loss: 0.48300597071647644, G Loss: 1.7892452478408813\n",
      "Epoch [43/50], Step [600/7038], D Loss: 0.4246174395084381, G Loss: 1.9248045682907104\n",
      "Epoch [43/50], Step [700/7038], D Loss: 0.5439127683639526, G Loss: 1.4801918268203735\n",
      "Epoch [43/50], Step [800/7038], D Loss: 0.422155499458313, G Loss: 1.69916832447052\n",
      "Epoch [43/50], Step [900/7038], D Loss: 0.5169967412948608, G Loss: 1.4099904298782349\n",
      "Epoch [43/50], Step [1000/7038], D Loss: 0.2518565356731415, G Loss: 2.044290065765381\n",
      "Epoch [43/50], Step [1100/7038], D Loss: 0.48912185430526733, G Loss: 1.5531760454177856\n",
      "Epoch [43/50], Step [1200/7038], D Loss: 0.644443690776825, G Loss: 1.4680153131484985\n",
      "Epoch [43/50], Step [1300/7038], D Loss: 0.3268939256668091, G Loss: 1.854799509048462\n",
      "Epoch [43/50], Step [1400/7038], D Loss: 0.45658454298973083, G Loss: 1.4126088619232178\n",
      "Epoch [43/50], Step [1500/7038], D Loss: 0.3922295570373535, G Loss: 1.6929380893707275\n",
      "Epoch [43/50], Step [1600/7038], D Loss: 0.3012925386428833, G Loss: 1.7653058767318726\n",
      "Epoch [43/50], Step [1700/7038], D Loss: 0.567321240901947, G Loss: 1.644258975982666\n",
      "Epoch [43/50], Step [1800/7038], D Loss: 1.6726868152618408, G Loss: 1.056627631187439\n",
      "Epoch [43/50], Step [1900/7038], D Loss: 0.5281368494033813, G Loss: 1.9676932096481323\n",
      "Epoch [43/50], Step [2000/7038], D Loss: 0.39554348587989807, G Loss: 1.5506479740142822\n",
      "Epoch [43/50], Step [2100/7038], D Loss: 0.4414832293987274, G Loss: 1.3110805749893188\n",
      "Epoch [43/50], Step [2200/7038], D Loss: 0.3916228413581848, G Loss: 1.8946857452392578\n",
      "Epoch [43/50], Step [2300/7038], D Loss: 0.5808097124099731, G Loss: 1.4935160875320435\n",
      "Epoch [43/50], Step [2400/7038], D Loss: 0.4341990351676941, G Loss: 1.4792656898498535\n",
      "Epoch [43/50], Step [2500/7038], D Loss: 0.6586891412734985, G Loss: 1.7764724493026733\n",
      "Epoch [43/50], Step [2600/7038], D Loss: 0.4454925060272217, G Loss: 1.4539083242416382\n",
      "Epoch [43/50], Step [2700/7038], D Loss: 0.5221889615058899, G Loss: 1.3961502313613892\n",
      "Epoch [43/50], Step [2800/7038], D Loss: 0.5711058378219604, G Loss: 1.760269284248352\n",
      "Epoch [43/50], Step [2900/7038], D Loss: 0.3834148645401001, G Loss: 1.6449244022369385\n",
      "Epoch [43/50], Step [3000/7038], D Loss: 1.1463812589645386, G Loss: 1.812060832977295\n",
      "Epoch [43/50], Step [3100/7038], D Loss: 0.6742290258407593, G Loss: 1.1194517612457275\n",
      "Epoch [43/50], Step [3200/7038], D Loss: 1.1015031337738037, G Loss: 1.011513352394104\n",
      "Epoch [43/50], Step [3300/7038], D Loss: 0.2963348925113678, G Loss: 1.579795002937317\n",
      "Epoch [43/50], Step [3400/7038], D Loss: 0.3414457440376282, G Loss: 1.783461332321167\n",
      "Epoch [43/50], Step [3500/7038], D Loss: 0.3705345094203949, G Loss: 1.7041045427322388\n",
      "Epoch [43/50], Step [3600/7038], D Loss: 0.3007732033729553, G Loss: 1.66071355342865\n",
      "Epoch [43/50], Step [3700/7038], D Loss: 0.9095474481582642, G Loss: 1.843202829360962\n",
      "Epoch [43/50], Step [3800/7038], D Loss: 0.48270928859710693, G Loss: 1.4154404401779175\n",
      "Epoch [43/50], Step [3900/7038], D Loss: 0.44193315505981445, G Loss: 1.5103089809417725\n",
      "Epoch [43/50], Step [4000/7038], D Loss: 0.5048604011535645, G Loss: 1.6443454027175903\n",
      "Epoch [43/50], Step [4100/7038], D Loss: 0.42798322439193726, G Loss: 1.2801997661590576\n",
      "Epoch [43/50], Step [4200/7038], D Loss: 0.49484288692474365, G Loss: 1.2696824073791504\n",
      "Epoch [43/50], Step [4300/7038], D Loss: 0.377473384141922, G Loss: 2.031512498855591\n",
      "Epoch [43/50], Step [4400/7038], D Loss: 0.4429602324962616, G Loss: 1.5609444379806519\n",
      "Epoch [43/50], Step [4500/7038], D Loss: 0.3335442841053009, G Loss: 1.7637590169906616\n",
      "Epoch [43/50], Step [4600/7038], D Loss: 0.3499860167503357, G Loss: 1.6451793909072876\n",
      "Epoch [43/50], Step [4700/7038], D Loss: 0.780307412147522, G Loss: 1.8709142208099365\n",
      "Epoch [43/50], Step [4800/7038], D Loss: 0.5195748805999756, G Loss: 1.3441665172576904\n",
      "Epoch [43/50], Step [4900/7038], D Loss: 0.43492716550827026, G Loss: 1.3711018562316895\n",
      "Epoch [43/50], Step [5000/7038], D Loss: 0.49790358543395996, G Loss: 1.3149346113204956\n",
      "Epoch [43/50], Step [5100/7038], D Loss: 0.572375476360321, G Loss: 1.3516076803207397\n",
      "Epoch [43/50], Step [5200/7038], D Loss: 0.7122437357902527, G Loss: 0.9688594341278076\n",
      "Epoch [43/50], Step [5300/7038], D Loss: 0.47335708141326904, G Loss: 1.6987102031707764\n",
      "Epoch [43/50], Step [5400/7038], D Loss: 0.5102840662002563, G Loss: 1.6540672779083252\n",
      "Epoch [43/50], Step [5500/7038], D Loss: 0.3511224687099457, G Loss: 1.5453181266784668\n",
      "Epoch [43/50], Step [5600/7038], D Loss: 0.5548267364501953, G Loss: 1.558992624282837\n",
      "Epoch [43/50], Step [5700/7038], D Loss: 0.5966976881027222, G Loss: 1.5643658638000488\n",
      "Epoch [43/50], Step [5800/7038], D Loss: 0.39717844128608704, G Loss: 1.5866076946258545\n",
      "Epoch [43/50], Step [5900/7038], D Loss: 0.547539234161377, G Loss: 1.1441198587417603\n",
      "Epoch [43/50], Step [6000/7038], D Loss: 0.32475197315216064, G Loss: 1.5820081233978271\n",
      "Epoch [43/50], Step [6100/7038], D Loss: 0.5561862587928772, G Loss: 1.3706313371658325\n",
      "Epoch [43/50], Step [6200/7038], D Loss: 0.7022843956947327, G Loss: 1.0127830505371094\n",
      "Epoch [43/50], Step [6300/7038], D Loss: 0.6798272728919983, G Loss: 2.4807040691375732\n",
      "Epoch [43/50], Step [6400/7038], D Loss: 0.6181170344352722, G Loss: 1.1936099529266357\n",
      "Epoch [43/50], Step [6500/7038], D Loss: 0.3297300934791565, G Loss: 2.6830227375030518\n",
      "Epoch [43/50], Step [6600/7038], D Loss: 0.41057783365249634, G Loss: 1.4597920179367065\n",
      "Epoch [43/50], Step [6700/7038], D Loss: 0.3559870421886444, G Loss: 1.3643946647644043\n",
      "Epoch [43/50], Step [6800/7038], D Loss: 0.5620728135108948, G Loss: 1.3539880514144897\n",
      "Epoch [43/50], Step [6900/7038], D Loss: 0.42250198125839233, G Loss: 1.7728705406188965\n",
      "Epoch [43/50], Step [7000/7038], D Loss: 0.47327905893325806, G Loss: 1.2722606658935547\n",
      "Epoch [44/50], Step [0/7038], D Loss: 0.4589056372642517, G Loss: 2.057619333267212\n",
      "Epoch [44/50], Step [100/7038], D Loss: 0.6398904323577881, G Loss: 1.5921564102172852\n",
      "Epoch [44/50], Step [200/7038], D Loss: 0.35684001445770264, G Loss: 1.7245452404022217\n",
      "Epoch [44/50], Step [300/7038], D Loss: 0.3284015357494354, G Loss: 1.6168928146362305\n",
      "Epoch [44/50], Step [400/7038], D Loss: 0.48395058512687683, G Loss: 1.318315863609314\n",
      "Epoch [44/50], Step [500/7038], D Loss: 0.3528989255428314, G Loss: 1.6597973108291626\n",
      "Epoch [44/50], Step [600/7038], D Loss: 0.577286958694458, G Loss: 1.0378217697143555\n",
      "Epoch [44/50], Step [700/7038], D Loss: 0.38739854097366333, G Loss: 1.9381957054138184\n",
      "Epoch [44/50], Step [800/7038], D Loss: 0.43939927220344543, G Loss: 1.5153979063034058\n",
      "Epoch [44/50], Step [900/7038], D Loss: 0.33728963136672974, G Loss: 1.4920551776885986\n",
      "Epoch [44/50], Step [1000/7038], D Loss: 0.5167335271835327, G Loss: 1.5703729391098022\n",
      "Epoch [44/50], Step [1100/7038], D Loss: 0.7431907653808594, G Loss: 1.0421260595321655\n",
      "Epoch [44/50], Step [1200/7038], D Loss: 0.3451550006866455, G Loss: 1.8880671262741089\n",
      "Epoch [44/50], Step [1300/7038], D Loss: 0.7258152961730957, G Loss: 1.1384756565093994\n",
      "Epoch [44/50], Step [1400/7038], D Loss: 0.25779789686203003, G Loss: 1.923876166343689\n",
      "Epoch [44/50], Step [1500/7038], D Loss: 0.5044689178466797, G Loss: 1.799432635307312\n",
      "Epoch [44/50], Step [1600/7038], D Loss: 0.2619485557079315, G Loss: 1.8427234888076782\n",
      "Epoch [44/50], Step [1700/7038], D Loss: 0.3911033570766449, G Loss: 1.885527491569519\n",
      "Epoch [44/50], Step [1800/7038], D Loss: 0.47501349449157715, G Loss: 1.3937184810638428\n",
      "Epoch [44/50], Step [1900/7038], D Loss: 0.5134716629981995, G Loss: 2.0807862281799316\n",
      "Epoch [44/50], Step [2000/7038], D Loss: 0.5542753338813782, G Loss: 1.2376015186309814\n",
      "Epoch [44/50], Step [2100/7038], D Loss: 0.5960626602172852, G Loss: 1.3003597259521484\n",
      "Epoch [44/50], Step [2200/7038], D Loss: 0.35735732316970825, G Loss: 2.2638275623321533\n",
      "Epoch [44/50], Step [2300/7038], D Loss: 0.3734534680843353, G Loss: 1.4078762531280518\n",
      "Epoch [44/50], Step [2400/7038], D Loss: 0.5454914569854736, G Loss: 1.33991539478302\n",
      "Epoch [44/50], Step [2500/7038], D Loss: 0.8203707933425903, G Loss: 1.5364787578582764\n",
      "Epoch [44/50], Step [2600/7038], D Loss: 0.538855254650116, G Loss: 1.4795117378234863\n",
      "Epoch [44/50], Step [2700/7038], D Loss: 0.6680164337158203, G Loss: 1.3664687871932983\n",
      "Epoch [44/50], Step [2800/7038], D Loss: 0.3369622826576233, G Loss: 1.395349383354187\n",
      "Epoch [44/50], Step [2900/7038], D Loss: 0.5282585620880127, G Loss: 1.3059464693069458\n",
      "Epoch [44/50], Step [3000/7038], D Loss: 0.4205036461353302, G Loss: 1.6812771558761597\n",
      "Epoch [44/50], Step [3100/7038], D Loss: 0.4859362840652466, G Loss: 1.4288934469223022\n",
      "Epoch [44/50], Step [3200/7038], D Loss: 0.31144312024116516, G Loss: 1.2826173305511475\n",
      "Epoch [44/50], Step [3300/7038], D Loss: 0.3919700086116791, G Loss: 1.6654658317565918\n",
      "Epoch [44/50], Step [3400/7038], D Loss: 0.6499109864234924, G Loss: 1.48123300075531\n",
      "Epoch [44/50], Step [3500/7038], D Loss: 0.4401679039001465, G Loss: 1.2925925254821777\n",
      "Epoch [44/50], Step [3600/7038], D Loss: 0.6599639654159546, G Loss: 1.2910782098770142\n",
      "Epoch [44/50], Step [3700/7038], D Loss: 0.6855242252349854, G Loss: 1.3474942445755005\n",
      "Epoch [44/50], Step [3800/7038], D Loss: 0.400113970041275, G Loss: 1.670691967010498\n",
      "Epoch [44/50], Step [3900/7038], D Loss: 0.40755796432495117, G Loss: 1.2899508476257324\n",
      "Epoch [44/50], Step [4000/7038], D Loss: 0.5664318799972534, G Loss: 1.4615398645401\n",
      "Epoch [44/50], Step [4100/7038], D Loss: 0.47300297021865845, G Loss: 1.5068987607955933\n",
      "Epoch [44/50], Step [4200/7038], D Loss: 0.5098045468330383, G Loss: 1.3182461261749268\n",
      "Epoch [44/50], Step [4300/7038], D Loss: 0.34887927770614624, G Loss: 1.8116250038146973\n",
      "Epoch [44/50], Step [4400/7038], D Loss: 0.40939199924468994, G Loss: 1.6965612173080444\n",
      "Epoch [44/50], Step [4500/7038], D Loss: 0.3517661690711975, G Loss: 1.7797911167144775\n",
      "Epoch [44/50], Step [4600/7038], D Loss: 0.4862990379333496, G Loss: 1.5616073608398438\n",
      "Epoch [44/50], Step [4700/7038], D Loss: 0.47602030634880066, G Loss: 1.2736948728561401\n",
      "Epoch [44/50], Step [4800/7038], D Loss: 0.36174097657203674, G Loss: 1.6698493957519531\n",
      "Epoch [44/50], Step [4900/7038], D Loss: 0.3315846920013428, G Loss: 1.8916678428649902\n",
      "Epoch [44/50], Step [5000/7038], D Loss: 0.7042499780654907, G Loss: 1.5392385721206665\n",
      "Epoch [44/50], Step [5100/7038], D Loss: 0.4836080074310303, G Loss: 1.5083740949630737\n",
      "Epoch [44/50], Step [5200/7038], D Loss: 0.6742371916770935, G Loss: 0.9685198068618774\n",
      "Epoch [44/50], Step [5300/7038], D Loss: 0.385439395904541, G Loss: 1.659088373184204\n",
      "Epoch [44/50], Step [5400/7038], D Loss: 0.6249479651451111, G Loss: 1.5714815855026245\n",
      "Epoch [44/50], Step [5500/7038], D Loss: 0.7270598411560059, G Loss: 0.7450776696205139\n",
      "Epoch [44/50], Step [5600/7038], D Loss: 0.3757198750972748, G Loss: 1.4584150314331055\n",
      "Epoch [44/50], Step [5700/7038], D Loss: 0.3750538229942322, G Loss: 1.2828283309936523\n",
      "Epoch [44/50], Step [5800/7038], D Loss: 0.357595831155777, G Loss: 1.4252761602401733\n",
      "Epoch [44/50], Step [5900/7038], D Loss: 0.2898121476173401, G Loss: 1.914082407951355\n",
      "Epoch [44/50], Step [6000/7038], D Loss: 0.5546033382415771, G Loss: 1.7608749866485596\n",
      "Epoch [44/50], Step [6100/7038], D Loss: 0.5534682273864746, G Loss: 1.6125651597976685\n",
      "Epoch [44/50], Step [6200/7038], D Loss: 0.2667295038700104, G Loss: 1.6827491521835327\n",
      "Epoch [44/50], Step [6300/7038], D Loss: 0.6211239099502563, G Loss: 1.1640853881835938\n",
      "Epoch [44/50], Step [6400/7038], D Loss: 0.41734910011291504, G Loss: 2.0329508781433105\n",
      "Epoch [44/50], Step [6500/7038], D Loss: 0.31246417760849, G Loss: 1.5425244569778442\n",
      "Epoch [44/50], Step [6600/7038], D Loss: 0.3684340715408325, G Loss: 1.5012348890304565\n",
      "Epoch [44/50], Step [6700/7038], D Loss: 0.4676130712032318, G Loss: 1.6950792074203491\n",
      "Epoch [44/50], Step [6800/7038], D Loss: 0.6616488099098206, G Loss: 1.5975444316864014\n",
      "Epoch [44/50], Step [6900/7038], D Loss: 0.6205452084541321, G Loss: 1.7911313772201538\n",
      "Epoch [44/50], Step [7000/7038], D Loss: 0.4491981565952301, G Loss: 1.8804404735565186\n",
      "Epoch [45/50], Step [0/7038], D Loss: 0.40547916293144226, G Loss: 1.3947187662124634\n",
      "Epoch [45/50], Step [100/7038], D Loss: 0.45116931200027466, G Loss: 1.4852527379989624\n",
      "Epoch [45/50], Step [200/7038], D Loss: 0.5673603415489197, G Loss: 1.4585506916046143\n",
      "Epoch [45/50], Step [300/7038], D Loss: 0.38762417435646057, G Loss: 1.490394949913025\n",
      "Epoch [45/50], Step [400/7038], D Loss: 0.5123600959777832, G Loss: 1.5302088260650635\n",
      "Epoch [45/50], Step [500/7038], D Loss: 0.36865952610969543, G Loss: 1.6005172729492188\n",
      "Epoch [45/50], Step [600/7038], D Loss: 0.4481126070022583, G Loss: 1.8691785335540771\n",
      "Epoch [45/50], Step [700/7038], D Loss: 0.636446475982666, G Loss: 0.9848155379295349\n",
      "Epoch [45/50], Step [800/7038], D Loss: 0.48055338859558105, G Loss: 1.1144832372665405\n",
      "Epoch [45/50], Step [900/7038], D Loss: 0.4053317904472351, G Loss: 1.4059624671936035\n",
      "Epoch [45/50], Step [1000/7038], D Loss: 0.6089992523193359, G Loss: 2.254243850708008\n",
      "Epoch [45/50], Step [1100/7038], D Loss: 0.4946046471595764, G Loss: 1.4806627035140991\n",
      "Epoch [45/50], Step [1200/7038], D Loss: 0.3932412266731262, G Loss: 1.8490873575210571\n",
      "Epoch [45/50], Step [1300/7038], D Loss: 0.43157660961151123, G Loss: 1.7333059310913086\n",
      "Epoch [45/50], Step [1400/7038], D Loss: 0.32593756914138794, G Loss: 1.7132388353347778\n",
      "Epoch [45/50], Step [1500/7038], D Loss: 0.4558762311935425, G Loss: 1.7438693046569824\n",
      "Epoch [45/50], Step [1600/7038], D Loss: 0.5776931047439575, G Loss: 1.4917373657226562\n",
      "Epoch [45/50], Step [1700/7038], D Loss: 0.561769962310791, G Loss: 1.3084375858306885\n",
      "Epoch [45/50], Step [1800/7038], D Loss: 0.3948059380054474, G Loss: 1.6086686849594116\n",
      "Epoch [45/50], Step [1900/7038], D Loss: 0.3403860628604889, G Loss: 1.7622040510177612\n",
      "Epoch [45/50], Step [2000/7038], D Loss: 0.43354928493499756, G Loss: 2.0193536281585693\n",
      "Epoch [45/50], Step [2100/7038], D Loss: 0.3821696937084198, G Loss: 1.7682658433914185\n",
      "Epoch [45/50], Step [2200/7038], D Loss: 0.6426339149475098, G Loss: 1.330746054649353\n",
      "Epoch [45/50], Step [2300/7038], D Loss: 0.5689682364463806, G Loss: 1.2602124214172363\n",
      "Epoch [45/50], Step [2400/7038], D Loss: 0.5107292532920837, G Loss: 1.5241045951843262\n",
      "Epoch [45/50], Step [2500/7038], D Loss: 0.5475469827651978, G Loss: 1.2004390954971313\n",
      "Epoch [45/50], Step [2600/7038], D Loss: 0.4908137321472168, G Loss: 1.5630131959915161\n",
      "Epoch [45/50], Step [2700/7038], D Loss: 0.3393155336380005, G Loss: 1.6267255544662476\n",
      "Epoch [45/50], Step [2800/7038], D Loss: 0.5215912461280823, G Loss: 1.163017988204956\n",
      "Epoch [45/50], Step [2900/7038], D Loss: 0.3787103295326233, G Loss: 1.2670403718948364\n",
      "Epoch [45/50], Step [3000/7038], D Loss: 0.7875378727912903, G Loss: 1.18796968460083\n",
      "Epoch [45/50], Step [3100/7038], D Loss: 0.6629536151885986, G Loss: 1.592203974723816\n",
      "Epoch [45/50], Step [3200/7038], D Loss: 0.4281785190105438, G Loss: 1.9921324253082275\n",
      "Epoch [45/50], Step [3300/7038], D Loss: 0.5809813737869263, G Loss: 1.4886293411254883\n",
      "Epoch [45/50], Step [3400/7038], D Loss: 0.2000725120306015, G Loss: 2.0188915729522705\n",
      "Epoch [45/50], Step [3500/7038], D Loss: 0.36814257502555847, G Loss: 2.0646533966064453\n",
      "Epoch [45/50], Step [3600/7038], D Loss: 0.7352569699287415, G Loss: 1.6227351427078247\n",
      "Epoch [45/50], Step [3700/7038], D Loss: 0.37432464957237244, G Loss: 1.6812552213668823\n",
      "Epoch [45/50], Step [3800/7038], D Loss: 0.20246274769306183, G Loss: 2.2204196453094482\n",
      "Epoch [45/50], Step [3900/7038], D Loss: 0.3455648422241211, G Loss: 1.6464112997055054\n",
      "Epoch [45/50], Step [4000/7038], D Loss: 0.7388772964477539, G Loss: 2.050257444381714\n",
      "Epoch [45/50], Step [4100/7038], D Loss: 0.4027056097984314, G Loss: 1.8319343328475952\n",
      "Epoch [45/50], Step [4200/7038], D Loss: 0.5690388083457947, G Loss: 1.4336905479431152\n",
      "Epoch [45/50], Step [4300/7038], D Loss: 0.6026420593261719, G Loss: 1.4267032146453857\n",
      "Epoch [45/50], Step [4400/7038], D Loss: 0.28135770559310913, G Loss: 1.9036005735397339\n",
      "Epoch [45/50], Step [4500/7038], D Loss: 0.5937963724136353, G Loss: 1.2639163732528687\n",
      "Epoch [45/50], Step [4600/7038], D Loss: 0.4665031433105469, G Loss: 1.4222747087478638\n",
      "Epoch [45/50], Step [4700/7038], D Loss: 0.3954692780971527, G Loss: 2.044495105743408\n",
      "Epoch [45/50], Step [4800/7038], D Loss: 0.47423768043518066, G Loss: 1.4060615301132202\n",
      "Epoch [45/50], Step [4900/7038], D Loss: 0.3432851731777191, G Loss: 1.8548285961151123\n",
      "Epoch [45/50], Step [5000/7038], D Loss: 0.3796623647212982, G Loss: 1.3308334350585938\n",
      "Epoch [45/50], Step [5100/7038], D Loss: 0.30439138412475586, G Loss: 1.6890208721160889\n",
      "Epoch [45/50], Step [5200/7038], D Loss: 0.36225196719169617, G Loss: 1.7581690549850464\n",
      "Epoch [45/50], Step [5300/7038], D Loss: 0.5179266333580017, G Loss: 1.2441667318344116\n",
      "Epoch [45/50], Step [5400/7038], D Loss: 0.3045808970928192, G Loss: 1.7855830192565918\n",
      "Epoch [45/50], Step [5500/7038], D Loss: 0.8279101252555847, G Loss: 1.5429315567016602\n",
      "Epoch [45/50], Step [5600/7038], D Loss: 0.4518839716911316, G Loss: 1.40910005569458\n",
      "Epoch [45/50], Step [5700/7038], D Loss: 0.6643560528755188, G Loss: 1.3487015962600708\n",
      "Epoch [45/50], Step [5800/7038], D Loss: 0.3807471692562103, G Loss: 1.463799238204956\n",
      "Epoch [45/50], Step [5900/7038], D Loss: 0.33697885274887085, G Loss: 1.5507773160934448\n",
      "Epoch [45/50], Step [6000/7038], D Loss: 0.23108643293380737, G Loss: 2.201603412628174\n",
      "Epoch [45/50], Step [6100/7038], D Loss: 0.5884140729904175, G Loss: 1.6529377698898315\n",
      "Epoch [45/50], Step [6200/7038], D Loss: 0.39554089307785034, G Loss: 1.4098566770553589\n",
      "Epoch [45/50], Step [6300/7038], D Loss: 0.3265168368816376, G Loss: 1.63137948513031\n",
      "Epoch [45/50], Step [6400/7038], D Loss: 0.64210045337677, G Loss: 1.361986517906189\n",
      "Epoch [45/50], Step [6500/7038], D Loss: 0.3900323212146759, G Loss: 1.4481111764907837\n",
      "Epoch [45/50], Step [6600/7038], D Loss: 0.49717041850090027, G Loss: 1.6696940660476685\n",
      "Epoch [45/50], Step [6700/7038], D Loss: 0.49337348341941833, G Loss: 1.3246020078659058\n",
      "Epoch [45/50], Step [6800/7038], D Loss: 0.42199546098709106, G Loss: 1.5740222930908203\n",
      "Epoch [45/50], Step [6900/7038], D Loss: 0.5495138168334961, G Loss: 1.2979215383529663\n",
      "Epoch [45/50], Step [7000/7038], D Loss: 0.36559996008872986, G Loss: 1.5644688606262207\n",
      "Epoch [46/50], Step [0/7038], D Loss: 0.7219438552856445, G Loss: 0.9954331517219543\n",
      "Epoch [46/50], Step [100/7038], D Loss: 0.34369874000549316, G Loss: 1.6493580341339111\n",
      "Epoch [46/50], Step [200/7038], D Loss: 0.4369834065437317, G Loss: 1.3624597787857056\n",
      "Epoch [46/50], Step [300/7038], D Loss: 0.38120466470718384, G Loss: 1.195356011390686\n",
      "Epoch [46/50], Step [400/7038], D Loss: 0.5828637480735779, G Loss: 1.299351692199707\n",
      "Epoch [46/50], Step [500/7038], D Loss: 0.5103241801261902, G Loss: 1.4568264484405518\n",
      "Epoch [46/50], Step [600/7038], D Loss: 0.3596131205558777, G Loss: 1.5766371488571167\n",
      "Epoch [46/50], Step [700/7038], D Loss: 0.3425807058811188, G Loss: 1.7399778366088867\n",
      "Epoch [46/50], Step [800/7038], D Loss: 0.7123538255691528, G Loss: 3.375948905944824\n",
      "Epoch [46/50], Step [900/7038], D Loss: 0.3509491980075836, G Loss: 1.5822978019714355\n",
      "Epoch [46/50], Step [1000/7038], D Loss: 0.6347028613090515, G Loss: 1.3205835819244385\n",
      "Epoch [46/50], Step [1100/7038], D Loss: 0.38520151376724243, G Loss: 1.521335482597351\n",
      "Epoch [46/50], Step [1200/7038], D Loss: 0.44369396567344666, G Loss: 1.423081874847412\n",
      "Epoch [46/50], Step [1300/7038], D Loss: 0.2573346197605133, G Loss: 1.5612126588821411\n",
      "Epoch [46/50], Step [1400/7038], D Loss: 0.5567421913146973, G Loss: 2.3109092712402344\n",
      "Epoch [46/50], Step [1500/7038], D Loss: 0.45091909170150757, G Loss: 1.483117938041687\n",
      "Epoch [46/50], Step [1600/7038], D Loss: 0.34979140758514404, G Loss: 1.762952208518982\n",
      "Epoch [46/50], Step [1700/7038], D Loss: 0.3299342095851898, G Loss: 1.8365203142166138\n",
      "Epoch [46/50], Step [1800/7038], D Loss: 0.6571773290634155, G Loss: 1.916011929512024\n",
      "Epoch [46/50], Step [1900/7038], D Loss: 0.414463609457016, G Loss: 1.5768734216690063\n",
      "Epoch [46/50], Step [2000/7038], D Loss: 0.45049944519996643, G Loss: 1.2946182489395142\n",
      "Epoch [46/50], Step [2100/7038], D Loss: 0.4943385124206543, G Loss: 1.52810800075531\n",
      "Epoch [46/50], Step [2200/7038], D Loss: 0.645412802696228, G Loss: 1.3470704555511475\n",
      "Epoch [46/50], Step [2300/7038], D Loss: 0.3961522579193115, G Loss: 1.6474106311798096\n",
      "Epoch [46/50], Step [2400/7038], D Loss: 0.43693092465400696, G Loss: 1.4752992391586304\n",
      "Epoch [46/50], Step [2500/7038], D Loss: 0.5554206371307373, G Loss: 1.3997095823287964\n",
      "Epoch [46/50], Step [2600/7038], D Loss: 0.3834100365638733, G Loss: 1.5738134384155273\n",
      "Epoch [46/50], Step [2700/7038], D Loss: 0.25034838914871216, G Loss: 1.7993344068527222\n",
      "Epoch [46/50], Step [2800/7038], D Loss: 0.5346845388412476, G Loss: 1.3171343803405762\n",
      "Epoch [46/50], Step [2900/7038], D Loss: 0.282438725233078, G Loss: 1.785933256149292\n",
      "Epoch [46/50], Step [3000/7038], D Loss: 0.5137383937835693, G Loss: 1.3994297981262207\n",
      "Epoch [46/50], Step [3100/7038], D Loss: 0.6924598217010498, G Loss: 1.1381795406341553\n",
      "Epoch [46/50], Step [3200/7038], D Loss: 0.3229654133319855, G Loss: 1.7362098693847656\n",
      "Epoch [46/50], Step [3300/7038], D Loss: 0.3697718679904938, G Loss: 1.5419977903366089\n",
      "Epoch [46/50], Step [3400/7038], D Loss: 0.4420744776725769, G Loss: 1.3783586025238037\n",
      "Epoch [46/50], Step [3500/7038], D Loss: 0.32262587547302246, G Loss: 1.711341381072998\n",
      "Epoch [46/50], Step [3600/7038], D Loss: 0.5719404220581055, G Loss: 1.2477785348892212\n",
      "Epoch [46/50], Step [3700/7038], D Loss: 0.4528619349002838, G Loss: 1.4868311882019043\n",
      "Epoch [46/50], Step [3800/7038], D Loss: 0.6381663680076599, G Loss: 1.3313525915145874\n",
      "Epoch [46/50], Step [3900/7038], D Loss: 0.41110989451408386, G Loss: 1.6901406049728394\n",
      "Epoch [46/50], Step [4000/7038], D Loss: 0.41601240634918213, G Loss: 1.4135923385620117\n",
      "Epoch [46/50], Step [4100/7038], D Loss: 0.4499626159667969, G Loss: 1.485875129699707\n",
      "Epoch [46/50], Step [4200/7038], D Loss: 0.4414537847042084, G Loss: 1.3166697025299072\n",
      "Epoch [46/50], Step [4300/7038], D Loss: 0.7856810688972473, G Loss: 1.4441014528274536\n",
      "Epoch [46/50], Step [4400/7038], D Loss: 0.42022931575775146, G Loss: 1.6753288507461548\n",
      "Epoch [46/50], Step [4500/7038], D Loss: 0.2649284601211548, G Loss: 1.5068212747573853\n",
      "Epoch [46/50], Step [4600/7038], D Loss: 0.48614200949668884, G Loss: 1.4853205680847168\n",
      "Epoch [46/50], Step [4700/7038], D Loss: 0.5954660773277283, G Loss: 1.8623360395431519\n",
      "Epoch [46/50], Step [4800/7038], D Loss: 0.5294182896614075, G Loss: 1.436327576637268\n",
      "Epoch [46/50], Step [4900/7038], D Loss: 0.5977896451950073, G Loss: 1.3138155937194824\n",
      "Epoch [46/50], Step [5000/7038], D Loss: 0.44153809547424316, G Loss: 1.7058100700378418\n",
      "Epoch [46/50], Step [5100/7038], D Loss: 0.6365433931350708, G Loss: 1.3315268754959106\n",
      "Epoch [46/50], Step [5200/7038], D Loss: 0.7443932294845581, G Loss: 1.8391162157058716\n",
      "Epoch [46/50], Step [5300/7038], D Loss: 0.2798483967781067, G Loss: 1.8194931745529175\n",
      "Epoch [46/50], Step [5400/7038], D Loss: 0.4359152615070343, G Loss: 1.5481964349746704\n",
      "Epoch [46/50], Step [5500/7038], D Loss: 0.5655789375305176, G Loss: 1.0992183685302734\n",
      "Epoch [46/50], Step [5600/7038], D Loss: 0.44818973541259766, G Loss: 1.3938993215560913\n",
      "Epoch [46/50], Step [5700/7038], D Loss: 0.4950164258480072, G Loss: 1.4268114566802979\n",
      "Epoch [46/50], Step [5800/7038], D Loss: 0.4392750859260559, G Loss: 1.3685367107391357\n",
      "Epoch [46/50], Step [5900/7038], D Loss: 0.5863532423973083, G Loss: 1.4860243797302246\n",
      "Epoch [46/50], Step [6000/7038], D Loss: 0.40654295682907104, G Loss: 1.8515315055847168\n",
      "Epoch [46/50], Step [6100/7038], D Loss: 0.5551716685295105, G Loss: 1.5552836656570435\n",
      "Epoch [46/50], Step [6200/7038], D Loss: 0.5200293064117432, G Loss: 1.1598163843154907\n",
      "Epoch [46/50], Step [6300/7038], D Loss: 0.4367450177669525, G Loss: 1.3031153678894043\n",
      "Epoch [46/50], Step [6400/7038], D Loss: 0.6495075225830078, G Loss: 1.7515673637390137\n",
      "Epoch [46/50], Step [6500/7038], D Loss: 0.7077508568763733, G Loss: 1.5231850147247314\n",
      "Epoch [46/50], Step [6600/7038], D Loss: 0.31471961736679077, G Loss: 1.829068899154663\n",
      "Epoch [46/50], Step [6700/7038], D Loss: 0.3119049668312073, G Loss: 1.839664101600647\n",
      "Epoch [46/50], Step [6800/7038], D Loss: 0.3150724768638611, G Loss: 1.5113078355789185\n",
      "Epoch [46/50], Step [6900/7038], D Loss: 0.3415796458721161, G Loss: 1.418681263923645\n",
      "Epoch [46/50], Step [7000/7038], D Loss: 0.30703121423721313, G Loss: 1.918402910232544\n",
      "Epoch [47/50], Step [0/7038], D Loss: 0.4976547360420227, G Loss: 1.404507040977478\n",
      "Epoch [47/50], Step [100/7038], D Loss: 0.4032634496688843, G Loss: 1.3370376825332642\n",
      "Epoch [47/50], Step [200/7038], D Loss: 0.49450111389160156, G Loss: 1.076433777809143\n",
      "Epoch [47/50], Step [300/7038], D Loss: 0.5265493988990784, G Loss: 2.1516497135162354\n",
      "Epoch [47/50], Step [400/7038], D Loss: 0.38192957639694214, G Loss: 1.6105512380599976\n",
      "Epoch [47/50], Step [500/7038], D Loss: 0.4786144196987152, G Loss: 1.4023914337158203\n",
      "Epoch [47/50], Step [600/7038], D Loss: 0.3168219327926636, G Loss: 1.590707778930664\n",
      "Epoch [47/50], Step [700/7038], D Loss: 0.33273324370384216, G Loss: 1.7905583381652832\n",
      "Epoch [47/50], Step [800/7038], D Loss: 0.5195242762565613, G Loss: 1.1744128465652466\n",
      "Epoch [47/50], Step [900/7038], D Loss: 0.5433520078659058, G Loss: 1.5569785833358765\n",
      "Epoch [47/50], Step [1000/7038], D Loss: 0.35772645473480225, G Loss: 1.9167059659957886\n",
      "Epoch [47/50], Step [1100/7038], D Loss: 0.3262439966201782, G Loss: 1.9470572471618652\n",
      "Epoch [47/50], Step [1200/7038], D Loss: 0.29146257042884827, G Loss: 2.0507924556732178\n",
      "Epoch [47/50], Step [1300/7038], D Loss: 0.4392163157463074, G Loss: 1.3029028177261353\n",
      "Epoch [47/50], Step [1400/7038], D Loss: 0.7689782381057739, G Loss: 1.6237540245056152\n",
      "Epoch [47/50], Step [1500/7038], D Loss: 0.33566585183143616, G Loss: 1.436282753944397\n",
      "Epoch [47/50], Step [1600/7038], D Loss: 0.29662901163101196, G Loss: 2.3479161262512207\n",
      "Epoch [47/50], Step [1700/7038], D Loss: 0.4646158814430237, G Loss: 1.5441484451293945\n",
      "Epoch [47/50], Step [1800/7038], D Loss: 0.586881160736084, G Loss: 1.454296350479126\n",
      "Epoch [47/50], Step [1900/7038], D Loss: 0.39408597350120544, G Loss: 1.6278434991836548\n",
      "Epoch [47/50], Step [2000/7038], D Loss: 0.491699755191803, G Loss: 1.5060756206512451\n",
      "Epoch [47/50], Step [2100/7038], D Loss: 0.4140356183052063, G Loss: 1.4539622068405151\n",
      "Epoch [47/50], Step [2200/7038], D Loss: 0.4084157645702362, G Loss: 1.330290675163269\n",
      "Epoch [47/50], Step [2300/7038], D Loss: 0.3746556043624878, G Loss: 1.5722907781600952\n",
      "Epoch [47/50], Step [2400/7038], D Loss: 0.22278743982315063, G Loss: 2.014042615890503\n",
      "Epoch [47/50], Step [2500/7038], D Loss: 0.3634757399559021, G Loss: 1.7200336456298828\n",
      "Epoch [47/50], Step [2600/7038], D Loss: 0.4150092601776123, G Loss: 1.5960958003997803\n",
      "Epoch [47/50], Step [2700/7038], D Loss: 0.6915822625160217, G Loss: 1.2535152435302734\n",
      "Epoch [47/50], Step [2800/7038], D Loss: 0.4374978840351105, G Loss: 1.63222336769104\n",
      "Epoch [47/50], Step [2900/7038], D Loss: 0.7065435647964478, G Loss: 1.175371527671814\n",
      "Epoch [47/50], Step [3000/7038], D Loss: 0.6552950739860535, G Loss: 1.0124484300613403\n",
      "Epoch [47/50], Step [3100/7038], D Loss: 0.3789061903953552, G Loss: 2.0724616050720215\n",
      "Epoch [47/50], Step [3200/7038], D Loss: 0.5023325085639954, G Loss: 1.9684559106826782\n",
      "Epoch [47/50], Step [3300/7038], D Loss: 0.5955961346626282, G Loss: 1.2101415395736694\n",
      "Epoch [47/50], Step [3400/7038], D Loss: 0.5464751124382019, G Loss: 1.8748140335083008\n",
      "Epoch [47/50], Step [3500/7038], D Loss: 0.1989353448152542, G Loss: 2.0169434547424316\n",
      "Epoch [47/50], Step [3600/7038], D Loss: 0.5663328766822815, G Loss: 1.3081834316253662\n",
      "Epoch [47/50], Step [3700/7038], D Loss: 0.46009567379951477, G Loss: 1.4732449054718018\n",
      "Epoch [47/50], Step [3800/7038], D Loss: 0.5139813423156738, G Loss: 1.7796484231948853\n",
      "Epoch [47/50], Step [3900/7038], D Loss: 0.5916303396224976, G Loss: 3.254876136779785\n",
      "Epoch [47/50], Step [4000/7038], D Loss: 0.4428459405899048, G Loss: 1.455796718597412\n",
      "Epoch [47/50], Step [4100/7038], D Loss: 0.37063202261924744, G Loss: 1.2653084993362427\n",
      "Epoch [47/50], Step [4200/7038], D Loss: 0.6613456606864929, G Loss: 1.1883721351623535\n",
      "Epoch [47/50], Step [4300/7038], D Loss: 0.3024049699306488, G Loss: 1.716144323348999\n",
      "Epoch [47/50], Step [4400/7038], D Loss: 0.291252076625824, G Loss: 1.7670722007751465\n",
      "Epoch [47/50], Step [4500/7038], D Loss: 0.7346941828727722, G Loss: 1.104882836341858\n",
      "Epoch [47/50], Step [4600/7038], D Loss: 0.4680269956588745, G Loss: 1.2175688743591309\n",
      "Epoch [47/50], Step [4700/7038], D Loss: 0.5280581712722778, G Loss: 1.011047124862671\n",
      "Epoch [47/50], Step [4800/7038], D Loss: 0.5267089009284973, G Loss: 1.5576801300048828\n",
      "Epoch [47/50], Step [4900/7038], D Loss: 0.42094969749450684, G Loss: 1.6500195264816284\n",
      "Epoch [47/50], Step [5000/7038], D Loss: 0.41215217113494873, G Loss: 1.7164337635040283\n",
      "Epoch [47/50], Step [5100/7038], D Loss: 0.2836349308490753, G Loss: 1.8014154434204102\n",
      "Epoch [47/50], Step [5200/7038], D Loss: 0.512843906879425, G Loss: 1.3647270202636719\n",
      "Epoch [47/50], Step [5300/7038], D Loss: 0.20489931106567383, G Loss: 2.3170509338378906\n",
      "Epoch [47/50], Step [5400/7038], D Loss: 0.8846521377563477, G Loss: 1.5993081331253052\n",
      "Epoch [47/50], Step [5500/7038], D Loss: 0.47954994440078735, G Loss: 1.4502654075622559\n",
      "Epoch [47/50], Step [5600/7038], D Loss: 0.5919009447097778, G Loss: 1.3707799911499023\n",
      "Epoch [47/50], Step [5700/7038], D Loss: 0.3127172887325287, G Loss: 1.817338228225708\n",
      "Epoch [47/50], Step [5800/7038], D Loss: 0.4409770667552948, G Loss: 1.6020307540893555\n",
      "Epoch [47/50], Step [5900/7038], D Loss: 0.32536664605140686, G Loss: 1.2994376420974731\n",
      "Epoch [47/50], Step [6000/7038], D Loss: 0.3203539550304413, G Loss: 1.8003735542297363\n",
      "Epoch [47/50], Step [6100/7038], D Loss: 0.41905367374420166, G Loss: 1.324044108390808\n",
      "Epoch [47/50], Step [6200/7038], D Loss: 0.5653012990951538, G Loss: 2.053924560546875\n",
      "Epoch [47/50], Step [6300/7038], D Loss: 0.5464541912078857, G Loss: 1.1002953052520752\n",
      "Epoch [47/50], Step [6400/7038], D Loss: 0.3333285450935364, G Loss: 1.6893161535263062\n",
      "Epoch [47/50], Step [6500/7038], D Loss: 0.46023082733154297, G Loss: 1.6655703783035278\n",
      "Epoch [47/50], Step [6600/7038], D Loss: 0.658118486404419, G Loss: 1.1505368947982788\n",
      "Epoch [47/50], Step [6700/7038], D Loss: 0.2598881423473358, G Loss: 1.7839815616607666\n",
      "Epoch [47/50], Step [6800/7038], D Loss: 0.5785844326019287, G Loss: 1.3187059164047241\n",
      "Epoch [47/50], Step [6900/7038], D Loss: 0.38516706228256226, G Loss: 1.8508546352386475\n",
      "Epoch [47/50], Step [7000/7038], D Loss: 0.5151982307434082, G Loss: 1.354927897453308\n",
      "Epoch [48/50], Step [0/7038], D Loss: 0.46812230348587036, G Loss: 1.2832462787628174\n",
      "Epoch [48/50], Step [100/7038], D Loss: 0.4023842513561249, G Loss: 1.3672173023223877\n",
      "Epoch [48/50], Step [200/7038], D Loss: 0.2865781784057617, G Loss: 1.8876954317092896\n",
      "Epoch [48/50], Step [300/7038], D Loss: 0.42993444204330444, G Loss: 1.482847809791565\n",
      "Epoch [48/50], Step [400/7038], D Loss: 0.490704745054245, G Loss: 1.3713093996047974\n",
      "Epoch [48/50], Step [500/7038], D Loss: 0.7102326154708862, G Loss: 1.2795443534851074\n",
      "Epoch [48/50], Step [600/7038], D Loss: 0.41822540760040283, G Loss: 1.2099725008010864\n",
      "Epoch [48/50], Step [700/7038], D Loss: 0.3837137520313263, G Loss: 1.7811510562896729\n",
      "Epoch [48/50], Step [800/7038], D Loss: 0.2738523483276367, G Loss: 2.053253173828125\n",
      "Epoch [48/50], Step [900/7038], D Loss: 0.4886325001716614, G Loss: 1.6756901741027832\n",
      "Epoch [48/50], Step [1000/7038], D Loss: 0.548814594745636, G Loss: 1.311510682106018\n",
      "Epoch [48/50], Step [1100/7038], D Loss: 0.42052263021469116, G Loss: 1.3797730207443237\n",
      "Epoch [48/50], Step [1200/7038], D Loss: 0.674350380897522, G Loss: 1.5194882154464722\n",
      "Epoch [48/50], Step [1300/7038], D Loss: 0.5664899349212646, G Loss: 2.0620949268341064\n",
      "Epoch [48/50], Step [1400/7038], D Loss: 0.40551048517227173, G Loss: 1.5379174947738647\n",
      "Epoch [48/50], Step [1500/7038], D Loss: 0.5253816843032837, G Loss: 1.7244285345077515\n",
      "Epoch [48/50], Step [1600/7038], D Loss: 0.4415271282196045, G Loss: 1.290238857269287\n",
      "Epoch [48/50], Step [1700/7038], D Loss: 0.6910293698310852, G Loss: 2.090592384338379\n",
      "Epoch [48/50], Step [1800/7038], D Loss: 0.6384478807449341, G Loss: 1.3594927787780762\n",
      "Epoch [48/50], Step [1900/7038], D Loss: 0.39709728956222534, G Loss: 1.850934386253357\n",
      "Epoch [48/50], Step [2000/7038], D Loss: 0.345869243144989, G Loss: 1.4915369749069214\n",
      "Epoch [48/50], Step [2100/7038], D Loss: 0.38578009605407715, G Loss: 1.583132028579712\n",
      "Epoch [48/50], Step [2200/7038], D Loss: 0.4818955659866333, G Loss: 1.397153615951538\n",
      "Epoch [48/50], Step [2300/7038], D Loss: 0.5480930209159851, G Loss: 1.135354995727539\n",
      "Epoch [48/50], Step [2400/7038], D Loss: 0.3828767240047455, G Loss: 2.05837345123291\n",
      "Epoch [48/50], Step [2500/7038], D Loss: 0.3148234188556671, G Loss: 1.4734036922454834\n",
      "Epoch [48/50], Step [2600/7038], D Loss: 0.3873923718929291, G Loss: 1.4900431632995605\n",
      "Epoch [48/50], Step [2700/7038], D Loss: 0.6762620806694031, G Loss: 0.9577322006225586\n",
      "Epoch [48/50], Step [2800/7038], D Loss: 0.4632352292537689, G Loss: 1.102821707725525\n",
      "Epoch [48/50], Step [2900/7038], D Loss: 0.3441430628299713, G Loss: 1.9293767213821411\n",
      "Epoch [48/50], Step [3000/7038], D Loss: 0.49278268218040466, G Loss: 1.2079955339431763\n",
      "Epoch [48/50], Step [3100/7038], D Loss: 0.8751485347747803, G Loss: 1.4689372777938843\n",
      "Epoch [48/50], Step [3200/7038], D Loss: 0.3814518451690674, G Loss: 1.433073878288269\n",
      "Epoch [48/50], Step [3300/7038], D Loss: 0.3082704544067383, G Loss: 1.5189751386642456\n",
      "Epoch [48/50], Step [3400/7038], D Loss: 0.5763651132583618, G Loss: 1.2414345741271973\n",
      "Epoch [48/50], Step [3500/7038], D Loss: 0.3552534580230713, G Loss: 3.302339553833008\n",
      "Epoch [48/50], Step [3600/7038], D Loss: 0.41050440073013306, G Loss: 1.5938202142715454\n",
      "Epoch [48/50], Step [3700/7038], D Loss: 0.6427590847015381, G Loss: 1.1675235033035278\n",
      "Epoch [48/50], Step [3800/7038], D Loss: 0.7312759160995483, G Loss: 1.0086501836776733\n",
      "Epoch [48/50], Step [3900/7038], D Loss: 0.5730934739112854, G Loss: 1.3132870197296143\n",
      "Epoch [48/50], Step [4000/7038], D Loss: 0.6894713640213013, G Loss: 1.6743438243865967\n",
      "Epoch [48/50], Step [4100/7038], D Loss: 0.38617223501205444, G Loss: 1.406532883644104\n",
      "Epoch [48/50], Step [4200/7038], D Loss: 0.29878854751586914, G Loss: 1.996650218963623\n",
      "Epoch [48/50], Step [4300/7038], D Loss: 0.20953543484210968, G Loss: 1.6969006061553955\n",
      "Epoch [48/50], Step [4400/7038], D Loss: 0.31572067737579346, G Loss: 1.816379427909851\n",
      "Epoch [48/50], Step [4500/7038], D Loss: 0.6237081289291382, G Loss: 1.3612656593322754\n",
      "Epoch [48/50], Step [4600/7038], D Loss: 0.6283104419708252, G Loss: 1.1859792470932007\n",
      "Epoch [48/50], Step [4700/7038], D Loss: 0.39015424251556396, G Loss: 1.3705397844314575\n",
      "Epoch [48/50], Step [4800/7038], D Loss: 0.4020783007144928, G Loss: 1.4575120210647583\n",
      "Epoch [48/50], Step [4900/7038], D Loss: 0.36978742480278015, G Loss: 2.390080213546753\n",
      "Epoch [48/50], Step [5000/7038], D Loss: 0.7791858315467834, G Loss: 1.3348615169525146\n",
      "Epoch [48/50], Step [5100/7038], D Loss: 0.389736533164978, G Loss: 1.3239012956619263\n",
      "Epoch [48/50], Step [5200/7038], D Loss: 0.2818717360496521, G Loss: 1.6539255380630493\n",
      "Epoch [48/50], Step [5300/7038], D Loss: 0.4102238118648529, G Loss: 1.6063525676727295\n",
      "Epoch [48/50], Step [5400/7038], D Loss: 0.3323540687561035, G Loss: 1.7208685874938965\n",
      "Epoch [48/50], Step [5500/7038], D Loss: 0.3638852834701538, G Loss: 1.5101324319839478\n",
      "Epoch [48/50], Step [5600/7038], D Loss: 0.4282436966896057, G Loss: 1.787235975265503\n",
      "Epoch [48/50], Step [5700/7038], D Loss: 0.47618791460990906, G Loss: 1.856374740600586\n",
      "Epoch [48/50], Step [5800/7038], D Loss: 0.4926761984825134, G Loss: 1.5508979558944702\n",
      "Epoch [48/50], Step [5900/7038], D Loss: 0.406793475151062, G Loss: 1.5116912126541138\n",
      "Epoch [48/50], Step [6000/7038], D Loss: 0.514621913433075, G Loss: 1.7570805549621582\n",
      "Epoch [48/50], Step [6100/7038], D Loss: 0.30374830961227417, G Loss: 1.912375807762146\n",
      "Epoch [48/50], Step [6200/7038], D Loss: 0.34453117847442627, G Loss: 1.8267083168029785\n",
      "Epoch [48/50], Step [6300/7038], D Loss: 0.5166691541671753, G Loss: 1.144222617149353\n",
      "Epoch [48/50], Step [6400/7038], D Loss: 0.3958236575126648, G Loss: 1.6825482845306396\n",
      "Epoch [48/50], Step [6500/7038], D Loss: 0.4025822877883911, G Loss: 1.666029930114746\n",
      "Epoch [48/50], Step [6600/7038], D Loss: 0.7839447259902954, G Loss: 1.1720057725906372\n",
      "Epoch [48/50], Step [6700/7038], D Loss: 0.49777132272720337, G Loss: 1.4554725885391235\n",
      "Epoch [48/50], Step [6800/7038], D Loss: 0.5312305092811584, G Loss: 2.324906587600708\n",
      "Epoch [48/50], Step [6900/7038], D Loss: 0.40639325976371765, G Loss: 1.7412596940994263\n",
      "Epoch [48/50], Step [7000/7038], D Loss: 0.43500787019729614, G Loss: 1.4575896263122559\n",
      "Epoch [49/50], Step [0/7038], D Loss: 0.2757036089897156, G Loss: 2.0612950325012207\n",
      "Epoch [49/50], Step [100/7038], D Loss: 0.4345685839653015, G Loss: 1.4002857208251953\n",
      "Epoch [49/50], Step [200/7038], D Loss: 0.5632385015487671, G Loss: 1.2652995586395264\n",
      "Epoch [49/50], Step [300/7038], D Loss: 0.689494788646698, G Loss: 1.3931434154510498\n",
      "Epoch [49/50], Step [400/7038], D Loss: 0.26831740140914917, G Loss: 1.8644391298294067\n",
      "Epoch [49/50], Step [500/7038], D Loss: 0.4240642786026001, G Loss: 1.4137659072875977\n",
      "Epoch [49/50], Step [600/7038], D Loss: 0.3642053008079529, G Loss: 1.645310401916504\n",
      "Epoch [49/50], Step [700/7038], D Loss: 0.4134204387664795, G Loss: 1.698978304862976\n",
      "Epoch [49/50], Step [800/7038], D Loss: 0.39841291308403015, G Loss: 1.8784124851226807\n",
      "Epoch [49/50], Step [900/7038], D Loss: 0.2899862825870514, G Loss: 1.9183802604675293\n",
      "Epoch [49/50], Step [1000/7038], D Loss: 0.5167816281318665, G Loss: 1.4396119117736816\n",
      "Epoch [49/50], Step [1100/7038], D Loss: 0.45405346155166626, G Loss: 1.3191384077072144\n",
      "Epoch [49/50], Step [1200/7038], D Loss: 0.9893872737884521, G Loss: 1.3346455097198486\n",
      "Epoch [49/50], Step [1300/7038], D Loss: 0.4470447301864624, G Loss: 1.6063542366027832\n",
      "Epoch [49/50], Step [1400/7038], D Loss: 0.7135880589485168, G Loss: 1.3279261589050293\n",
      "Epoch [49/50], Step [1500/7038], D Loss: 0.48360639810562134, G Loss: 1.5034598112106323\n",
      "Epoch [49/50], Step [1600/7038], D Loss: 0.48118284344673157, G Loss: 1.2693759202957153\n",
      "Epoch [49/50], Step [1700/7038], D Loss: 0.318950891494751, G Loss: 1.6211767196655273\n",
      "Epoch [49/50], Step [1800/7038], D Loss: 0.3480815291404724, G Loss: 2.0221951007843018\n",
      "Epoch [49/50], Step [1900/7038], D Loss: 0.48290568590164185, G Loss: 1.4356669187545776\n",
      "Epoch [49/50], Step [2000/7038], D Loss: 0.25255098938941956, G Loss: 1.637434482574463\n",
      "Epoch [49/50], Step [2100/7038], D Loss: 0.5284828543663025, G Loss: 1.5151069164276123\n",
      "Epoch [49/50], Step [2200/7038], D Loss: 0.6098510026931763, G Loss: 1.374259352684021\n",
      "Epoch [49/50], Step [2300/7038], D Loss: 0.4211667776107788, G Loss: 1.5406039953231812\n",
      "Epoch [49/50], Step [2400/7038], D Loss: 0.8903077840805054, G Loss: 1.752646565437317\n",
      "Epoch [49/50], Step [2500/7038], D Loss: 0.23641739785671234, G Loss: 1.8904930353164673\n",
      "Epoch [49/50], Step [2600/7038], D Loss: 0.8435620069503784, G Loss: 1.3834997415542603\n",
      "Epoch [49/50], Step [2700/7038], D Loss: 0.35238003730773926, G Loss: 1.518463373184204\n",
      "Epoch [49/50], Step [2800/7038], D Loss: 0.4164566099643707, G Loss: 1.822723150253296\n",
      "Epoch [49/50], Step [2900/7038], D Loss: 0.6267859935760498, G Loss: 1.564998745918274\n",
      "Epoch [49/50], Step [3000/7038], D Loss: 0.20867261290550232, G Loss: 2.5301852226257324\n",
      "Epoch [49/50], Step [3100/7038], D Loss: 0.5537889003753662, G Loss: 1.6325716972351074\n",
      "Epoch [49/50], Step [3200/7038], D Loss: 0.2990241050720215, G Loss: 1.5620981454849243\n",
      "Epoch [49/50], Step [3300/7038], D Loss: 0.36144885420799255, G Loss: 2.0401437282562256\n",
      "Epoch [49/50], Step [3400/7038], D Loss: 0.4576932191848755, G Loss: 1.1141879558563232\n",
      "Epoch [49/50], Step [3500/7038], D Loss: 0.8669389486312866, G Loss: 0.9935041069984436\n",
      "Epoch [49/50], Step [3600/7038], D Loss: 0.3747745156288147, G Loss: 1.5538254976272583\n",
      "Epoch [49/50], Step [3700/7038], D Loss: 0.4544684886932373, G Loss: 1.310347557067871\n",
      "Epoch [49/50], Step [3800/7038], D Loss: 0.3831862211227417, G Loss: 1.5579447746276855\n",
      "Epoch [49/50], Step [3900/7038], D Loss: 0.5059666633605957, G Loss: 1.2039430141448975\n",
      "Epoch [49/50], Step [4000/7038], D Loss: 0.4008779525756836, G Loss: 1.3062572479248047\n",
      "Epoch [49/50], Step [4100/7038], D Loss: 0.40524351596832275, G Loss: 1.563669204711914\n",
      "Epoch [49/50], Step [4200/7038], D Loss: 0.2881178855895996, G Loss: 1.7722293138504028\n",
      "Epoch [49/50], Step [4300/7038], D Loss: 0.5204733610153198, G Loss: 1.9469832181930542\n",
      "Epoch [49/50], Step [4400/7038], D Loss: 0.5062944889068604, G Loss: 1.6128041744232178\n",
      "Epoch [49/50], Step [4500/7038], D Loss: 0.5083186030387878, G Loss: 1.6208850145339966\n",
      "Epoch [49/50], Step [4600/7038], D Loss: 0.5853089690208435, G Loss: 1.5388882160186768\n",
      "Epoch [49/50], Step [4700/7038], D Loss: 0.5527309775352478, G Loss: 1.6628996133804321\n",
      "Epoch [49/50], Step [4800/7038], D Loss: 0.5355196595191956, G Loss: 1.349955677986145\n",
      "Epoch [49/50], Step [4900/7038], D Loss: 0.41795533895492554, G Loss: 1.795749545097351\n",
      "Epoch [49/50], Step [5000/7038], D Loss: 0.5308991074562073, G Loss: 1.7234474420547485\n",
      "Epoch [49/50], Step [5100/7038], D Loss: 0.5274538397789001, G Loss: 1.542447805404663\n",
      "Epoch [49/50], Step [5200/7038], D Loss: 0.3928980827331543, G Loss: 1.4226497411727905\n",
      "Epoch [49/50], Step [5300/7038], D Loss: 0.4067182242870331, G Loss: 2.075289011001587\n",
      "Epoch [49/50], Step [5400/7038], D Loss: 0.5551598072052002, G Loss: 1.2820451259613037\n",
      "Epoch [49/50], Step [5500/7038], D Loss: 0.4290229082107544, G Loss: 1.934944748878479\n",
      "Epoch [49/50], Step [5600/7038], D Loss: 0.5744999051094055, G Loss: 1.559418797492981\n",
      "Epoch [49/50], Step [5700/7038], D Loss: 0.48110532760620117, G Loss: 1.3385412693023682\n",
      "Epoch [49/50], Step [5800/7038], D Loss: 0.6651778817176819, G Loss: 1.3953100442886353\n",
      "Epoch [49/50], Step [5900/7038], D Loss: 0.34239640831947327, G Loss: 1.585518717765808\n",
      "Epoch [49/50], Step [6000/7038], D Loss: 0.6663349866867065, G Loss: 1.5227868556976318\n",
      "Epoch [49/50], Step [6100/7038], D Loss: 0.49510037899017334, G Loss: 1.4100035429000854\n",
      "Epoch [49/50], Step [6200/7038], D Loss: 0.431373655796051, G Loss: 1.7961400747299194\n",
      "Epoch [49/50], Step [6300/7038], D Loss: 1.2739648818969727, G Loss: 1.9763407707214355\n",
      "Epoch [49/50], Step [6400/7038], D Loss: 0.2590240240097046, G Loss: 2.0800020694732666\n",
      "Epoch [49/50], Step [6500/7038], D Loss: 0.49446696043014526, G Loss: 1.6340221166610718\n",
      "Epoch [49/50], Step [6600/7038], D Loss: 0.4945201277732849, G Loss: 1.412514328956604\n",
      "Epoch [49/50], Step [6700/7038], D Loss: 0.43952929973602295, G Loss: 1.6509441137313843\n",
      "Epoch [49/50], Step [6800/7038], D Loss: 0.5426319241523743, G Loss: 1.4415569305419922\n",
      "Epoch [49/50], Step [6900/7038], D Loss: 0.30771881341934204, G Loss: 1.796210765838623\n",
      "Epoch [49/50], Step [7000/7038], D Loss: 0.4336819648742676, G Loss: 2.931417226791382\n"
     ]
    }
   ],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "num_epochs = 50  \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        real_images = batch['Photo'].to(device)  \n",
    "        fake_images = generator(real_images).detach()\n",
    "        real_loss = criterion(discriminator(real_images), torch.ones_like(discriminator(real_images)))\n",
    "        fake_loss = criterion(discriminator(fake_images), torch.zeros_like(discriminator(fake_images)))\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        optimizer_D.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        fake_images = generator(real_images)\n",
    "        g_loss = criterion(discriminator(fake_images), torch.ones_like(discriminator(fake_images)))\n",
    "        optimizer_G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        if i % 100 == 0:  \n",
    "            print(f\"Epoch [{epoch}/{num_epochs}], Step [{i}/{len(dataloader)}], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c63c30-d3b6-4ff2-85d7-fa560503e70b",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "654920cd-be08-4d5b-ad34-deb22b36cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_generated_images(images, nmax=5):\n",
    "    fig, axes = plt.subplots(figsize=(10, 5), nrows=1, ncols=nmax, sharey=True, sharex=True)\n",
    "    for ax, img in zip(axes.flatten(), images[:nmax]):\n",
    "        img = img.detach().cpu().numpy().transpose(1, 2, 0)\n",
    "        img = (img + 1) / 2 \n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765a6233-1783-48b8-90dd-11271f2766e2",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a7af9a-148d-407d-afde-bc89efff97ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "\n",
    "generator.eval()\n",
    "save_dir = './tmp/monet_imgs'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for i in range(7000):\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(1, 100, 1, 1, device=device)\n",
    "        generated_image = generator(noise)\n",
    "        generated_image = (generated_image + 1) / 2  \n",
    "        save_path = f'{save_dir}/{i:04d}.jpg'\n",
    "        save_image(generated_image.cpu(), save_path)\n",
    "shutil.make_archive('images', 'zip', save_dir)\n",
    "\n",
    "shutil.move('images.zip', './images.zip')\n",
    "\n",
    "shutil.rmtree(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921ae66-ecf5-4e21-b536-24983aecd873",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f721c2-f5d0-4ab0-a11e-41c195ee6681",
   "metadata": {},
   "source": [
    "This workflow demonstrates a practical application of deep learning models for image generation, showcasing not only the model's inference capabilities but also the necessary post-processing steps for handling and distributing the generated data. The use of PyTorch for model inference and standard Python libraries for file management underscores the importance of integrating deep learning models with broader software engineering practices to create end-to-end pipelines.\n",
    "\n",
    "The provided adjustments ensure that the code runs efficiently and correctly, addressing common issues such as device management for tensors, data normalization for image visualization, and robust file handling. Successfully executing this pipeline can serve as a foundation for more complex projects involving image generation, such as creating datasets for further machine learning projects, digital art creation, or enhancing data augmentation strategies for training other models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
